<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>Tutorial Machine Learning Archivi - Data Trading</title>
	<atom:link href="https://datatrading.info/category/tutorial-machine-learning/feed/" rel="self" type="application/rss+xml" />
	<link></link>
	<description>Tecnologie Digitali applicate al Trading</description>
	<lastBuildDate>Sun, 31 Jul 2022 17:57:36 +0000</lastBuildDate>
	<language>it-IT</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	

<image>
	<url>https://datatrading.info/wp-content/uploads/2019/04/favico.-300x300.jpg</url>
	<title>Tutorial Machine Learning Archivi - Data Trading</title>
	<link></link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>Inversione della Matrice &#8211; Algebra Lineare per il Deep Learning (parte 3)</title>
		<link>https://datatrading.info/inversione-della-matrice-algebra-lineare-per-il-deep-learning-parte-3/</link>
					<comments>https://datatrading.info/inversione-della-matrice-algebra-lineare-per-il-deep-learning-parte-3/#respond</comments>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Mon, 08 Jan 2018 18:49:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Deep Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5487</guid>

					<description><![CDATA[<p>Nel precedente articolo sull&#8217;algebra lineare abbiamo considerato le operazioni di base sulle matrici come la somma e la moltiplicazione tra matrici. Queste operazioni sono un prerequisito necessario verso il concetto di inversione di matrice. In questo articolo introduciamo l&#8217;inversione di matrice e  ne descriviamo l&#8217;importanza. Motiviamo l&#8217;inversione della matrice attraverso il concetto di risoluzione di equazioni &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/inversione-della-matrice-algebra-lineare-per-il-deep-learning-parte-3/"> <span class="screen-reader-text">Inversione della Matrice &#8211; Algebra Lineare per il Deep Learning (parte 3)</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/inversione-della-matrice-algebra-lineare-per-il-deep-learning-parte-3/">Inversione della Matrice &#8211; Algebra Lineare per il Deep Learning (parte 3)</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5487" class="elementor elementor-5487">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-29ba58a elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="29ba58a" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-e33908c" data-id="e33908c" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-db178d6 elementor-widget elementor-widget-text-editor" data-id="db178d6" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Nel <a href="https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/">precedente articolo sull&#8217;algebra lineare</a> abbiamo considerato le operazioni di base sulle matrici come la somma e la moltiplicazione tra matrici. Queste operazioni sono un prerequisito necessario verso il concetto di <strong>inversione di matrice</strong>.</p><p>In questo articolo introduciamo l&#8217;inversione di matrice e  ne descriviamo l&#8217;importanza. Motiviamo l&#8217;inversione della matrice attraverso il concetto di risoluzione di equazioni lineari simultanee, che possono essere familiari dalle lezioni di matematica delle scuole superiori.</p><p>Risolvere equazioni lineari simultanee è indispensabile in molti campi della scienza applicata. Nella fisica e  nell&#8217;ingegneria, la simulazione numerica dei flussi di fluido su un computer richiede la risoluzione di equazioni lineari simultanee. Nella finanza quantitativa sono usate per risolvere il <a href="https://datatrading.info/derivazione-dellequazione-di-black-scholes/">Black-Scholes PDE</a>, necessaria per i prezzi di alcuni tipi di opzioni.</p><p>L&#8217;inversione della matrice è una tecnica importante perchè può aiutarci a risolvere queste equazioni lineari simultanee. È un metodo fondamentale nella statistica e nel machine learning, che deriva dalla soluzione della <a href="https://datatrading.info/metodo-della-massima-verosimiglianza-per-la-regressione-lineare/">stima dei minimi quadrati ordinari per la regressione lineare</a> .</p><h2>Equazioni lineari simultanee</h2><p>Iniziamo con un esempio motivante di un piccolo insieme di equazioni lineari simultanee:</p><p style="text-align: center;">\(\begin{eqnarray}<br />x + 2y + 4z &amp;=&amp; 10 \\<br />3x + y &#8211; 5z &amp;=&amp; -8 \\<br />4x &#8211; 3y + 7z &amp;=&amp; 4<br />\end{eqnarray}\)</p><p>L&#8217;obiettivo consiste nel trovare i valori di <em>x</em>, <em>y </em>e <em>z </em>che soddisfano queste equazioni. Nel caso precedente, con solo tre equazioni, una manipolazione algebrica relativamente semplice fornisce la risposta.</p><p>Quando il numero di equazioni aumenta in modo significativo, può diventare complicato dal punto di vista nozionale scrivere le equazioni in questo modo.</p><p>Un&#8217;alternativa è scrivere tali sistemi in modo compatto usando la notazione matriciale. Considerano \(\boldsymbol{x} = [x, y, z]^T\), \(\boldsymbol{b} = [10, -8, 4]^T\) e la matrice dei coefficienti <em><strong>A</strong></em> abbiamo quanto segue:</p><p style="text-align: center;">\(\boldsymbol{A} = \left[ \begin{array}{ccc}<br />1 &amp; 2 &amp; 4 \\<br />3 &amp; 1 &amp; -5 \\<br />4 &amp; -3 &amp; 7<br />\end{array} \right]\)</p><p>È possibile scrivere il sistema sopra come:</p><p style="text-align: center;">\(\left[ \begin{array}{ccc}<br />1 &amp; 2 &amp; 4 \\<br />3 &amp; 1 &amp; -5 \\<br />4 &amp; -3 &amp; 7<br />\end{array} \right]<br />\left[ \begin{array}{c}<br />x \\<br />y \\<br />z<br />\end{array} \right] =<br />\left[ \begin{array}{c}<br />10 \\<br />-8 \\<br />4<br />\end{array} \right]\)</p><p>Oppure, in modo più compatto:</p><p style="text-align: center;">\(\begin{eqnarray}<br />\boldsymbol{A} \boldsymbol{x} = \boldsymbol{b}<br />\end{eqnarray}\)</p><p>Il carattere in grassetto sottolinea che i termini nell&#8217;equazione sono quantità vettoriali e matriciali piuttosto che quantità scalari.</p><p>Se questa fosse un&#8217;equazione algebrica della forma \(A x = b\) con \(A \neq 0\), dove \(A, x, b \in \mathbb{R}\) cioè i termini sono tutte quantità scalari, allora questo potrebbe essere risolta per <strong><em>x</em></strong> dividendo semplicemente per <strong><em>A</em></strong>:</p><p style="text-align: center;">\(\begin{equation}<br />x = \frac{b}{A} = \frac{1}{A} b = A^{-1} b<br />\end{equation}\)</p><p>Questa equazione dimostra  che \(x = A^{-1} b\). Possiamo quindi chiederci se sia possibile risolvere l&#8217;equazione della matrice \(\boldsymbol{A} \boldsymbol{x} = \boldsymbol{b}x\) attraverso una forma simile all&#8217;espressione \(\boldsymbol{x} = \boldsymbol{A}^{-1} \boldsymbol{b}\)?</p><p>Poiché l&#8217;operazione di divisione per una matrice non è definita, la risposta sta nella definizione della matrice \(\boldsymbol{A}^{-1}\), nota come <strong>matrice inversa</strong> di <strong><em>A</em></strong>. Per farlo è però necessario introdurre ulteriori strumenti matematici.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-8ee7b6b elementor-widget elementor-widget-text-editor" data-id="8ee7b6b" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Delta di Kronecker e matrici di identità</h2><p>Il <strong>delta di Kronecker</strong> è una funzione matematica di due variabili <em>i</em>,- <em>j</em> con i seguenti valori:</p><p style="text-align: center;">\(\begin{equation}<br />\delta_{ij} =<br />\begin{cases}<br />1, &amp; \text{if } i=j,\\<br />0, &amp; \text{if } i\neq j.<br />\end{cases}<br />\end{equation}\)</p><p>In sostanza, il delta di Kronecker è pari a uno quando <em>i</em> e <em>j</em> sono uguali mentre è pari a zero quando sono diversi.</p><p>Questa funzione può essere utilizzata per definire una nuova matrice quadrata in cui ogni elemento della matrice in posizione <em>i,j</em> è uguale al delta di Kronecker di quel valore.</p><p>Matematicamente questo è scritto in modo compatto come \(\boldsymbol{I}_n=[\delta_{ij}]_{n \times n}\). La matrice stessa avrà la seguente forma:</p><p style="text-align: center;">\(\begin{equation}<br />\boldsymbol{I}_n=\begin{bmatrix}<br />\kern4pt 1 &amp; 0 &amp; 0 &amp; \dots &amp; 0 \kern4pt \\<br />\kern4pt 0 &amp; 1 &amp; 0 &amp; \dots &amp; 0 \kern4pt \\<br />\kern4pt 0 &amp; 0 &amp; 1 &amp; \dots &amp; 0 \kern4pt \\<br />\kern4pt \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \kern4pt \\<br />\kern4pt 0 &amp; 0 &amp; 0 &amp; \dots &amp; 1 \kern4pt \\<br />\end{bmatrix}<br />\end{equation}\)</p><p>In particolare tutti gli elementi della matrice sono zero tranne quelli sulla <em>diagonale</em> della matrice, che sono uguali a uno. Questo perché gli elementi diagonali rappresentano il caso in cui <em>i=j</em> e il delta di Kronecker è uguale a uno per questi valori.</p><p>Questo tipo di matrice è noto come <strong>matrice identità</strong> con dimensione <em>n</em>. La matrice identità possiede la proprietà unica che quando viene moltiplicata a sinistra o a destra per una qualsiasi matrice quadrata \(\boldsymbol{A} \in \mathbb{R}^{n \times n}\) lascia invariata <strong><em>A</em></strong>:</p><p style="text-align: center;">\(\begin{equation}<br />\boldsymbol{I}_n \boldsymbol{A} = \boldsymbol{A} \boldsymbol{I}_n = \boldsymbol{A}<br />\end{equation}\)</p><p>Questo è facilmente dimostrabile con la definizione di moltiplicazione tra matrici  descritte nell&#8217;<a href="https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/">articolo precedente</a>.</p><p>Possiamo ora definire la matrice inversa \(\boldsymbol{A}^{-1}\). L&#8217;inversa di una matrice è precisamente la matrice che moltiplicata a sinistra o a destra per <strong><em>A</em></strong> produce la matrice identità:</p><p style="text-align: center;">\(\begin{equation}<br />\boldsymbol{A}^{-1} \boldsymbol{A} = \boldsymbol{I}_n = \boldsymbol{A} \boldsymbol{A}^{-1}<br />\end{equation}\)</p><p>Quanto sopra può essere dimostrato considerando le analoghe regole di moltiplicazione per un&#8217;equazione algebrica scalare equivalente:</p><p style="text-align: center;">\(\begin{equation}<br />\frac{a}{a} = \frac{1}{a} a = a^{-1} a = 1 = a a^{-1} = a \frac{1}{a} = \frac{a}{a}<br />\end{equation}\)</p><p>In particolare \(a^{-1} a = 1 = a a^{-1}\). Il valore 1 può essere interpretato come una matrice 1&#215;1 con un unico valore.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e85f2a5 elementor-widget elementor-widget-text-editor" data-id="e85f2a5" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Risolvere l&#8217;equazione matriciale</h2><p>Con queste definizioni è ora possibile risolvere l&#8217;equazione originale \(\boldsymbol{A} \boldsymbol{x} = \boldsymbol{b}\):</p><p style="text-align: center;">\(\begin{eqnarray}<br />\boldsymbol{A} \boldsymbol{x} &amp;=&amp; \boldsymbol{b} \\<br />\boldsymbol{A}^{-1} \boldsymbol{A} \boldsymbol{x} &amp;=&amp; \boldsymbol{A}^{-1} \boldsymbol{b} \\<br />\boldsymbol{I}_n \boldsymbol{x} &amp;=&amp; \boldsymbol{A}^{-1} \boldsymbol{b} \\<br />\boldsymbol{x} &amp;=&amp; \boldsymbol{A}^{-1} \boldsymbol{b}\label{eqn-matrix-inverse}<br />\end{eqnarray}\)</p><p>Innanzitutto l&#8217;equazione viene moltiplicata a sinistra per la matrice inversa \(\boldsymbol{A}^{-1}\). Il termine \(\boldsymbol{A}^{-1} \boldsymbol{A}\) può quindi essere impostato sulla matrice identità \(\boldsymbol{I}_n\).</p><p>Dato che qualsiasi vettore o matrice rimane invariato quando moltiplicato per la matrice identità, possiamo rimuovere il riferimento a \(\boldsymbol{I}_n\) e quindi ottenere un&#8217;espressione per <em>x</em> in termini di matrice inversa \(\boldsymbol{A}^{-1}\) e il vettore <strong><em>b</em></strong>.</p><p>Possiamo quindi risolvere l&#8217;equazione \(\boldsymbol{x} = \boldsymbol{A}^{-1} \boldsymbol{b}\) per il vettore sconosciuto <strong><em>x </em></strong>supponendo che esista un&#8217;appropriata \(\boldsymbol{A}^{-1}\).</p><p>Tuttavia, dobbiamo ancora descrivere come procedere per calcolare \(\boldsymbol{A}^{-1}\) o se è possibile farlo.</p><p>Questo sarà argomento per futuri articoli della serie, ma descriviamo brevemente alcuni dei principali meccanismi per il calcolo dell&#8217;inversa della matrice.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fdff79b elementor-widget elementor-widget-text-editor" data-id="fdff79b" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Algoritmi per l&#8217;inversione di matrice</h2><p>Un metodo comune per trovare l&#8217;inverso di una matrice (se esiste) consiste nell&#8217;utilizzare una tecnica nota come <strong>eliminazione Gauss-Jordan</strong> (o eliminazione gaussiana). Tuttavia per un matrice \(n \times n\) di grandi dimensioni è un meccanismo costoso e inefficiente per trovare l&#8217;inversa.</p><p>Il costo dell&#8217;operazione aumenta cubicamente con la dimensione della matrice, cioè ha una complessità aritmetica di \(\mathcal{O}(n^3)\). Questo può essere un problema significativo quando è necessario eseguire molte operazioni di calcolo delle matrici inverse.</p><p>Per la maggior parte delle applicazioni nelle scienze applicate, nella finanza quantitativa e nel deep learning è sufficiente <em>approssimare</em> la soluzione <strong><em>x</em></strong> entro una certa tolleranza piuttosto che cercare il valore esatto.</p><p>Esistono molti algoritmi meno intensivi dal punto di vista computazionale che sono abbastanza efficaci da fornire l&#8217;accuratezza necessaria.</p><p>Questi algoritmi consistono in una versione ben ottimizzata dell&#8217;eliminazione di Gauss-Jordan per  particolari matrici <em>strutturate</em>o utilizzano un <a href="https://en.wikipedia.org/wiki/Iterative_method">approccio iterativo</a> che approssima <strong><em>x</em></strong> con una certa precisione in un numero finito di iterazioni.</p><p>La necessità di approssimare efficacemente <strong><em>x </em></strong>nella suddetta equazione matriciale ha portato allo sviluppo di un intero sottocampo della matematica noto come <strong>Algebra Lineare Numerica</strong>.</p><p>Alcune <strong>fattorizzazioni di matrici</strong> possono essere estremamente utili per risolvere in modo più efficiente questa equazione. Tali fattorizzazioni sono ampiamente discussi negli articoli successivi.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-840bda2 elementor-widget elementor-widget-text-editor" data-id="840bda2" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Prossimi passi</h2>
Nel prossimo articolo descriviamo l&#8217;eliminazione di Gauss-Jordan e scriviamo del codice Python per eseguire un&#8217;inversione di matrice e confrontare la nostra implementazione con quella fornita dalla libreria SciPy.					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/inversione-della-matrice-algebra-lineare-per-il-deep-learning-parte-3/">Inversione della Matrice &#8211; Algebra Lineare per il Deep Learning (parte 3)</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://datatrading.info/inversione-della-matrice-algebra-lineare-per-il-deep-learning-parte-3/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Algebra delle Matrice &#8211; Algebra Lineare per il Deep Learning (parte 2)</title>
		<link>https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/</link>
					<comments>https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/#respond</comments>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Wed, 03 Jan 2018 20:53:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Deep Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5446</guid>

					<description><![CDATA[<p>Nell&#8217;articolo precedente abbiamo introdotto le tre entità  base usate nell&#8217;algebra lineare, ovvero lo scalare, il vettore e la matrice che sono versioni specifiche di un&#8217;entità più generale, nota come tensore. In questo articolo descriviamo come effettuare operazioni tra queste entità. Tali operazioni includono l&#8217;addizione e la moltiplicazione, le cui regole per le entità vettoriali differiscono leggermente rispetto l&#8217;addizione e &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/"> <span class="screen-reader-text">Algebra delle Matrice &#8211; Algebra Lineare per il Deep Learning (parte 2)</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/">Algebra delle Matrice &#8211; Algebra Lineare per il Deep Learning (parte 2)</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5446" class="elementor elementor-5446">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-0b19bed elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="0b19bed" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-ad6578d" data-id="ad6578d" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-fa0d69a elementor-widget elementor-widget-text-editor" data-id="fa0d69a" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Nell&#8217;articolo <a href="https://datatrading.info/scalari-vettori-matrici-e-tensori-algebra-lineare-per-il-deep-learning-parte-1/">precedente</a> abbiamo introdotto le tre entità  base usate nell&#8217;algebra lineare, ovvero lo <strong>scalare</strong>, il <strong>vettore</strong> e la <strong>matrice</strong> che sono versioni specifiche di un&#8217;entità più generale, nota come <strong>tensore</strong>.</p><p>In questo articolo descriviamo come effettuare <em>operazioni</em> tra queste entità. Tali operazioni includono l&#8217;<strong>addizione</strong> e la <strong>moltiplicazione</strong>, le cui regole per le entità vettoriali differiscono leggermente rispetto l&#8217;addizione e la moltiplicazione scalare. In questo articolo definiamo con precisione tali operazioni e  vediamo alcuni esempi numerici per aiutarci nella spiegazione.</p><p>In questa fase può non essere chiaro il <em>motivo per cui</em> queste operazioni sono utili nel contesto del deep learning. Tuttavia, nell&#8217;articolo precedente abbiamo affermato che l&#8217;algebra lineare è il &#8220;linguaggio in cui è stato scritto  il machine learning&#8221;. Se riusciamo a comprendere le basi del linguaggio, possiamo capire e cogliere molto meglio idee più complesse che costituiscono la spina dorsale dei modelli di rete neurale, descritte negli articoli successivi.</p><p>Iniziamo descrivendo la <strong>somma di matrici</strong> e poi  introduciamo la <strong>moltiplicazione di matrici</strong> . Queste operazioni permettono di discutere un argomento noto come <strong>inversione di matrice</strong>, che fornisce la base del prossimo articolo.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-84c7f7f elementor-widget elementor-widget-text-editor" data-id="84c7f7f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Somma di matrice</h2><p>Cosa significa sommare insieme due matrici? In questa sezione esploriamo tale operazione e vediamo come, in realtà, è abbastanza intuitiva.</p><p>Le matrici possono essere sommate a scalari, vettori e altre matrici. Ognuna di queste operazioni ha una precisa definizione. Queste tecniche sono frequentemente utilizzate nel machine learning e  nel deep learning, quindi è necessario familiarizzare con esse.</p><h4>Addizione matrice-matrice</h4><p>Date due matrici di dimensione \(m \times n\), \(\boldsymbol{A}=[a_{ij}]\) e \(\boldsymbol{B}=[b_{ij}]\), è possibile definire la matrice \(\boldsymbol{C}=[c_{ij}]\) come somma di matrici \(\boldsymbol{C} = \boldsymbol{A} + \boldsymbol{B}\) dove \(c_{ij} = a_{ij} + b_{ij}\).</p><p>In altre parole, ogni elemento di <strong><em>C</em></strong> è la somma degli elementi corrispondenti delle matrici di partenza. Questa operazione è possibile solo quando le due matrici hanno la stessa dimensione, quindi per definizione la dimensione di <strong><em>C</em></strong> è pari a \(m \times n\).</p><p>La somma di matrici è <em>commutativa</em>. cioè il risultato non dipendente dall&#8217;ordine in cui sono sommate aggiunte le matrici:</p><p style="text-align: center;">\(\begin{equation}\boldsymbol{A} + \boldsymbol{B} = \boldsymbol{B} + \boldsymbol{A}\end{equation}\)</p><p>E&#8217; anche <em>associativa</em>, cioè si ottiene lo stesso risultato se si sommano prima due matrici e poi un&#8217;altra, o se si sommassero prima altre due e poi l&#8217;altra:</p><p style="text-align: center;">\(\begin{equation}\boldsymbol{A} + (\boldsymbol{B} + \boldsymbol{C}) = (\boldsymbol{A} + \boldsymbol{B}) + \boldsymbol{C}\end{equation}\)</p><p>Entrambi queste proprietà derivano dalla somma scalare che ha la stessa proprietà commutativa e associativa, dato che stiamo semplicemente sommando insieme gli elementi delle matrici.</p><p>Sottolineiamo queste proprietà della somma di matrici per differenziarla dalla moltiplicazione di matrici (definita di seguito) che è commutativa.</p><p><strong>Esempio</strong><br />Consideriamo due matrici <strong><em>A</em></strong> e <strong><em>B</em></strong>. Possiamo creare una nuova matrice <strong><em>C</em></strong> tramite la somma:</p><p style="text-align: center;">\(\boldsymbol{A} + \boldsymbol{B} = \left[ \begin{array}{ccc}<br />1 &amp; 4 &amp; 17 \\<br />18 &amp; 3 &amp; 2 \\<br />5 &amp; 19 &amp; 1 \\<br />\end{array} \right] +<br />\left[ \begin{array}{ccc}<br />12 &amp; 18 &amp; 6 \\<br />4 &amp; 3 &amp; 33 \\<br />23 &amp; 5 &amp; 8 \\<br />\end{array} \right] =<br />\left[ \begin{array}{ccc}<br />13 &amp; 22 &amp; 23 \\<br />22 &amp; 6 &amp; 35 \\<br />28 &amp; 24 &amp; 9 \\<br />\end{array} \right] =<br />\boldsymbol{C}\)</p><p>È chiaro che gli elementi di <strong><em>C</em></strong> sono semplicemente la somma degli elementi di <strong><em>A</em></strong> e <strong><em>B</em> </strong>nelle posizioni corrispondenti.</p><h4>Somma matrice-scalare</h4><p>È possibile sommare un valore scalare <em>x</em> ad una matrice \(\boldsymbol{A}=[a_{ij}]\) per produrre una nuova matrice \(\boldsymbol{B}=[b_{ij}]\) dove \(b_{ij} = x + a_{ij}\). Questo significa semplicemente che stiamo aggiungendo lo stesso valore scalare a ogni elemento della matrice. È scritto come \(\boldsymbol{B} = x + \boldsymbol{A}\).</p><p>La somma tra uno scalare e una matrice gode delle proprietà commutativa e associativa, dato che la normale somma scalare è sia commutativa che associativa.</p><h4>Trasmissione</h4><p>Per alcune applicazioni di machine learning è possibile definire una notazione abbreviata nota come <strong>broadcasting</strong>. Consideriamo \(\boldsymbol{A} \in \mathbb{R}^{m \times n}\) una matrice di valori reali a \(m \times n\) dimensioni e \(\boldsymbol{x} \in \mathbb{R}^m\) un vettore di <em>m</em> dimensioni.</p><p>È possibile definire \(\boldsymbol{B} = \boldsymbol{A} + \boldsymbol{x}\), nonostante il fatto che la matrice <em><strong>A</strong></em> e il vettore <em><strong>x</strong></em> sono di diverse dimensioni. La somma è definita come \(b_{ij} = a_{ij} + x_j\).</p><p>Cioè, gli elementi di <em>x</em> sono sommati ad ogni riga della matrice. Dal momento che il valore diviene &#8220;trasmesso&#8221; in ogni riga il processo è noto come broadcasting.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-55439b7 elementor-widget elementor-widget-text-editor" data-id="55439b7" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Moltiplicazioni di matrici</h2><p>Le regole per la somma di matrici sono relativamente semplici e intuitive. Tuttavia, quando si tratta di moltiplicare le matrici, le regole diventano più complesse.</p><h4>Matrice trasposta</h4><p>Per definire alcune operazioni di moltiplicazione matrice-matrice come il <strong>prodotto scalare</strong> (discusso di seguito) è necessario definire la <strong>trasposizione</strong> di una matrice. La trasposizione di una matrice \(\boldsymbol{A}=[a_{ij}]_{m \times n}\) di dimensione \(n \times m\) è indicata come \(\boldsymbol{A}^{T}\) di dimensione \(n \times m\) e dal punto di vista degli elementi è definita come:</p><p style="text-align: center;">\(\begin{equation}\boldsymbol{A}^{T} = [a_{ji}]_{n \times m}\end{equation}\)</p><p>Cioè, gli indici <em>i</em> e <em>j</em> sono invertiti. Questo ha l&#8217;effetto di<br />riflettere la matrice lungo la linea degli elementi diagonali. L&#8217;operazione è definita per matrici non quadrate, così come per vettori e scalari (che sono semplicemente matrici 1&#215;1). Per definizione è ovvio che la trasposizione di uno scalare è lo scalre stesso: \(x = x^T\). Inoltre la trasposizione della trasposta di una matrice corrisponde alla matrice stessa: \(\boldsymbol{A}^{TT} = \boldsymbol{A}\).</p><p><strong>Esempi</strong></p><p style="text-align: center;">\(\boldsymbol{A} = \left[ \begin{array}{ccc}<br />a_{11} &amp; a_{12} &amp; a_{13} \\<br />a_{21} &amp; a_{22} &amp; a_{23}<br />\end{array} \right], \quad<br />\boldsymbol{A}^T = \left[ \begin{array}{cc}<br />a_{11} &amp; a_{21} \\<br />a_{12} &amp; a_{22} \\<br />a_{13} &amp; a_{23}<br />\end{array} \right]\)<br />\(\boldsymbol{x} = \left[ \begin{array}{c}<br />x_{1} \\<br />x_{2} \\<br />x_{3}<br />\end{array} \right], \quad<br />\boldsymbol{x}^T = \left[ \begin{array}{ccc}<br />x_{1} &amp; x_{2} &amp; x_3<br />\end{array} \right]\)</p><p>Sottolineiamo che \(\boldsymbol{A}^{T}\) non rappresenta <em>A</em> moltiplicata per se stessa <em>T</em> volte. Questa è un&#8217;operazione completamente diversa. Fortunatamente, di solito risulta chiaro dal contesto se intendiamo la trasposizione di una matrice o la moltiplicazione ripetuta per se stessa.</p><h4>Moltiplicazione matrice-matrice</h4><p>Consideriamo ora la moltiplicazione matrice-matrice. Questa è un&#8217;operazione più complessa della somma di matrici perché non consiste semplicemente nella moltiplicazione elemento per elemento delle matrici. Si usa invece una procedura più complessa, per ogni elemento, che coinvolge un&#8217;intera riga di una matrice e un&#8217;intera colonna dell&#8217;altra.</p><p>L&#8217;operazione è prevista solo per matrici di specifiche dimensioni. La prima matrice deve avere tante colonne quante sono le righe della seconda matrice, altrimenti l&#8217;operazione non è possibile.</p><p>La definizione seguente può essere un po&#8217; difficile da capire inizialmente, quindi consigliamo di leggere attentamente e quindi provare ad applicare la procedura attraverso gli esempi per vedere come le istanze numeriche specifiche corrispondono alla formula generale.</p><p>Data una matrice \(\boldsymbol{A}=[a_{ij}]_{m \times n}\) e una matrice \(\boldsymbol{B}=[b_{ij}]_{n \times p}\) il <strong>prodotto di matrice</strong> \(\boldsymbol{C}=\boldsymbol{A}\boldsymbol{B}=[c_{ij}]_{m \times p}\) è definito elemento per elemento  come:</p><p style="text-align: center;">\(\begin{equation}<br />c_{ij} = \sum^n_{k=1} a_{ik} b_{kj}<br />\end{equation}\)</p><p>In altre parole gli elementi \(c_{ij}\) della matrice \(\boldsymbol{C}=\boldsymbol{A}\boldsymbol{B}\) sono ricavati sommando i prodotti degli elementi dell&#8217;<strong><em>i</em></strong>-esima fila di <strong><em>A </em></strong>con gli elementi della <strong><em>j</em></strong>-esima colonna di <strong><em>B</em></strong>.</p><p>Da notare che la moltiplicazione matrice-matrice non gode della proprietà commutativa, cioè:</p><p style="text-align: center;">\(\begin{eqnarray}<br />\boldsymbol{A}\boldsymbol{B} \neq \boldsymbol{B}\boldsymbol{A}<br />\end{eqnarray}\)</p><p><strong>Esempi</strong></p><p>Date le due matrici seguenti:</p><p style="text-align: center;">\(\boldsymbol{A} = \left[ \begin{array}{ccc}<br />2 &amp; 5 &amp; 1 \\<br />7 &amp; 3 &amp; 6<br />\end{array} \right], \quad<br />\boldsymbol{B} = \left[ \begin{array}{cc}<br />1 &amp; 8 \\<br />9 &amp; 4 \\<br />3 &amp; 5<br />\end{array} \right]\)</p><p>È possibile costruire il prodotto <strong><em>AB</em></strong> di dimensione 2&#215;2:</p><p style="text-align: center;">\(\boldsymbol{AB} = \left[ \begin{array}{cc}<br />2 \cdot 1 + 5 \cdot 9 + 1 \cdot 3 &amp; 2 \cdot 8 + 5 \cdot 4 + 1 \cdot 5 \\<br />7 \cdot 1 + 3 \cdot 9 + 6 \cdot 3 &amp; 7 \cdot 8 + 3 \cdot 4 + 6 \cdot 5<br />\end{array} \right] =<br />\left[ \begin{array}{cc}<br />50 &amp; 41 \\<br />52 &amp; 98<br />\end{array} \right]\)</p><p>È anche possibile costruire il prodotto <em><strong>BA</strong></em> di dimensione 3&#215;3:</p><p style="text-align: center;">\(\boldsymbol{BA} = \left[ \begin{array}{ccc}<br />1 \cdot 2 + 8 \cdot 7 &amp; 1 \cdot 5 + 8 \cdot 3 &amp; 1 \cdot 1 + 8 \cdot 6 \\<br />9 \cdot 2 + 4 \cdot 7 &amp; 9 \cdot 5 + 4 \cdot 3 &amp; 9 \cdot 1 + 4 \cdot 6 \\<br />3 \cdot 2 + 5 \cdot 7 &amp; 3 \cdot 5 + 5 \cdot 3 &amp; 3 \cdot 1 + 5 \cdot 6 \\<br />\end{array} \right] =<br />\left[ \begin{array}{ccc}<br />58 &amp; 29 &amp; 49 \\<br />46 &amp; 57 &amp; 33 \\<br />41 &amp; 30 &amp; 33<br />\end{array} \right]\)</p><p>La definizione di cui sopra inizialmente non sembra essere definita in modo semplice. La moltiplicazione matrice-matrice è definita in questo modo perchè coinvolge matrici che rappresentano funzioni <a href="https://en.wikipedia.org/wiki/Linear_map" target="_blank" rel="noopener">di mappa lineare</a> tra due spazi vettoriali. Non dobbiamo preoccuparci dei concetti relativi alle mappe lineari poiché esulano dallo scopo di questa serie di articoli.</p><p>Tuttavia, possiamo fornire brevemente alcune definizioni attraverso l&#8217;idea di <em>comporre</em> insieme le funzioni. In matematica è possibile comporre insieme due funzioni e produrre una nuova funzione. la nuova funzione <em>h</em> può essere definita come \(h = f \circ g\), dove il simbolo \(\circ\) rappresenta la composizione delle funzioni. Questa notazione significa che <em>h</em> è l&#8217;applicazione di <em>g</em> e poi l&#8217;applicazione di <em>f</em> al risultato.</p><p>Se, per esempio, \(f=sin(x)\) e \(g=x^2\) allora \(h = sin(x^2)\). La composizione delle funzioni non è commutativa quindi \(f \circ g \neq g \circ f\) quindi \(g \circ f = sin^2 (x) è una funzione completamente diversa. Questo è il motivo per cui la moltiplicazione matrice-matrice non è commutativa e anche perché è definita come sopra.</p><p>Si noti inoltre che questa definizione non implica che gli elementi della matrice <em>A</em> sono definiti come la moltiplicazione elemento per elemento di quelli di <em>A</em> e <em>B,</em> cioè gli elementi in ogni posizione non possono essere semplicemente moltiplicati insieme per ottenere la nuova matrice del prodotto. Questa è un&#8217;operazione completamente diversa nota come <strong>Prodotto Hadamard</strong> che è descritta nei paragrafi successivi.</p><p>Dato che un vettore colonna è una matrice <em>n x 1</em> allora è possibile effettuare la moltiplicazione matrice-vettore. Se la matrice di moltiplicazione a sinistra ha dimensione <em>m x n</em> allora questa è un&#8217;operazione valida che produce un&#8217;altra matrice <em>m x 1</em> (vettore colonna) come output.</p><p><span class="">La moltiplicazione matrice-matrice e vettore-matrice sono operazioni estremamente comuni nei campi delle scienze fisiche, della grafica computazionale e del machine learning. Sono state sviluppate</span> librerie software altamente ottimizzate come <a href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms" target="_blank" rel="noopener">BLAS</a> e <a href="https://en.wikipedia.org/wiki/LAPACK" target="_blank" rel="noopener">LAPACK</a>  per consentire un efficiente calcolo scientifico, in particolare con le <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" target="_blank" rel="noopener">GPU</a>.</p><h4>Moltiplicazione matrice-scalare</h4><p>La moltiplicazione matrice-scalare è più semplice rispetto alla moltiplicazione tra matrici. Data una matrice \(\)\boldsymbol{A}=[a_{ij}]_{m \times n} e uno scalare \(\)\lambda \in \mathbb{R}\) il prodotto a matrice scalare \(\lambda \boldsymbol{A}\) si calcola moltiplicando ogni elemento di \(\boldsymbol{A}\) per \(\lambda\) tale che \(\lambda \boldsymbol{A} = [\lambda a_{ij}]_{m \times n}\)</p><p>Se consideriamo due scalari a valori reali \(\lambda, \mu \in \mathbb{R}\) allora dalle definizione derivano le seguenti relazioni:</p><p style="text-align: center;">\(\begin{eqnarray}<br />\lambda (\boldsymbol{A} + \boldsymbol{B}) &amp;=&amp; \lambda \boldsymbol{A} + \lambda \boldsymbol{B} \\<br />(\lambda + \mu) \boldsymbol{A} &amp;=&amp; \lambda \boldsymbol{A} + \mu \boldsymbol{A} \\<br />\lambda (\mu \boldsymbol{A}) &amp;=&amp; (\lambda \mu) \boldsymbol{A}<br />\end{eqnarray}\)</p><p>La prima relazione afferma che la somma di due matrici moltiplicata per uno scale corrisponde alla moltiplicazione individuale di ciascuna matrice per lo scalare e poi sommate insieme.</p><p>La seconda relazione afferma che la somma di due scalari moltiplicata per una matrice corrisponde alla somma dei risultati delle singole moltiplicazioni dei due scalari per la matrice.</p><p>La terza relazione afferma che l&#8217;ordine della moltiplicazione scalare non ha importanza. Se moltiplichiamo la matrice per uno scalare e quindi moltiplichiamo il risultato per un altro scalare, corrisponde alla moltiplicazione di entrambi gli scalari e poi per la matrice.</p><p>Tutti questi risultati derivano dalle semplici regole di moltiplicazione e addizione scalare.</p><h4>Prodotto Hadamard</h4><p>È possibile definire la moltiplicazione di matrici elemento per elemento, che differisce dalla definizione di moltiplicazione matrice-matrice sopra. Il <strong>prodotto di Hadamard</strong> di due matrici \(\boldsymbol{A}=[a_{ij}]_{m \times n}\) e \(\boldsymbol{B}=[b_{ij}]_{m \times n}\), indicato come \(\boldsymbol{A} \odot \boldsymbol{B}\), è definito dalla seguente espressione:</p><p style="text-align: center;">\(\begin{equation}<br />\boldsymbol{A} \odot \boldsymbol{B} = [a_{ij} b_{ij}]_{m \times n}<br />\end{equation}\)</p><p>Cioè, gli elementi della nuova matrice sono calcolati semplicemente come moltiplicazione scalare di ciascuno degli elementi delle matrici. Da notare che il prodotto di Hadamard gode della proprietà commutativa, dato che è anche la moltiplicazione scalare, a differenza della normale moltiplicazione matrice-matrice.</p><p>Quando è necessario utilizzare il prodotto Hadamard? In effetti, un tale operatore ha ampie applicazioni, tra cui la correzione dei codici nelle trasmissioni satellitari e nella crittografia, l&#8217;elaborazione dei segnali e gli algoritmi di compressione con perdita di immagini in formato JPEG.</p><h4>Prodotto scalare</h4><p>Un particolare caso di moltiplicazione matrice-matrice da sottolineare si verifica tra due vettori ed è noto come <strong>prodotto scalare</strong>. Ha una profonda relazione con la geometria ed è utile in tutte le aree delle scienze fisiche e computazionali.</p><p>Dobbiamo essere estremamente attenti per quanto riguarda la notazione. Dobbiamo essere particolarmente precisi per questa definizione, che per alcuni di voi potrebbe essere insolita. In realtà il prodotto scalare è definito come una particolare moltiplicazione matrice-matrice, dove uno dei vettori è una &#8220;matrice&#8221; con una riga e l&#8217;altro una &#8220;matrice&#8221; con una colonna. Tuttavia, spesso si ha un leggero &#8220;abuso di notazione&#8221; per cui si definisce il prodotto scalare per due vettori qualsiasi (riga o colonna).</p><p>La definizione standard di un prodotto scalare tra due vettori \(\boldsymbol{x}, \boldsymbol{y} \in \mathbb{R}^n\) di <em>n</em> dimensioni è \(\boldsymbol{x} \cdot \boldsymbol{y}\), da cui deriva il nome dell&#8217;operazione. Tuttavia nei libri di testo più avanzati (in particolare i popolari testi di statistica, machine learning e deep learning) è definito come \(\boldsymbol{x}^T \boldsymbol{y}\) dove <strong><em>T</em></strong> rappresenta la trasposizione di <strong><em>x</em></strong>.</p><p>Questo perché <em><strong>x </strong></em>e <em><strong>y </strong></em>sono generalmente considerati entrambi vettori <em>colonna</em>. Una moltiplicazione matrice-matrice tra due vettori colonna non è definita, quindi uno dei vettori deve essere trasposto in un vettore riga in modo tale che la moltiplicazione matrice-matrice sia correttamente definita. La notazione \(\boldsymbol{x}^T \boldsymbol{y}\) è frequentemente usata nei libri accademici e articoli più avanzati. Vediamo ora i dettagli della definizione!</p><p>Dati due vettori <em>colonna</em> \(\boldsymbol{x}, \boldsymbol{y} \in \mathbb{R}^n\) è possibile definire il <strong>prodotto scalare</strong> tra di loro prendendo la trasposizione di uno per formare un prodotto che è definito all&#8217;interno delle regole di moltiplicazione matrice-matrice. Tale prodotto produce un valore scalare che gode della proprietà commutativa:</p><p style="text-align: center;">\(\begin{equation}<br />\boldsymbol{x}^T \boldsymbol{y} = \sum^n_{i=1} x_i y_i = \boldsymbol{y}^T \boldsymbol{x}<br />\end{equation}\)</p><p>Il prodotto scalare ha un importante significato geometrico. È il prodotto delle <a href="https://en.wikipedia.org/wiki/Euclidean_distance" target="_blank" rel="noopener">distanze euclidee</a> dei due vettori e del coseno dell&#8217;angolo tra di loro. Negli articoli successivi introduciamo il concetto di <strong>norma</strong>, dove formalizziamo la definizione.</p><p>Un altro modo di pensare al prodotto scalare è considerare il prodotto scalare di un vettore con se stesso come il quadrato della distanza del vettore:</p><p style="text-align: center;">\(\begin{equation}<br />\boldsymbol{x}^T \boldsymbol{x} = \sum^n_{i=1} x_i x_i = \sum^n_{i=1} x_i^2<br />\end{equation}\)</p><p>Quindi per trovare la distanza (euclidea) di un vettore possiamo semplicemente prendere la radice quadrata del prodotto scalare del vettore, \(\sqrt{\boldsymbol{x}^T \boldsymbol{x}}\).</p><p><em>Il prodotto scalare è un caso particolare di un&#8217;entità matematica più generale nota come <strong>prodotto interno</strong>. In spazi vettoriali più astratti il prodotto interno consente di rendere rigorosi concetti intuitivi come la lunghezza e l&#8217;angolo di un vettore. Tuttavia, tali spazi esulano dallo scopo di questa serie di articoli.</em></p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-4aacc25 elementor-widget elementor-widget-text-editor" data-id="4aacc25" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Prossimi passi</h2><p>Questo articolo è stato interamente dedicato alle operazioni applicate a una o più matrici. Possiamo ora sommare e moltiplicare matrici tra di loro. Ma cosa otteniamo con questo? Come possiamo usarlo?</p><p>Nel prossimo articolo esaminiamo uno degli argomenti più fondamentali dell&#8217;algebra lineare: l&#8217;inversione di una matrice. L&#8217;inversione di matrice ci consente di risolvere equazioni di matrici, esattamente nello stesso modo in cui l&#8217;algebra scalare ci consente di risolvere equazioni scalari.</p><p>Questa è un&#8217;operazione molto diffusa nelle scienze fisiche e computazionali ed è indispensabile negli studi di deep learning.</p><h2>Riferimenti</h2><ul><li>[1] Blyth, T.S. and Robertson, E.F. (2002) <em>Basic Linear Algebra, 2nd Ed.</em>, Springer</li><li>[2] Strang, G. (2016) <em>Introduction to Linear Algebra, 5th Ed.</em>, Wellesley-Cambridge Press</li><li><a href="http://www.deeplearningbook.org/" name="ref-goodfellow2016">[3] Goodfellow, I.J., Bengio, Y., Courville, A. (2016) <em>Deep Learning</em>, MIT Press</a></li></ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/">Algebra delle Matrice &#8211; Algebra Lineare per il Deep Learning (parte 2)</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://datatrading.info/algebra-delle-matrice-algebra-lineare-per-il-deep-learning-parte-2/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Scalari, Vettori, Matrici e Tensori &#8211; Algebra Lineare per il Deep Learning (parte 1)</title>
		<link>https://datatrading.info/scalari-vettori-matrici-e-tensori-algebra-lineare-per-il-deep-learning-parte-1/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Thu, 28 Dec 2017 14:48:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Deep Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5405</guid>

					<description><![CDATA[<p>Poiché il deep learning è un argomento importante per il machine learning applicato al trading pensiamo sia opportuno scrivere alcuni articoli che introduco i concetti matematici fondamentali &#8211; algebra lineare, calcolo e probabilità &#8211; che sono necessari per comprendere davvero il deep learning per il trading quantitativo. Questo articolo è il primo di una serie &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/scalari-vettori-matrici-e-tensori-algebra-lineare-per-il-deep-learning-parte-1/"> <span class="screen-reader-text">Scalari, Vettori, Matrici e Tensori &#8211; Algebra Lineare per il Deep Learning (parte 1)</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/scalari-vettori-matrici-e-tensori-algebra-lineare-per-il-deep-learning-parte-1/">Scalari, Vettori, Matrici e Tensori &#8211; Algebra Lineare per il Deep Learning (parte 1)</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5405" class="elementor elementor-5405">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-b2b8611 elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="b2b8611" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-b5c5d2e" data-id="b5c5d2e" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-d709869 elementor-widget elementor-widget-text-editor" data-id="d709869" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Poiché il <a href="https://datatrading.info/cose-il-deep-learning/">deep learning</a> è un argomento importante per il machine learning applicato al trading pensiamo sia opportuno scrivere alcuni articoli che introduco i concetti matematici fondamentali &#8211; algebra lineare, calcolo e probabilità &#8211; che sono necessari per comprendere <em>davvero</em> il deep learning per il trading quantitativo.</p><p>Questo articolo è il primo di una serie di post sull&#8217;argomento <strong>Algebra lineare per il Deep Learning</strong>. Ha lo scopo di descrivere alcune delle idee e delle nozioni di base che si troveranno nei libri di testo e nei documenti di ricerca di deep learning più avanzati. Leggere questi documenti è <em>assolutamente fondamentale</em> per trovare i <strong>migliori metodi di trading quantitativo</strong> e come tale aiuta a capire questi approcci!</p><p>L&#8217;algebra lineare è un argomento fondamentale nella matematica ed è estremamente usata nelle scienze fisiche. Costituisce anche la spina dorsale di molti algoritmi di machine learning. E&#8217; quindi fondamentale che il professionista di deep learning comprenda questi concetti fondamentali. E&#8217; <span style="font-size: 15px;">una branca della matematica </span><a style="font-size: 15px; background-color: #ffffff;" href="https://en.wikipedia.org/wiki/Continuous_function" target="_blank" rel="noopener">continua</a><span style="font-size: 15px;">, invece che </span><a style="font-size: 15px; background-color: #ffffff;" href="https://en.wikipedia.org/wiki/Discrete_mathematics" target="_blank" rel="noopener">discreta</a><span style="font-size: 15px;">. </span></p><p><span style="font-size: 15px;">Il matematico, il fisico, l&#8217;ingegnere e il quant hanno probabilmente familiarità con la matematica continua attraverso lo studio delle </span><a style="font-size: 15px; background-color: #ffffff;" href="https://en.wikipedia.org/wiki/Differential_equation" target="_blank" rel="noopener">equazioni differenziali</a><span style="font-size: 15px;">, che sono utilizzate per modellare molti fenomeni fisici e finanziari.</span></p><p>L&#8217;informatico, lo sviluppatore di software o il trader discrezionale retail, tuttavia, potrebbero aver studiato solamente i concetti matematici relativi alla<a href="https://en.wikipedia.org/wiki/Graph_theory" target="_blank" rel="noopener"> teoria dei grafi</a> o alla <a href="https://en.wikipedia.org/wiki/Combinatorics" target="_blank" rel="noopener">combinatoria</a>, argomenti che fanno parte della matematica discreta. Quindi le notazioni di <em>insiemi</em> e <em>funzioni</em> presentate in questo articolo potrebbero essere inizialmente sconosciute.</p><p>Per questo motivo la discussione presentata in questa serie di articoli omette il consueto approccio &#8220;teorema e dimostrazione&#8221; di un libro di testo di matematica universitaria. Ci concentriamo invece su argomenti specifici ed importanti per i professionisti del deep learning di diversa estrazione.</p><p><em>Da notare che la descrizione dell&#8217;algebra lineare presentata in questa serie di articoli segue da vicino le notazioni trattati nei lavori di Goodfellow et al (2016) [3], Blyth e Robertson (2002) [1], e Strang (2016) [2].</em></p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-7fc7e4d elementor-widget elementor-widget-text-editor" data-id="7fc7e4d" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Motivazione</h2>
<p>La probabilità, il calcolo e l&#8217;algebra lineare sono i &#8220;linguaggi&#8221; in cui viene scritto il machine learning. Lo studio di questi argomenti fornisce una comprensione più profonda della meccanica algoritmica sottostante e consente lo sviluppo di nuovi algoritmi, che possono essere implementati in strategie di trading quantitativo più sofisticate.</p>
<p>Molti algoritmi di&nbsp;<a href="https://datatrading.info/guida-introduttiva-al-machine-learning-statistico/">machine learning</a> supervisionato e <a href="https://datatrading.info/cose-il-deep-learning/">deep learning</a> prevedono l&#8217;ottimizzazione di una <a href="https://en.wikipedia.org/wiki/Loss_function" target="_blank" rel="noopener">funzione&nbsp; obiettivo</a> attraverso la modifica dei parametri del modello. A tale scopo è necessario conoscere come la funzione obiettivo cambia al variare dei parametri del modello.</p>
<p>Questo motiva immediatamente il calcolo, l&#8217;argomento elementare in matematica che descrive i cambiamenti di quantità rispetto a un altro.&nbsp;In particolare richiede il concetto di&nbsp;<a href="https://en.wikipedia.org/wiki/Partial_derivative" target="_blank" rel="noopener">derivata parziale</a>, che descrive come la funzione obiettivo viene alterata attraverso singole modifiche di ogni parametro.</p>
<p>Le derivate parziali sono spesso raggruppate insieme, in matrici, per consentire un calcolo più semplice. Anche i modelli di machine learning più elementari come la <a href="https://datatrading.info/metodo-della-massima-verosimiglianza-per-la-regressione-lineare/" target="_blank" rel="noopener">regressione lineare</a>&nbsp;sono ottimizzati con queste tecniche di algebra lineare.</p>
<p>Un argomento chiave nell&#8217;algebra lineare è la <em>notazione</em> di vettore e&nbsp; di matrice. Essere in grado di &#8220;leggere il linguaggio&#8221; dell&#8217;algebra lineare aprirà la capacità di comprendere libri di testo, articoli web e documenti di ricerca che contengono descrizioni di modelli più complesse. Questo non solo consente la riproduzione e la verifica dei modelli esistenti, ma consente estensioni e nuovi sviluppi che possono essere&nbsp; successivamente implementati nelle strategie di trading.</p>
<p>L&#8217;algebra lineare fornisce i primi passi nella&nbsp;<em>vettorizzazione</em>, presentando un modo più&nbsp; preciso per descrivere la parallelizzazione di determinate operazioni. Gli algoritmi scritti nella notazione standard &#8220;for-loop&#8221; possono essere riformulati come equazioni di matrici con notevoli guadagni in termini di efficienza computazionale.</p>
<p>Tali metodi sono utilizzati nelle principali librerie Python come NumPy, SciPy, Scikit-Learn, Pandas e Tensorflow. Le GPU sono state progettate per eseguire operazioni ottimizzate di algebra lineare. L&#8217;esplosiva crescita del deep learning può essere in parte attribuita alla natura ad elevato parallelismo degli algoritmi sottostanti l&#8217;hardware delle GPU.</p>
<p>Nonostante l&#8217;algebra lineare sia una branca della matematica continua, le entità descritte di seguito sono implementate in un ambiente computazionale discreto. Queste rappresentazioni discrete di entità di algebra lineare possono portare a problemi di <a href="https://en.wikipedia.org/wiki/Integer_overflow" target="_blank" rel="noopener">overflow</a>&nbsp;e&nbsp;<a href="https://en.wikipedia.org/wiki/Arithmetic_underflow" target="_blank" rel="noopener">underflow</a>, che rappresentano i limiti della rappresentazione computazionale in modo efficace di numeri estremamente grandi e piccoli.</p>
<p>Un meccanismo per mitigare gli effetti della limitata rappresentazione numerica consiste nell&#8217;utilizzare le tecniche di <a href="https://en.wikipedia.org/wiki/Matrix_decomposition" target="_blank" rel="noopener">decomposizione delle matrici</a>. Tali tecniche consentono di rappresentare alcuni tipi di matrici con matrici più semplici e strutturate che hanno utili proprietà computazionali.</p>
<p>Le tecniche di decomposizione della matrice includono la decomposizione&nbsp;<a href="https://en.wikipedia.org/wiki/LU_decomposition" target="_blank" rel="noopener">Lower Upper (LU)</a>, la decomposizione&nbsp;<a href="https://www.quantstart.com/articles/QR-Decomposition-with-Python-and-NumPy" target="_blank" rel="noopener">QR</a> e la decomposizione <a href="https://en.wikipedia.org/wiki/Singular_value_decomposition" target="_blank" rel="noopener">Singular Value (SVD)</a>. Sono una componente intrinseca di alcuni algoritmi di machine learning, inclusi i <a href="https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)" target="_blank" rel="noopener">minimi quadrati lineari</a>&nbsp;e&nbsp;<a href="https://en.wikipedia.org/wiki/Principal_component_analysis" target="_blank" rel="noopener">l&#8217;analisi dei componenti principali (PCA)</a>. La decomposizione di una matrice&nbsp; è descritta in dettaglio in questa serie.</p>
<p><em>Non si può sottovalutare quanto sia fondamentale l&#8217;algebra lineare per il deep learning</em>.&nbsp;Per coloro che mirano a implementare i modelli quantitativi più sofisticati basati su tecniche di deep learning, o cercano lavoro in aziende che lo sono, sarà necessario apprendere estremamente bene l&#8217;algebra lineare.</p>
<p>Il materiale di questa serie di articoli descrive il minimo indispensabile, ma per comprendere la frontiera della ricerca è necessario andare molto oltre. Nei riferimenti alla fine dell&#8217;articolo è disponibile un breve elenco delle risorse dove continuare a studiare l&#8217;algebra lineare.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e005b67 elementor-widget elementor-widget-text-editor" data-id="e005b67" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Vettori e matrici</h2><p>Le due entità matematiche  fondamentali dell&#8217;algebra lineare sono il <strong>vettore</strong> e la <strong>matrice</strong>. Sono esempi di un&#8217;entità più generale nota come <strong>tensore</strong>. I tensori possiedono un <em>ordine</em> (o <em>rank</em>), che determina il numero di dimensioni in un array necessarie per rappresentarlo.</p><h4>Scalari</h4><p><strong>Gli scalari</strong> sono numeri singoli e sono un esempio di tensore di ordine 0. In matematica è necessario descrivere l&#8217;insieme di valori a cui appartiene uno scalare. La notazione \(x \in \mathbb{R}\) afferma che il valore scalare (minuscolo). <em>x </em>è un elemento (o un membro) dell&#8217;insieme dei numeri a valori reali, \(\mathbb{R}\).</p><p>Esistono vari insiemi di numeri di interesse all&#8217;interno del machine learning. \(\mathbb{N}\) rappresenta l&#8217;insieme degli interi positivi (\(1, 2, 3,\ldots\)). \(\mathbb{Z}\) rappresenta gli interi, che includono valori positivi, negativi e lo zero. \(\mathbb{Q}\) rappresenta l&#8217;insieme dei numeri razionali, cioè che possono essere espressi come una frazione di due interi.</p><h4>Vettori</h4><p><strong>I vettori</strong> sono matrici ordinate di numeri singoli e sono un esempio di tensore del 1° ordine. I vettori sono membri di oggetti noti <strong>spazi vettoriali</strong>. Uno spazio vettoriale può essere considerato come l&#8217;intera raccolta di <em>tutti i</em> possibili vettori di una specifica lunghezza (o dimensione). Lo spazio vettoriale tridimensionale a valori reali, indicato da \(\mathbb{R}^3\) è spesso usato per rappresentare matematicamente la nostra nozione del mondo reale di spazio tridimensionale.</p><p>Più formalmente uno spazio vettoriale è un <a href="https://en.wikipedia.org/wiki/Cartesian_product" target="_blank" rel="noopener">prodotto cartesiano</a> <em>n</em>-dimensionale di un dataset con se stesso, insieme a definizioni appropriate su come aggiungere vettori e moltiplicarli per valori scalari. Se tutti gli scalari in un vettore sono a valori reali, allora la notazione \(\boldsymbol{x} \in \mathbb{R}^n\) afferma che il valore del vettore (in grassetto minuscolo) <em>x </em>è un membro dello spazio vettoriale  a <em>n-</em>dimensioni dei numeri reali, \(\mathbb{R}^n\).</p><p>A volte è necessario identificare in modo esplicito i <em>componenti</em> di un vettore. L&#8217;<em>i</em>-esimo elemento scalare di un vettore è scritto come \(x_i\). Da notare che è scritto in minuscolo e senza grassetto poiché l&#8217;elemento è uno scalare. Un vettore a <em>n </em>dimensioni può essere scritto esplicitamente usando la seguente notazione:</p><p style="text-align: center;">\(\begin{equation}\boldsymbol{x}=\begin{bmatrix}<br />\kern4pt x_1 \kern4pt \\<br />\kern4pt x_2 \kern4pt \\<br />\kern4pt \vdots \kern4pt \\<br />\kern4pt x_n \kern4pt<br />\end{bmatrix}\end{equation}\)</p><p>Dato che gli scalari esistono per rappresentare i valori, perché sono necessari i vettori? I vettori sono usati principalmente per rappresentare quantità fisiche che hanno sia una <em>magnitudine</em> (grandezza) che una <em>direzione</em>. Gli scalari sono in grado di rappresentare solo le grandezze.</p><p>Ad esempio scalari e vettori codificano la differenza tra la velocità di un&#8217;auto e la sua velocità direzionale. La velocità direzionale contiene non il valore scalare (la velocità) ma anche la direzione di marcia. Non è difficile immaginare molte più grandezze fisiche che possiedono caratteristiche simili come le forze gravitazionali ed elettromagnetiche o la velocità del vento.</p><p>Nel machine learning i vettori  sono usati per rappresentare insiemi di feature, con i loro singoli componenti che specificano l&#8217;importanza di una particolare feature. Tali feature potrebbero includere l&#8217;importanza relativa delle parole in un documento di testo, l&#8217;intensità di un insieme di pixel in un&#8217;immagine bidimensionale o i valori storici dei prezzi per una selezione di strumenti finanziari.</p><h4>Matrici</h4><p>Le <strong>matrici</strong> sono array rettangolari costituiti da numeri e sono un esempio di tensori del 2° ordine. Se <em>m</em> e <em>n </em>sono numeri interi positivi, cioè \(m,n \in \mathbb{N}\), allora la matrice \(m \times n\) contiene <em>n*m</em> numeri, con <em>m</em> righe e <em>n</em> colonne.</p><p>Se tutti gli scalari in una matrice sono a valori reali, allora una matrice è indicata con lettere maiuscole in grassetto, come \(\boldsymbol{A} \in \mathbb{R}^{m \times n}\). Cioè la matrice vive in spazio vettoriale di \(m \times n\) dimensioni di valori reali. Quindi le matrici sono in realtà vettori che vengono semplicemente scritti in modo simile a una tabella bidimensionale.</p><p>Le sue componenti sono identificati da due indici <em>i</em> e <em>j</em>. <em>i </em>rappresenta l&#8217;indice della riga della matrice, mentre <em>j</em> rappresenta l&#8217;indice della colonna della matrice. Ogni componente di <strong>A</strong> è identificato da \(a_{ij}\).</p><p>La matrice totale \(m \times n\) può essere scritta come:</p><p style="text-align: center;">\(\begin{equation}\boldsymbol{A}=\begin{bmatrix}<br />\kern4pt a_{11} &amp; a_{12} &amp; a_{13} &amp; \ldots &amp; a_{1n} \kern4pt \\<br />\kern4pt a_{21} &amp; a_{22} &amp; a_{23} &amp; \ldots &amp; a_{2n} \kern4pt \\<br />\kern4pt a_{31} &amp; a_{32} &amp; a_{33} &amp; \ldots &amp; a_{3n} \kern4pt \\<br />\kern4pt \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \kern4pt \\<br />\kern4pt a_{m1} &amp; a_{m2} &amp; a_{m3} &amp; \ldots &amp; a_{mn} \kern4pt \\<br />\end{bmatrix}\end{equation}\)</p><p>Spesso è utile abbreviare la visualizzazione completa delle componenti della matrice con la seguente espressione:</p><p style="text-align: center;">\(\begin{equation}\boldsymbol{A} = [a_{ij}]_{m \times n}\end{equation}\)</p><p>Dove \(a_{ij}\) è indicato come l&#8217;\((i,j)\)-esimo elemento della matrice <strong>A</strong>. Il pedice \(m \times n\) può essere eliminato se la dimensione della matrice è chiara dal contesto.</p><p>Da notare che un vettore colonna è una mattrice di  dimensione \(m \times 1\), poiché ha <em>m </em>righe e <em>1</em> colonna. Salvo diversa indicazione, tutti i vettori saranno considerati vettori colonna.</p><p>Le matrici rappresentano un tipo di funzione nota come <a href="https://en.wikipedia.org/wiki/Linear_map" target="_blank" rel="noopener">mappa lineare</a>. Sulla base di regole che sono descritte negli articoli successivi, è possibile definire operazioni di moltiplicazione tra matrici o tra matrici e vettori. Tali operazioni sono estremamente importanti nelle scienze fisiche, nella finanza quantitativa, nell&#8217;informatica e nel machine learning.</p><p>Le matrici possono codificare operazioni geometriche come rotazione, riflessione e trasformazione. Pertanto, se una collezione di vettori rappresenta i vertici di un modello geometrico tridimensionale in un software CAD (<a href="https://en.wikipedia.org/wiki/Linear_map" target="_blank" rel="noopener">Computer Aided Design</a>), moltiplicando individualmente questi vettori con una predefinita <a href="https://en.wikipedia.org/wiki/Transformation_matrix">matrice di  trasformazione</a> produce nuovi vettori che rappresentano le posizioni dei vertici ruotati. Questa è la base della moderna computer grafica 3D.</p><p>Nel deep learning i pesi della rete neurale sono memorizzati come matrici, mentre gli input delle feature sono memorizzati come vettori. Formulare il problema in termini di algebra lineare consente una gestione compatta di questi calcoli. Descrivendo il problema in termini di tensori e utilizzando i  metodi dell&#8217;algebra lineare, è possibile ottenere l&#8217;addestramento in tempi rapidi  con l&#8217;hardware delle moderne GPU.</p><h4>Tensori</h4><p>Il tensore è un&#8217;entità più generale che racchiude lo scalare, il vettore e la matrice. A volte è necessario, sia nelle scienze fisiche che nel machine learning, utilizzare i tensori con ordine superiore a due.</p><p>In fisica teorica, e in particolare nella relatività generale, il tensore di <a href="https://en.wikipedia.org/wiki/Riemann_curvature_tensor" target="_blank" rel="noopener">curvatura di Riemann</a> è un tensore di 4° ordine che descrive la curvatura locale dello <a href="https://en.wikipedia.org/wiki/Spacetime" target="_blank" rel="noopener">spaziotempo</a>. Nel machine learning, e in particolare nel deep learning, si può usare un tensore di 3° ordine per descrivere i valori di intensità a più canali (rosso, verde e blu) di un&#8217;immagine bidimensionale.</p><p>In questa serie di post i tensori sono identificati tramite la notazione sans-serif in grassetto, <strong>A</strong>. Per un tensore di 3° ordine gli elementi saranno dati da \(a_{ijk}\), mentre per un tensore di 4° ordine gli elementi saranno dati da \(a_{ijkl}\).</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-886256b elementor-widget elementor-widget-text-editor" data-id="886256b" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Prossimi passi</h2><p>Nel prossimo articolo sono illustrate le operazioni di base della moltiplicazione matrice-vettore e matrice-matrice. Questo argomento è noto come <strong>algebra delle matrici</strong>.</p><h2>Riferimenti</h2><ul><li>[1] Blyth, T.S. and Robertson, E.F. (2002) <em>Basic Linear Algebra, 2nd Ed.</em>, Springer</li><li>[2] Strang, G. (2016) <em>Introduction to Linear Algebra, 5th Ed.</em>, Wellesley-Cambridge Press</li><li><a href="http://www.deeplearningbook.org/" target="_blank" rel="noopener" name="ref-goodfellow2016">[3] Goodfellow, I.J., Bengio, Y., Courville, A. (2016) <em>Deep Learning</em>, MIT Press</a></li></ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/scalari-vettori-matrici-e-tensori-algebra-lineare-per-il-deep-learning-parte-1/">Scalari, Vettori, Matrici e Tensori &#8211; Algebra Lineare per il Deep Learning (parte 1)</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Cos&#8217;è il Deep Learning?</title>
		<link>https://datatrading.info/cose-il-deep-learning/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Sat, 23 Dec 2017 07:08:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Deep Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5043</guid>

					<description><![CDATA[<p>Nell&#8217;articolo precedente di questa serie abbiamo descritto un approccio deep learning con la libreria Theano di Python tramite un esempio di regressione logistica. Con questo articolo vogliamo fornire una descrizione più approfondita dei concetti fondamentali del deep learning. Al giorno d&#8217;oggi è quasi impossibile lavorare in qualsiasi campo ad alto contenuto tecnologico senza conoscere gli &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/cose-il-deep-learning/"> <span class="screen-reader-text">Cos&#8217;è il Deep Learning?</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/cose-il-deep-learning/">Cos&#8217;è il Deep Learning?</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5043" class="elementor elementor-5043">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-b1afdeb elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="b1afdeb" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-30b2eb2" data-id="30b2eb2" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-17abdae elementor-widget elementor-widget-text-editor" data-id="17abdae" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Nell&#8217;articolo precedente di questa serie abbiamo descritto un approccio deep learning con la libreria Theano di Python tramite un esempio di regressione logistica. Con questo articolo vogliamo fornire una descrizione più approfondita dei concetti fondamentali del deep learning.</p><p>Al giorno d&#8217;oggi è quasi impossibile lavorare in qualsiasi campo ad alto contenuto tecnologico senza conoscere gli ultimi progressi nel campo del deep learning. La finanza quantitativa non è da meno. Molti degli speech presente nelle recenti conferenze sulla finanza quantitativa come QuantCon di Quantopian e AI &amp; Data Science &#8211; Capital Markets di Newsweek si concentrano principalmente sul deep learning come prossima frontiera nel trading quantitativo.</p><p>Sfortunatamente il deep learning ha la reputazione di essere difficile, sempre in rapida evoluzione e impenetrabile senza un dottorato di ricerca in neuroscienze computazionali. Questo in effetti potrebbe essere stato  vero cinque anni fa, ma i recenti progressi delle librerie open source e la grande disponibilità di hardware ad elevato parallelismo permettono anche a coloro che sono dotati solo di una conoscenza di base della programmazione di usare tecniche avanzate di deep learning.</p><p>Questa serie di articoli sul deep learning vuole fornire una guida ai trader che sono completamente neofiti di questa tecnica. Vuole portare un assoluto principiante di deep learning a poter svolgere autonomamente la propria ricerca di deep learning per scopi di trading quantitativo.</p><p>In questo articolo forniamo un&#8217;introduzione al deep learning. Descriviamo i concetti di rappresentazione e di apprendimento gerarchico delle feature. Successivamente prendiamo in considerazione l&#8217;applicazione del deep learning nel trading quantitativo e se otteniamo qualche vantaggio.</p><h2>Introduzione al Deep Learning:</h2><p>Il deep learning è un sottoinsieme del più ampio campo del machine leaning (Murphy, 2012 [1]), che a sua volta è un&#8217;area di ricerca interdisciplinare di matematica, statistica, informatica e neuroscienza. Negli ultimi cinque anni il deep learning è uscito dal dominio accademico per diventare la tecnica di apprendimento automatico dominante in uso in molti settori ad alta tecnologia.</p><p> </p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ef8ad8e elementor-aspect-ratio-169 elementor-widget elementor-widget-video" data-id="ef8ad8e" data-element_type="widget" data-settings="{&quot;youtube_url&quot;:&quot;https:\/\/youtu.be\/fmVWLr0X1Sk&quot;,&quot;video_type&quot;:&quot;youtube&quot;,&quot;controls&quot;:&quot;yes&quot;,&quot;aspect_ratio&quot;:&quot;169&quot;}" data-widget_type="video.default">
				<div class="elementor-widget-container">
					<div class="elementor-wrapper elementor-fit-aspect-ratio elementor-open-inline">
			<div class="elementor-video"></div>		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-6f109c2 elementor-widget elementor-widget-text-editor" data-id="6f109c2" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Il deep learning ha trovato applicazioni in tutto lo spettro dell&#8217;Intelligenza Artificiale (AI), comprese le auto a guida autonoma (Nvidia, 2017 [2]), la robotica (Levine et al, 2016  [3]), la sintesi vocale (van den Oord et al, 2016 [4]), il riconoscimento vocale (Yu e Deng, 2014 [5]), traduzione linguistica (Cho et al, 2014 [6]), trasferimento dello stile dell&#8217;immagine (Gatys et al, 2016 [7]), generazione automatica di contenuti (Goodfellow et al, 2014 [8]) nonché prestazioni di livello mondiale che battono l&#8217;uomo ai giochi da tavolo e ai videogiochi dall&#8217;Atari 2600 (Mnih et al, 2015 [9]) all&#8217;antico gioco del Go (Silver et al, 2016 [10]).</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ab5d7a7 elementor-widget elementor-widget-image" data-id="ab5d7a7" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="700" height="797" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-neural-style-transfer.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-deep-learning-neural-style-transfer" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-neural-style-transfer.png 700w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-neural-style-transfer-263x300.png 263w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-neural-style-transfer-141x160.png 141w" sizes="(max-width: 700px) 100vw, 700px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-0caed5f elementor-widget elementor-widget-text-editor" data-id="0caed5f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Sebbene le applicazioni di cui sopra abbiano avuto un&#8217;ampio risalto nella stampa popolare, molte delle tecniche hanno trovato usi in contesti industriali più tradizionali. Ciò include il rilevamento delle anomalie (Zhai, 2016 [18]) e l&#8217;ottimizzazione dei sistemi di controllo (Gao, 2014 [19]).</p><p>Il tasso di progresso nell&#8217;deep learning è stato esplosivo. La comunità estremamente aperta unisce il mondo accademico, l&#8217;industria e la finanza, fornendo ampi dataset del mondo reale su cui addestrare una serie sempre crescente di nuovi modelli.</p><p>Un format di pubblicazione libera che utilizza prevalentemente il <a href="https://arxiv.org/">server di prestampa arXiv</a> ha permesso una rapida diffusione dei risultati. Le librerie open source come <a href="http://caffe.berkeleyvision.org/">Caffe</a>, <a href="http://torch.ch/">Torch</a>, <a href="http://deeplearning.net/software/theano/" class="broken_link">Theano</a>, <a href="https://www.tensorflow.org/">Tensorflow</a> e <a href="https://keras.io/">Keras</a> hanno  molto diminuito le complessità di implementazione di nuove architetture. Inoltre si ha un&#8217;ampia riproducibilità grazie l&#8217;implementazioni di modelli su repository open source come <a href="https://github.com/">Github</a>.</p><p> </p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ec04e7d elementor-widget elementor-widget-image" data-id="ec04e7d" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="678" height="320" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-geforce-gtx-1080ti.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-deep-learning-geforce-gtx-1080ti" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-geforce-gtx-1080ti.png 678w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-geforce-gtx-1080ti-300x142.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-geforce-gtx-1080ti-160x76.png 160w" sizes="(max-width: 678px) 100vw, 678px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-694f275 elementor-widget elementor-widget-text-editor" data-id="694f275" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p><span class="goog-text-highlight">I recenti progressi nelle architetture di elaborazione parallela hanno consentito a laboratori accademici e d industriali di svolgere ricerche su hardware di base come le unità di elaborazione grafica (GPU) a livello consumer, su workstation locali economiche o tramite nodi di calcolo paralleli basati su cloud-on-demand.</span></p><p>La confluenza di queste  ricerche ha portato a risultati incredibilmente impressionanti, insieme a un enorme clamore popolare che circonda il deep learning.</p><h2><span class="goog-text-highlight">Che cos&#8217;è il Deep Learning?</span></h2><h3> </h3><h3>Rappresentazioni</h3><p>La motivazione per le tecniche di deep learning inizia con una discussione sul campo più ampio del machine learning. Il machine learning può essere considerato un meccanismo per mappare le <strong>rappresentazioni</strong> dei dati sui <strong>risultati</strong> (Goodfellow et al, 2016 [11]).</p><p>Nel trading quantitativo questo si manifesta spesso come &#8220;indicatori&#8221; artigianali sui dati dei prezzi finanziari al fine di prevedere il prezzo dell&#8217;asset per il giorno successivo.</p><p>La performance di questi modelli di trading dipende fortemente dalla qualità di questi indicatori o <strong>feature</strong>, ovvero dalle rappresentazioni dei prezzi sottostanti.</p><p>Questo può essere semplicemente visto utilizzando le stesse informazioni sui prezzi ritardati grezzi come feature. Per alcuni asset molto liquidi i prezzi sottostanti non si correlano bene con i risultati predittivi, a causa del basso rapporto segnale/rumore nella maggior parte dei dati storici sui prezzi degli asset. Questo significa che è necessaria una specifica creazione manuale delle feature per estrarre utili segnali predittivi. In sostanza, è la scelta della rappresentazione delle  feature che è importante.</p><p>Quindi il compito fondamentale del ricercatore di quant trading è capire quali feature un segnale predittivo utile. Non solo questo compito richiede molto tempo, ma richiede anche una manutenzione costante a causa della presenza del &#8220;decadimento alfa&#8221;, dove i segnali predittivi vengono arbitrariamente eliminati con passare del tempo.</p><p>Una possibile soluzione a questo problema è utilizzare tecniche di machine learning non solo per apprendere le mappature tra i predittori e le risposte, una volta che i predittori sono stati realizzati a mano, ma anche per <em>effettivamente apprendere i predittori stessi</em>. In altre parole, affinché i modelli di apprendimento automatico utilizzino i dati per apprendere la migliore rappresentazione che produce un segnale predittivo.</p><p>In alcuni campi questo può produrre prestazioni di gran lunga superiori alle feature create dall&#8217;uomo. Inoltre, libera una parte sostanziale del tempo di ricerca, poiché queste feature non devono essere trovate in modo manuale.</p><h3>Feature gerarchiche</h3><p>È qui che entra in gioco il deep learning. &#8220;Risolve&#8221; il problema della creazione delle feature introducendo una <em>gerarchia</em> nelle rappresentazioni delle feature. Imparando concetti semplici e quindi basandosi su questi concetti per formare esempi più complessi, è possibile produrre insiemi altamente predittivi di rappresentazioni di feature che superano di gran lunga quelli sviluppati dagli esseri umani.</p><p>Come esempio dal campo della <strong>visione</strong> artificiale, una <strong>rete neurale convoluzionale</strong> utilizzerà molti livelli nascosti per acquisire pixel di input dell&#8217;immagine, formare bordi da questi pixel, formare angoli/contorni da questi bordi e quindi riconoscere oggetti da schemi di angoli e bordi.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e7d949b elementor-widget elementor-widget-image" data-id="e7d949b" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="600" height="237" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alex-net-kernels.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-deep-learning-alex-net-kernels" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alex-net-kernels.png 600w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alex-net-kernels-300x119.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alex-net-kernels-160x63.png 160w" sizes="(max-width: 600px) 100vw, 600px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-3a5d23b elementor-widget elementor-widget-text-editor" data-id="3a5d23b" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>L&#8217;intuizione chiave è che le informazioni sui pixel nella sua rappresentazione grezza non sono ben correlate con gli oggetti nell&#8217;immagine. È solo utilizzando un insieme gerarchico di trasformazioni di feature non lineari in una rete &#8220;deep&#8221; che il segnale predittivo diventa estremamente forte.</p><p>Questo approccio è basato sulle modalità di funzionamento del cervello umano. Nel corso della vita umana vengono apprese idee semplici, che vengono utilizzate per formare gerarchie di idee più complesse. Il deep learning applica questo approccio nell&#8217;ambito del machine learning.</p><p>Tuttavia, il deep learning non è un&#8217;idea nuova. Si tratta effettivamente di un &#8220;rebranding&#8221; del noto campo delle Reti Neurali Artificiali. I progressi nella potenza di calcolo, nell&#8217;ingegneria del software e nei dataset disponibili hanno fatto sì che le vecchie reti neurali &#8220;superficiali&#8221; abbiano lasciato il posto a reti neurali &#8220;profonde&#8221; di varie architetture, spesso con molti &#8220;strati nascosti&#8221;.</p><h3>Perché ora?</h3><p>Gli algoritmi alla base delle reti neurali profonde, tra cui la backpropagation e la discesa stocastica del gradiente, esistono da molto tempo. Allora perché il deep learning ha appena iniziato a mostrare promesse significative?</p><p>Principalmente perché solo ora è possibile fornire a questi algoritmi le risorse di cui hanno bisogno per produrre risultati così impressionanti.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-56a72eb elementor-widget elementor-widget-image" data-id="56a72eb" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="242" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alexnet-architecture-768x242.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-deep-learning-alexnet-architecture" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alexnet-architecture-768x242.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alexnet-architecture-300x95.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alexnet-architecture-160x50.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-deep-learning-alexnet-architecture.png 850w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-92c58c3 elementor-widget elementor-widget-text-editor" data-id="92c58c3" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Tali risorse includono un&#8217;abbondanza di <strong>dati di addestramento</strong> estremamente ben etichettati e la disponibilità di <strong>hardware economico ad elevato parallelismo</strong>, per il quale è semplice scrivere software.</p><p>L&#8217;incredibile crescita di Internet ha, conseguentemente, prodotto vaste tipologie di serie temporali registrate, testo, immagini, audio e video, molti dei quali sono etichettati. L&#8217;avvento della Graphics Processing Unit (GPU) ha permesso che tali dataset possono essere elaborati in un lasso di tempo ragionevole.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-098a8ca elementor-widget elementor-widget-image" data-id="098a8ca" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="500" height="414" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-qs-deep-learning-nvidia-tesla-p100.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-qs-deep-learning-nvidia-tesla-p100" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-qs-deep-learning-nvidia-tesla-p100.png 500w, https://datatrading.info/wp-content/uploads/trading-machine-learning-qs-deep-learning-nvidia-tesla-p100-300x248.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-qs-deep-learning-nvidia-tesla-p100-160x132.png 160w" sizes="(max-width: 500px) 100vw, 500px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-204292c elementor-widget elementor-widget-text-editor" data-id="204292c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>La combinazione di questi ampi dataset con hardware altamente parallelizzabile ha consentito ai moderni modelli di deep learning di superare di gran lunga le prestazioni umane in molte attività di classificazione, spesso con un intervento umano minimo.</p><h2>Deep learning per il trading quantitativo</h2><p>Sebbene il deep learning sia un campo di ricerca relativamente nuovo, sta già mostrando notevoli promesse nel campo della finanza. Alcune interessanti  ricerche sono state pubblicate negli ultimi due anni:</p><ul><li>Le direzioni dei futures sulle materie prime e sul forex sono state previste da reti neurali profonde (Dixon et al, 2016 [14])</li><li>L&#8217;effetto momentum nelle azioni è stato analizzato per prevedere rendimenti mensili/giornalieri sia più alti che più bassi rispetto alla mediana in (Takeuchi e Lee, 2013 [15]) e (Batres-Estrada, 2015 [16]).</li><li>Le tecniche di elaborazione del linguaggio naturale basate sul deep learning sono state applicate per prevedere il dissesto delle società finanziarie (Rönnqvist e Sarlin, 2016 [17]) e per prevedere i rendimenti azionari tedeschi sulla base delle notizie (Fehrer e Feuerriegel, 2015 [22]).</li></ul><p>In un <a href="https://datatrading.info/deep-learning-con-theano-regressione-logistica/">articolo precedente</a> abbiamo menzionato come le reti neurali profonde per il riconoscimento delle immagini venivano utilizzate per rilevare i serbatoi statici di stoccaggio  del petrolio per stimare le forniture mondiali di petrolio greggio.</p><p>In definitiva, gran parte del successo del deep learning supervisionato deriva dall&#8217;estrazione automatica delle feature. Tuttavia, per essere efficace, richiede una significativa quantità di dati di addestramento, con  ragionevoli rapporti segnale-rumore.</p><p>Quindi la sfida nella finanza quantistica è cercare di ottenere grandi quantità di dati finanziari di &#8220;addestramento&#8221; che contengano segnali utili. <span class="">Negli articoli successivi descriviamo ampiamente questi punti saranno trattati.</span></p><h2>Prossimi passi</h2><p>Negli articoli successivi  descrivamo le più comuni architetture di deep learning, tra cui il percettrone multistrato (MLP), la rete neurale convoluzionale (CNN) e la rete neurale ricorrente (RNN).</p><p>Introduciamo e installiamo due librerie di deep learning basate su Python, ovvero Tensorflow e Keras. Implementiamo in Keras le architetture di cui sopra per dimostrarne la facilità d&#8217;uso. Inoltre delineiamo i prerequisiti matematici di base per la ricerca sul deep learning.</p><p>Successivamente presentiamo una guida alla creazione di un &#8220;PC di deep learning&#8221;, che fornisce istruzioni dettagliate su come costruire da zero un economico PC di deep learning per il trading algoritmico.</p><p>Infine, negli articoli successivi dedichiamo molto tempo all&#8217;applicazione di modelli di deep learning a problemi di finanza quantitativa.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-447b68c elementor-widget elementor-widget-text-editor" data-id="447b68c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Nota bibliografica</h2><p>Un testo di riferimento estremamente dettagliato sul campo del machine learning a livello accademico di base è (Murphy, 2012 [1]).</p><p>Un recente testo molto dettagliato sul deep learning, che presuppone una formazione universitaria in informatica, matematica o fisica è (Goodfellow, 2016 [11]). Copre tutte le architetture più note come il perceptron multistrato, la rete neurale convoluzionale e le reti neurali ricorrenti, oltre a fornire capitoli sulle ultime vie di ricerca.</p><p>Un recente documento di ricerca sulla natura dei &#8220;tre giganti&#8221; del deep learning (LeCun et al, 2015 [12]) fornisce una panoramica di alto livello dello stato dell&#8217;arte. Per coloro che sono interessati alla ricerca sul deep learning vale la pena iniziare lo studio della letteratura accademica.</p><p>Un&#8217;introduzione più delicata al deep learning è fornita dalla presentazione di diapositive di (Beam, 2017 [13]).</p><h2>Riferimenti</h2><ul><li><a href="https://www.cs.ubc.ca/~murphyk/MLbook/" name="ref-murphy2012">[1] Murphy, K.P. (2012) <em>Machine Learning &#8211; A Probabilistic Perspective</em>, MIT Press</a></li><li><a href="http://www.nvidia.com/object/drive-px.html" name="ref-nvidia-px2-2017">[2] Nvidia Corp. (2017) <em>Introducing the New Nvidia Drive PX 2</em>, http://www.nvidia.com/object/drive-px.html</a></li><li><a href="https://arxiv.org/abs/1603.02199" name="ref-levine2016">[3] Levine, S., Pastor, P., Krizhevsky, A., Quillen, D. (2016) &#8220;Learning Hand-Eye Coordination for Robotic Grasping with Deep Learning and Large-Scale Data Collection&#8221;, <em>1603.02199</em></a></li><li><a href="http://arxiv.org/abs/1609.03499" name="ref-wavenet2016">[4] van den Oord, A., Dieleman, S., Zen, H., Simonyan, K., Vinyals, O., Graves, A., Kalchbrenner, N., Senior, A.W., Kavukcuoglu, K. (2016) &#8220;WaveNet: A Generative Model for Raw Audio, <em>1609.03499</em>&#8220;</a></li><li><a href="http://amzn.to/2m2n8QQ" name="ref-yu2014">[5] Yu, D., Deng, L. (2014) <em>Automatic Speech Recognition: A Deep Learning Approach</em>, Springer</a></li><li><a href="https://arxiv.org/abs/1406.1078" name="ref-cho2014">[6] Cho, K., van Merrienboer, B., Gulcehre, C., Bahdanau, D., Bougares, F., Schwenk, H., Bengio, Y. (2014) &#8220;Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation, <em>1406.1078</em>&#8220;</a></li><li><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf" name="ref-gatys2016">[7] Gatys, L.A., Ecker, A.S., Bethge, M. (2016) &#8220;Image Style Transfer Using Convolutional Neural Networks&#8221;, <em>Computer Vision and Pattern Recognition</em></a></li><li><a href="https://arxiv.org/abs/1406.2661" name="ref-goodfellow2014">[8] Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y. (2014) &#8220;Generative Adversarial Networks, <em>1406.2661</em>&#8220;</a></li><li><a href="http://www.nature.com/nature/journal/v518/n7540/pdf/nature14236.pdf" name="ref-deepmindatari2015">[9] Mnih, V. et al (2015) &#8220;Human-level control through deep reinforcement learning&#8221;, <em>Nature</em> <strong>518</strong>: 529–533</a></li><li><a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html" name="ref-silver2016">[10] Silver, D. et al (2016) &#8220;Mastering the game of Go with deep neural networks and tree search&#8221;, <em>Nature</em> <strong>529</strong>: 484-489</a></li><li><a href="http://www.deeplearningbook.org/" name="ref-goodfellow2016">[11] Goodfellow, I.J., Bengio, Y., Courville, A. (2016) <em>Deep Learning</em>, MIT Press</a></li><li><a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf" name="ref-lecun2015">[12] LeCun, Y., Bengio, Y., Hinton, G. (2015) &#8220;Deep learning&#8221;, <em>Nature</em> <strong>521</strong> 436-444</a></li><li><a href="http://slides.com/beamandrew/deep-learning-101#/" name="ref-beam2017">[13] Beam, A. (2017) <em>Deep Learning 101</em>, http://slides.com/beamandrew/deep-learning-101#/</a></li><li><a href="https://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2756331" name="ref-dixon2016">[14] Dixon, M.F., Klabjan, D., Bang, J.H. (2016) &#8220;Classification-Based Financial Markets Prediction Using Deep Neural Networks&#8221;, <em>Algorithmic Finance</em></a><a href="https://papers.ssrn.com/sol3/Papers.cfm?abstract_id=2756331" name="ref-dixon2016"></a></li><li><a href="http://cs229.stanford.edu/proj2013/TakeuchiLee-ApplyingDeepLearningToEnhanceMomentumTradingStrategiesInStocks.pdf" name="ref-takeuchi2013">[15] Takeuchi, L., Lee, Y. (2013) &#8220;Applying Deep Learning to Enhance Momentum Trading Strategies in Stocks&#8221;</a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A820891&amp;dswid=-8761" name="ref-batres2015">[16] Batres-Estrada, B. (2015) &#8220;Deep learning for multivariate financial time series&#8221;, <em>Masters Thesis</em></a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="https://arxiv.org/pdf/1603.05670.pdf" name="ref-ronnqvist2016">[17] Rönnqvist, S., Sarlin, P. (2016) &#8220;Bank distress in the news: Describing events through deep learning, <em>1603.05670</em>&#8220;</a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="https://arxiv.org/pdf/1605.07717.pdf" name="ref-zhai2016">[18] Zhai, S., Cheng, Y., Lu, W., Zhang, Z. (2016) &#8220;Deep Structured Energy Based Models for Anomaly Detection, <em>1605.07717</em>&#8220;</a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="https://static.googleusercontent.com/media/www.google.com/en//about/datacenters/efficiency/internal/assets/machine-learning-applicationsfor-datacenter-optimization-finalv2.pdf" name="ref-gao2014">[19] Gao, J. (2014) &#8220;Machine Learning Applications for Data Center Optimization&#8221;, <em>Google</em></a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="https://arxiv.org/pdf/1508.06576.pdf" name="ref-gatys2015">[20] Gatys, L.A., Ecker, A.S., Bethge, M. (2015) &#8220;A Neural Algorithm of Artistic Style, <em>1508.06576</em>&#8220;</a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks" name="ref-krizhevsky2012">[21] Krizhevsky, A., Sutskever, I., Hinton, G. (2012) &#8220;ImageNet Classification with Deep Convolutional Neural Networks&#8221;, <em>Advances in Neural Information Processing Systems 25 (NIPS 2012)</em></a></li><li><a style="font-size: 15px; background-color: #ffffff;" href="https://arxiv.org/abs/1508.01993" name="ref-fehrer2015">[22] Fehrer, R., Feuerriegel, S. (2015) &#8220;Improving Decision Analytics with Deep Learning: The Case of Financial Disclosures, <em>1508.01993</em>&#8220;</a></li></ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/cose-il-deep-learning/">Cos&#8217;è il Deep Learning?</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Deep Learning con Theano &#8211; Regressione Logistica</title>
		<link>https://datatrading.info/deep-learning-con-theano-regressione-logistica/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Mon, 18 Dec 2017 07:04:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Deep Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5041</guid>

					<description><![CDATA[<p>Negli ultimi dieci anni il tema del deep learning è stato uno dei campi più discussi dell&#8217;apprendimento automatico e dell&#8217;intelligenza artificiale. Ha prodotto risultati all&#8217;avanguardia in aree diverse come la visione artificiale, il riconoscimento delle immagini, l&#8217;elaborazione del linguaggio naturale e il riconoscimento vocale. Tuttavia è stato anche ampiamente pubblicizzato &#8211; la risposta a tutti i problemi &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/deep-learning-con-theano-regressione-logistica/"> <span class="screen-reader-text">Deep Learning con Theano &#8211; Regressione Logistica</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/deep-learning-con-theano-regressione-logistica/">Deep Learning con Theano &#8211; Regressione Logistica</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5041" class="elementor elementor-5041">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-5b2d08d elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="5b2d08d" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-02acf0d" data-id="02acf0d" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-379662d elementor-widget elementor-widget-text-editor" data-id="379662d" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Negli ultimi dieci anni il tema del deep learning è stato uno dei campi più discussi dell&#8217;apprendimento automatico e dell&#8217;intelligenza artificiale. Ha prodotto risultati all&#8217;avanguardia in aree diverse come la visione artificiale, il riconoscimento delle immagini, l&#8217;elaborazione del linguaggio naturale e il riconoscimento vocale. Tuttavia è stato anche ampiamente pubblicizzato &#8211; la risposta a tutti i problemi di apprendimento automatico &#8211; ed è spesso frainteso a causa della sua ripida curva di apprendimento.</p><p>Negli ultimi due anni una delle principali aziende di deep learning, <a href="https://deepmind.com/">Google DeepMind</a>, è riuscita a utilizzare una tecnica particolare nota come deep reinforcement learning per battere gli umani ai giochi Atari 2600 [7]. In un recente concorso molto pubblicizzato [8], il modello AlphaGo ha battuto il miglior giocatore di <a href="https://en.wikipedia.org/wiki/Go_%28game%29">Go</a> in una serie di giochi, aumentando ulteriormente il mistero e l&#8217;eccitazione che circonda questa tecnica di apprendimento automatico.</p><p>Il deep learning non è una materia facile da imparare e per iniziare richiede alcuni concetti matematici  a livello universitario. In particolare si dovrebbero conoscere gli elementi di base dell&#8217;algebra lineare, del calcolo vettoriale (gradienti, derivate parziali) e della probabilità (stima di massima verosimiglianza). Oltre ai requisiti matematici è necessario una buona comprensione della programmazione orientata agli oggetti e, ai fini dell&#8217;efficienza, una conoscenza di base delle operazioni con una GPU. Tuttavia cerchiamo di introdurre molti di questi concetti quando sono necessari. Questa serie di articoli dovrebbe essere relativamente semplice per coloro che hanno un background matematico.</p><p>In questi articoli descriviamo cos&#8217;è il deep learning, perché è recentemente diventato così popolare, come funziona e come possiamo applicarlo alle aree della finanza quantitativa per migliorare i risultati del nostro modello e la redditività del portafoglio. Vediamo come sfrutture una libreria Python chiamata Theano [5] e le GPU di un computer per aumentare le prestazioni di allenamento dei modelli predittivi.</p><p>In particolare, nel corso della serie, consideriamo i seguenti argomenti:</p><ul><li>Regressione logistica a Theano (questo articolo)</li><li>Reti neurali e perceptron multistrato</li><li>Reti neurali di convoluzione (ConvNets)</li><li>Denoising Autoencoder e Stacked Denoising Autoencoder</li><li>Macchine Boltzmann limitate</li><li>Deep Belief Networks</li><li>Reinforcement Learning e Q-Learning</li><li>Deep Learning per l&#8217;analisi di serie temporali</li></ul>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-a1d3871 elementor-widget elementor-widget-text-editor" data-id="a1d3871" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Che cos&#8217;è l&#8217;apprendimento profondo?</h2><p>Il deep learning è un sottoinsieme del più ampio campo del machine learning che tenta di modellare le astrazioni di alto livello presenti nei dati al fine di migliorare notevolmente le prestazioni nell&#8217;apprendimento sia supervisionato che non supervisionato [9].</p><p>Raggiunge questo utilizzando più livelli di &#8220;processi&#8221;, ognuno dei quali contiene un insieme di funzioni di trasformazione non lineari che <em>apprendono le rappresentazioni</em> all&#8217;interno dei dati.</p><p>Questo approccio è basato direttamente dai processi che regolano le funzioni del cervello umano. Nel corso della nostra vita impariamo idee semplici e poi usiamo queste idee semplici per formare gerarchie di idee più complesse. Il deep learning offre un&#8217;applicazione di questo approccio alle attività di machine learning.</p><h4>Motivazioni per  l&#8217;uso del deep learning</h4><p>Uno dei principali problemi del machine learning statistico è il tempo richiesto per creare manualmente  le feature, o predittori, al fine di generare efficaci algoritmi di classificazione o regressione. Ad esempio, quando si tenta di prevedere i valori futuri di un indice del mercato azionario, potrebbe essere pertinente includere i tassi di interesse, i prezzi delle materie prime o i dati fondamentali delle azioni. Oppure per i dati che inizialmente non sono in una comoda rappresentazione numerica come video, audio o testo è necessario trovare efficienti algoritmi di trasformazione per ricavare feature predittive.</p><p>La scelta delle feature ottimali è difficile e richiede tempo. Le feature devono essere spesso realizzate a <em>mano</em> tramite la riduzione o la trasformazione della dimensione dei dati per migliorare le prestazioni predittive. Esempi di tali trasformazioni includono il <a href="https://en.wikipedia.org/wiki/Bag-of-words_model">Modello della borsa di parole</a> e i metodi di vettorizzazione della <a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">term frequency–inverse document frequency</a> per l&#8217;elaborazione del linguaggio naturale.</p><p>Il deep learning promette di sostituire l&#8217;attività manuale di <em>ingegneria delle  feature,</em> molto dispendiosa in termini di tempo, tramite l&#8217;introduzione di efficienti architetture di rete per l&#8217; <em>apprendimento non supervisionato delle  feature</em>. La chiave di questo processo risiede nella <em>rappresentazione gerarchica delle  feature</em> all&#8217;interno della struttura della rete.</p><p>L&#8217;attuale ricerca sugli algoritmi di deep learning tenta di creare modelli che riescano ad apprendere le rappresentazioni astratte a partire da grandi quantità di dati senza etichette. Tale ricerca è importante perché i dati non etichettati sono spesso estremamente abbondanti e facilmente disponibili rispetto al più costoso processo per ottenere dei dati etichettati, che viene utilizzato negli approcci di apprendimento supervisionato.</p><p>Il deep learning è diventato popolare negli ultimi dieci anni grazie a tre documenti &#8220;rivoluzionari&#8221; di <a href="https://en.wikipedia.org/wiki/Geoffrey_Hinton">Geoff Hinton</a> , <a href="https://en.wikipedia.org/wiki/Yoshua_Bengio">Yoshua Bengio</a> , <a href="https://en.wikipedia.org/wiki/Yann_LeCun">Yann LeCun</a> e altri [2]:</p><ul><li>Hinton, G. E., Osindero, S. and Teh, Y., <a href="http://www.cs.toronto.edu/~hinton/absps/fastnc.pdf">A fast learning algorithm for deep belief nets</a> Neural Computation 18:1527-1554, 2006</li><li>Yoshua Bengio, Pascal Lamblin, Dan Popovici and Hugo Larochelle, <a href="http://www.iro.umontreal.ca/~lisa/publications2/index.php/publications/show/190" class="broken_link">Greedy Layer-Wise Training of Deep Networks</a>, in J. Platt et al. (Eds), Advances in Neural Information Processing Systems 19 (NIPS 2006), pp. 153-160, MIT Press, 2007</li><li>Marc’Aurelio Ranzato, Christopher Poultney, Sumit Chopra and Yann LeCun <a href="http://yann.lecun.com/exdb/publis/pdf/ranzato-06.pdf">Efficient Learning of Sparse Representations with an Energy-Based Model</a>, in J. Platt et al. (Eds), Advances in Neural Information Processing Systems (NIPS 2006), MIT Press, 2007</li></ul><p>Oltre a tutta la vasta letteratura sull&#8217;argomento prodotta negli ultimi anni.</p><p>Inoltre, grazie all&#8217;aumento della potenza di calcolo, in particolare per quanto riguarda i costi ridotti e la maggiore disponibilità di unità di elaborazione grafica (GPU), il deep learning è diventato accessibile ad un&#8217;ampia comunità non accademica.</p><p>Alcune tecniche di deep learning forniscono risultati all&#8217;avanguardia in campi come la visione artificiale, l&#8217;elaborazione delle immagini, il riconoscimento vocale automatico e l&#8217;elaborazione del linguaggio naturale. Quindi è interessante considerare come potrebbero essere applicata ad altri settori come la finanza quantitativa.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-6400d7f elementor-widget elementor-widget-text-editor" data-id="6400d7f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Deep Learning per la finanza quantitativa</h4><p>Nonostante il deep learning sia chiaramente molto utile e performante in alcuni campi, offre le stesse prestazioni nella finanza quantitativa? Secondo me sì. Il deep learning è stato applicato con successo ai dati delle serie temporali [11] nonostante è necessario prendere in considerazione la natura temporale dei dati durante la realizzazione degli algoritmi di deep learning. Questo non è un problema banale e richiede molte ricerche.</p><p>Inoltre il deep learning ha mostrato risultati promettenti nel rilevamento delle anomalie temporali, almeno nei campi dell&#8217;ingegneria, ed è competitivo ad altri strumenti di rilevamento delle anomalie come le reti bayesiane applicate ai dati di serie temporali multivariate. Alcuni algoritmi di finanza quantitativa necessitano di determinare i &#8220;cambiamenti di regime&#8221; e il deep learning è probabilmente molto utile in questo caso.</p><p>Dove il Deep Learning aggiunge davvero valore al trader quantitativo è la possibilità di analizzare e dare facilmente un significato a grandi set di dati di immagini e produrre segnali basati su queste immagini. Come possiamo applicarlo in strategie quantitativi? Siamo interessati solo ai dati storici dei prezzi o anche ai dati fondamentali?</p><p>Per rispondere a queste domande dobbiamo considerare che oggi esiste una vasta gamma di fornitori di dati geospaziali, generati da una combinazione di costellazioni di satelliti in orbita terrestre bassa (LEO) e di droni appositamente costruiti per catturare immagini. Questi dati satellitari possono fornire una vasta gamma di informazioni su parametri precedentemente molto difficili da ottenere. Più passaggi al mese su una particolare regione forniscono l&#8217;elemento temporale alle immagini satellitari.</p><p>Ecco alcuni esempi di come una attività di trading quantitativo (un fondo o un trader retail) potrebbe utilizzare i dati satellitari e tecniche di deep learning per produrre segnali di trading:</p><ul><li><strong>Parcheggi auto</strong> dei negozi al dettaglio &#8211; L&#8217;analisi delle immagini satellitari dei parcheggi dei negozi al dettaglio per un determinato periodo, ad esempio tre mesi, con uno strumento di classificazione del deep learning, in grado di contare le auto, consente un&#8217;indicazione approssimativa dei dati di vendita. Questa indicazione può essere utilizzata, oltre ai dati fondamentali più tradizionali, per determinare la probabilità che un&#8217;azienda soddisfi le previsioni di vendita per il prossimo trimestre.</li><li><strong>Altezza dei serbatoi di stoccaggio delle raffinerie di petrolio</strong> &#8211; Il deep learning può essere applicato ai dati satellitari per classificare i serbatoi di stoccaggio del petrolio situati nelle raffinerie di tutto il mondo. Analizzando le ombre presenti nelle immagini è possibile determinare la quantità di petrolio stoccato in vari momenti. Questo può essere utilizzato per formare un &#8220;indice&#8221; di restrizione dell&#8217;offerta di petrolio, insieme a dati petroliferi più tradizionali come i futures sul petrolio greggio, per creare un modello fondamentale più accurato nel determinare la domanda e l&#8217;offerta.</li><li><strong>Rendimenti delle colture</strong> &#8211; Tecniche simili a quelle sopra possono essere utilizzate per accertare le rese delle colture (in molti settori), che forniranno informazioni su come il mercato dei futures per quella particolare commodity potrebbe comportarsi al momento del raccolto.</li></ul><p>Se tutto può sembrare piuttosto inverosimile, suggeriamo di dare un&#8217;occhiata ad alcune aziende che forniscono questo tipo di servizi al settore finanziario come <a href="https://orbitalinsight.com/solutions/" class="broken_link">Orbital Insight</a> e <a href="http://www.satimagingcorp.com/applications/natural-resources/agriculture/">Satellite Imaging Corporation</a>.</p><p>Gli hedge fund quantistici applicano queste tecniche già da tempo. La sempre maggiore disponibilità di immagini satellitari, librerie di deep learning e archiviazione ed elaborazione basate su cloud, permette anche al trader quantitativo retail di poter accedere facilmente a queste tecniche, se è ben  determinato a fare qualcosa di simile.</p><p>Nei successi articoli descriviamo come eseguire tale analisi, sperando che possa consentire di sviluppare e aggiungere alcune strategie non correlate al proprio portafoglio.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-7649803 elementor-widget elementor-widget-text-editor" data-id="7649803" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Librerie di software per il deep learning</h4><p>La popolarità del deep learning significa che non mancano le librerie di software open source disponibili. Un elenco completo può essere trovato <a href="https://en.wikipedia.org/wiki/Comparison_of_deep_learning_software">qui</a> su Wikipedia. Le librerie più performanti sono <a href="https://www.tensorflow.org/">Tensorflow</a>, <a href="http://torch.ch/">Torch</a>, <a href="http://deeplearning.net/software/theano/" class="broken_link">Theano</a> e <a href="http://caffe.berkeleyvision.org/">Caffe</a>.</p><p>Non ci soffermiamo sui pro e dei contro tra queste librerie. In definitiva, tutte sono utili per creare modelli di deep learning, in diversi linguaggi/ambienti di programmazione, con caratteristiche di prestazioni e diverse API per farlo. Se desideri indagare su quale potrebbe essere preferibile per i tuoi progetti, è meglio seguire il link Wikipedia sopra e confrontare.</p><p>Abbiamo scelto Theano per questi tutorial perchè è basato su Python, ha accesso sia alla CPU che alla GPU ed è un prerequisito per <a href="https://github.com/pymc-devs/pymc3">PyMC3</a>, che abbiamo già usato nell&#8217;articolo sull&#8217;<a href="https://datatrading.info/markov-chain-monte-carlo-per-linferenza-bayesiana-lalgoritmo-metropolis/">MCMC bayesiano</a>.</p><p>In questo articolo introduciamo Theano e lo applichiamo ad un semplice modello di regressione logistica.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e53a8a3 elementor-widget elementor-widget-text-editor" data-id="e53a8a3" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Introduzione a Theano</h2><p>Per questa serie di articoli utilizzeremo la libreria <a href="http://deeplearning.net/software/theano/" class="broken_link">Theano</a> di Python.</p><h4>Cos&#8217;è Theano?</h4><p>Theano è una libreria di calcolo numerico che consente di definire, ottimizzare e valutare espressioni matematiche che coinvolgono array multidimensionali, in modo efficiente attraverso la CPU o la GPU [5].</p><p>Cosa significa questo? Ebbene, molti modelli di machine learning vengono creati utilizzando grandi array multidimensionali, che vengono spesso utilizzati per memorizzare i valori o i pesi dei parametri. Inoltre, questi modelli analizzano i dati che sono anche archiviati in grandi array multidimensionali. Pertanto ha senso utilizzare una libreria in grado di gestire in modo efficiente i  dati multidimensionali.</p><p>Questo rende Theano particolarmente attraente dal punto di vista del deep learning perchè utilizza <em>espressioni simboliche</em>. In altre parole, invece di scrivere direttamente il codice Python per formule matematiche, si usa oggetti per <em>rappresentare</em> l&#8217;equazione. Theano prende questa equazione e trova il miglior modo per eseguirla ,in modo completamente trasparente per il programmatore. Di estrema importanza per le applicazioni di deep learning (soprattutto quelle che utilizzano <em>la discesa stocastica del gradiente</em>) è la capacità delle espressioni di essere simbolicamente differenziate. Descriviamo di seguito questo concetto in modo più dettagliato.</p><p>E&#8217; fondamentare evidenziare che Theano consente di scrivere <em>le specifiche</em> del modello anziché le <em>implementazioni</em> del modello. Questo  particolarmente utile perchè Theano è molto ben integrato nella GPU, che fornisce sostanziali accelerazioni per l&#8217;allenamento di deep learning.</p><p>Quindi Theano si trova da qualche parte tra <a href="http://www.numpy.org/">NumPy</a> e la libreria matematica simbolica <a href="http://www.sympy.org/en/index.html">SymPy</a> di Python</p><p>Dobbiamo sottolineare che Theano non viene usano esclusivamente per la ricerca sul deep learning. ad esempio, PyMC3, la libreria bayesiana di programmazione probabilistica, è parzialmente scritta anche in Theano.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-512f0a6 elementor-widget elementor-widget-text-editor" data-id="512f0a6" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Installazione di Theano</h4><p>È consigliabile seguire le istruzioni di installazione per Theano direttamente dal <a href="https://theano-pymc.readthedocs.io/en/latest/index.html">sito ufficiale</a> dato che è disponbile per molte piattaforme e diverse versioni di Python.</p><p>Questo articolo è sicuramente più facile da seguire se si dispone di un sistema basato su Unix, come Linux/Ubuntu, o Mac OS X. Credo che semplifichi anche l&#8217;interazione con una GPU perché è molto difficile poter accedere a una GPU tramite Anaconda su sistemi Windows.</p><p>Descriviamo ora la regressione logistica e alla sua implementazione a Theano.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-5da53f3 elementor-widget elementor-widget-text-editor" data-id="5da53f3" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2><span class="">Regressione logistica con Theano</span></h2><p>Abbiamo già descritto le motivazioni per cui il deep learning è un approccio da considerare e merita un&#8217;approfondimento. In questo paragrafo descriviamo come creare il nostro primo modello statistico &#8211; una regressione logistica multiclasse &#8211; utilizzando il framework Theano per capirne il funzionamento. Sebbene questa non sia una vera e propria tecnica di deep learning, è un primo passo fondamentale verso la comprensione di architetture più complicate come i perceptron multistrato e le reti neurali convoluzionali.</p><p>Applichiamo la regressione logistica a un famoso database noto come MNIST (database di cifre scritte a mano). Vediamo come possiamo ottenere ragionevoli prestazioni di classificazione con questo metodo. Tuttavia, l&#8217;aspetto più importante è descrivere come costruire un modello non banale in Theano e usarlo come base per modelli di deep learning più complessi nei prossimi articoli.</p><p>Iniziamo descrivendo il database MNIST e quindi ripassiamo brevemente la regressione logistica. Esploriamo  poi la discesa stocastica del gradiente, un algoritmo di ottimizzazione utilizzato per addestrare modelli, compresi quelli del deep learning. Descriviamo quindi le funzioni di verosimiglianza al fine di fornire una &#8220;funzione obiettivo&#8221; per l&#8217;addestramento. <span class="">Infine, implementiamo tutte queste tecniche in Theano e quindi addestriamo/testiamo il modello di regressione logistica con le CPU e le GPU.</span></p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-479ad55 elementor-widget elementor-widget-text-editor" data-id="479ad55" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Set di dati MNIST</h4><p>Il database Mixed National Institute of Standards and Technology (MNIST) [16] è un insieme di immagini di cifre scritte a mano, che viene spesso utilizzato per la formazione e il test nel campo del machine learning. Contiene 60.000 immagini di allenamento e 10.000 immagini di test, tutte di dimensioni 28&#215;28 pixel.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c928e25 elementor-widget elementor-widget-image" data-id="c928e25" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="530" height="297" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-mnist.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-mnist" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-mnist.png 530w, https://datatrading.info/wp-content/uploads/trading-machine-learning-mnist-300x168.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-mnist-160x90.png 160w" sizes="(max-width: 530px) 100vw, 530px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-f2cc7af elementor-widget elementor-widget-text-editor" data-id="f2cc7af" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Gli algoritmi di deep learning sono attualmente lo stato dell&#8217;arte per le prestazioni di classificazione sul set di dati MNIST. In particolare, un approccio con reti neurali a convoluzione gerarchica ha raggiunto un tasso di errore di appena lo 0,23% nel 2012.</p><p>In questa serie di articoli  usiamo il set di dati MNIST poiché è facile da lavorare e ci consente di verificare come le prestazioni di classificazione migliorano con la crescente sofisticazione delle architetture che  introduciamo.</p><p>Il set di dati MNIST, in una  semplice forma per essere usata in questi tutorial, può essere trovata qui: <a href="http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz">http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz</a>.</p><p>Affinché questo tutorial sia eseguito correttamente, questo file deve essere posizionato nella stessa directory del codice Python, che abbiamo chiamato <code>deep_logistic_regression_theano.py</code>. Non ha bisogno di essere decompresso. La decompressione verrà gestita all&#8217;interno di Python tramite il modulo <code>gzip</code>.</p><p>Nei sistemi Linux/Ubuntu possiamo direttamente scaricare il file con la seguente riga di comando:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-db2993c elementor-widget elementor-widget-code-highlight" data-id="db2993c" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-bash ">
				<code readonly="true" class="language-bash">
					<xmp>$ wget http://www.iro.umontreal.ca/~lisa/deep/data/mnist/mnist.pkl.gz</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-121f3db elementor-widget elementor-widget-text-editor" data-id="121f3db" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Modello di regressione logistica</h4><p>In questo tutorial usiamo il modello <em>probabilistico</em> di regressione logistica multiclasse per classificare le cifre scritte a mano di MNIST. Nonostante il nome, la regressione logistica è in realtà una tecnica di <em>classificazione.</em></p><p>Una discussione dettagliata sulla regressione logistica non rientra nello scopo di questo articolo. Un&#8217;introduzione all&#8217;argomento con un semplice livello matematico può essere trovata in James et al [13], mentre una discussione più avanzata a livello accademico può essere trovata in Hastie et al [12].</p><p>La regressione logistica ha lo scopo di assegnare probabilisticamente un&#8217;etichetta di classe all&#8217;immagine di una cifra (&#8220;classificazione&#8221;) dopo aver opportunamente &#8220;addestrato&#8221; il modello di regressione logistica su precedenti coppie immagine-etichetta. Quindi siamo in un regime di <em>apprendimento supervisionato.</em></p><p>Consideriamo \(Y\) la risposta della classe etichettata (la cifra) e \(x\) il nostro vettore di feature in ingresso (l&#8217;immagine 28&#215;28 pixel) allora la probabilità di classificazione in una <em>determinata</em> cifra  \(K\) a partire da una specifica immagine \(x\) è data da [12]:</p><p style="text-align: center;">\(\begin{eqnarray}P(Y=k \mid x) = \frac{\text{exp}(\beta_{k0} + \beta^{T}_k x)}{1 + \sum^{K-1}_{l=1} \text{exp}(\beta_{l0} + \beta^{T}_{l} x)}\end{eqnarray}\)</p><p>Dove \(k \in \{1,\ldots,K-1 \}\).</p><p>Per semplificare l&#8217;elenco dei parametri \(\beta_j\) possiamo riscrivere la formula usando le matrici. Se consideriamo \(W\) la matrice dei <em>pesi</em> e \(b\) il vettore dei <em>bias</em>, allora la probabilità diventa:</p><p style="text-align: center;">\(\begin{eqnarray}P(Y=k \mid x; W,b) = \frac{\text{exp}(W_k x + b_k}{\sum^{K}_{l=1} \text{exp}(W_l x + b_l)}\end{eqnarray}\)</p><p>A questo punto, supponendo di avere un meccanismo per trovare la matrice dei pesi \(W\) e il vettore dei bias \(b\), possiamo dire che la cifra più probabile per un particolare vettore di  feature dell&#8217;immagine \(x\) è data da \(P(Y=k \mid x; W,b)\).</p><p>Quindi classifichiamo l&#8217;immagine in una specifica cifra prendendo la cifra con la probabilità più alta tra tutte le cifre 0&#8230;9. Matematicamente questo viene scritto usando  la funzione \(\text{argmax}\) per la previsione del modello, \(y_{\text{pred}}\):</p><p style="text-align: center;">\(\begin{eqnarray}y_{\text{pred}} = \text{argmax}_k P(Y=k \mid x; W,b)\end{eqnarray}\)</p><p>Quindi non ci resta che determinare (in qualche modo) \(W\) e \(b\). È qui che entrano in gioco i concetti di <em>funzioni obiettivo</em>, <em>verosimiglianza</em> e <em>addestramento</em>. Prima di una discussione sulla probabilità, dobbiamo descrivere un algoritmo di ottimizzazione chiamato discesa stocastica del gradiente che costituisce la base per molti futuri algoritmi di deep learning.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ae8405c elementor-widget elementor-widget-text-editor" data-id="ae8405c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Discesa stocastica del gradiente</h4><p>Una parte fondamentale degli algoritmi di deep learning è <em>l&#8217;ottimizzazione</em>. Molte architetture di deep learning richiedono di ridurre al minimo una qualche forma di funzione obiettivo (o funzione di costo) affinché una rete di deep learning possa essere &#8220;addestrata&#8221; o &#8220;istruita&#8221;.</p><p>Un esempio più familiare è tratto dalla statistica classica. Per la regressione lineare potremmo usare i <a href="https://en.wikipedia.org/wiki/Least_squares">minimi quadrati</a> per trovare la &#8220;linea di miglior adattamento&#8221;. Un altro esempio è dato dalla regressione logistica utilizzata in questo articolo. Abbiamo bisogno di ottimizzare il negative log-likelihood (descritta più avanti) per verificare i parametri della regressione logistica.</p><p>Un particolare metodo di ottimizzazione usato frequentemente nel deep learning è la <strong>discesa stocastica del gradiente</strong>. Per descrivere come funziona la discesa stocastica del gradiente dobbiamo prima introdurre la discesa normale del gradiente.</p><p>La discesa del gradiente si basa sull&#8217;idea che se consideriamo una funzione obiettivo multivariabile o una &#8220;superficie di ottimizzazione&#8221;, data da \(f(x)\),  dove  \(f\) è differenziabile e \(x \in \mathbb{R}^n\), quindi in una regione locale intorno a un punto <em>a</em>, \(f\) diminuisce più rapidamente se ci si sposta nella direzione del gradiente negativo di \(f\) in <em>a</em>. In altre parole, viaggiamo nella direzione data da \(- \nabla f(a)\). In pratica questo vuol dire che il modo più veloce per scendere da una collina è viaggiare lungo il pendio che è il più ripido localmente.</p><p>Con questo algoritmo il successivo punto raggiunto, \(x_{n+1}\), è uguale al punto precedente, \(x_{n}\), meno la distanza percorsa in direzione della pendenza più ripida:</p><p style="text-align: center;">\(\begin{eqnarray}x_{n+1} = x_n &#8211; \gamma_n \nabla f(x_n)\end{eqnarray}\)</p><p>Dove \(\gamma_n\) è un parametro dipendente dal passo della distanza da percorrere, noto come <em>step size</em> o <em>learning rate</em>.</p><p>Tale sequenza di passaggi dovrebbe convergere al minimo locale desiderato. Nel caso di una rete di deep learning, questo dovrebbe portare a un set di parametri &#8220;formazione&#8221; o &#8220;apprendimento&#8221; ottimizzato localmente.</p><p>Nel machine learning e in altri esempi di stima statistica, le funzioni obiettivo hanno spesso la forma:</p><p style="text-align: center;">\(\begin{eqnarray}f(x) = \sum_{i=1}^n f_i (x)\end{eqnarray}\)</p><p>Cioè, la funzione obiettivo è una somma di funzioni \(f_i\), che sono spesso associati alla <em>i</em>-esima osservazione del set di dati di feature/formazione [14] .</p><p>La discesa stocastica del gradiente è simile alla discesa normale del gradiente. In questo caso, invece di valutare ad ogni step tutte le derivate parziali degli addendi \(f_i\), \(\frac{\partial f_i}{\partial x_j}\) (che è computazionalmente costoso), ad ogni passo si valuta solo un sottoinsieme casuale di derivate parziali.  Questo porta ad enormi risparmi sui costi computazionali, in particolare per le reti di  deep learning ad alta dimensione che dobbiamo prendere in considerazione.</p><p>Usiamo la discesa stocastica del gradiente per valutare la nostra funzione obiettivo, descritta di seguito, così come per tutti i restanti articoli sulle architetture di deep learning.</p><p>La particolare forma di discesa stocastica del gradiente usata in questo esempio è chiamata discesa stocastica del gradiente con la tecnica del mini-batch (MSGD) che prevede il calcolo della funzione obiettivo su più istanze selezionate anziché su una sola istanza. Questo ha l&#8217;effetto di ridurre la varianza nella stima del gradiente, poiché non siamo fortemente dipendenti da una singola istanza di allenamento per il nostro calcolo del gradiente. Introduce anche un parametro aggiuntivo, denominato \(B\), che è la dimensione del minibatch. Descriviamo la dimensione di \(B\) per  particolari problemi che si possono presentano, poiché ha un impatto sulla velocità di convergenza.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-cde5d84 elementor-widget elementor-widget-text-editor" data-id="cde5d84" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Funzione obiettivo per il Negative Log-Likelihood</h4><p><span class="">Come i modelli avanzati di deep learning, i modelli statistici classici richiedono un meccanismo in grado di generare i parametri ottimali per la previsione e l&#8217;inferenza. </span>Come accennato in precedenza, un esempio familiare è l&#8217;approccio dei minimi quadrati ordinario per la regressione lineare.</p><p>Per la regressione logistica dobbiamo utilizzare un concetto noto come <a href="https://en.wikipedia.org/wiki/Maximum_likelihood">metodo della massima verosimiglianza</a> (MLE). L&#8217;idea alla base della MLE è stimare i parametri di un modello statistico (come la pendenza e l&#8217;intercetta su una regressione lineare univariata) che &#8220;meglio&#8221; si adattano ai dati. Nel nostro caso siamo interessati a selezionare la migliore matrice <em>W</em> dei pesi e il vettore <em>b</em> <span style="font-size: 15px;">dei bias </span><span style="font-size: 15px;">che si adattano ai nostri dati di allenamento.</span></p><p>Il MLE prevede di selezionare i parametri che massimizzano la <em>funzione di verosimiglianza</em>. In questo modo si massimizza il &#8220;fitting&#8221; del modello con i dati di training.</p><p>Molte funzioni di verosimiglianza sono infatti prodotti di probabilità condizionata. Dato che stiamo cercando di massimizzare queste funzioni di verosimiglianza, dobbiamo considerare le loro derivate parziali rispetto ai valori dei parametri e impostarle a zero, come è consuetudine per trovare un punto massimo, minimo o stazionario.</p><p>L&#8217;assunzione di derivate parziali di prodotti di probabilità porta a equazioni complesse che diventano computazionalmente costose da valutare su larga scala. Quindi è spesso più facile lavorare con la <a href="https://en.wikipedia.org/wiki/Likelihood_function#Log-likelihood">verosimiglianza logaritmica</a> (&#8220;log-likelihood&#8221;). Il logaritmo naturale di un prodotto corrisponde a una somma di logaritmi rendendo la differenziazione molto più semplice. <span class="goog-text-highlight">Questo è possibile perché lo stesso logaritmo è una funzione monotona, cioè il massimo della log-likelihood è anche il massimo della verosimiglianza. </span>Quindi possiamo usare la log-likelihood al posto della funzione di verosimiglianza.</p><p>Nella regressione logistica la <em>negative</em> log-likelihood per <em>N</em> osservazioni dei dati di allenamento è data da [12]:</p><p style="text-align: center;">\(\begin{eqnarray}\ell (\theta = \{ W, d \} \mid \mathcal{D}) = \sum_{i=1}^N \log (P(Y=k \mid x_i; \theta))\end{eqnarray}\)</p><p>Cioè, considerando  i dati \(\mathcal{D}\) la negative log-likelihood dei parametri \(\theta\) (che sono la matrice <em>W</em> dei pesi e il vettore <em>b </em>dei bias) è uguale alla somma, attraverso tutti gli set di training in \(\mathcal{D}\) ,del logaritmo delle rispettive probabilità che una specifica cifra si verifichi dato la specifica <em>i</em>-esima immagine del vettore  delle feature, \(x_i\), con i parametri scelti.</p><p>Questa è la funzione obiettivo da valutare usando Theano. Di solito dobbiamo differenziare questa funzione, che potrebbe produrre alcune espressioni complesse per le sue derivate parziali rispetto ai parametri. Inoltre dobbiamo considerare problemi associati alla stabilità numerica [15] . Tuttavia, possiamo usare l&#8217;operatore di gradiente <code>grad</code> di Theano per raggiungere questo obiettivo.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-49e85eb elementor-widget elementor-widget-text-editor" data-id="49e85eb" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Implementazione della Regressione Logistica con Theano</h2><p>Finalmente siamo arrivati al- punto di iniziare a scrivere del codice con Theano. Descriviamo ora i singoli frammenti di codice mentre procediamo con l&#8217;implementazione-</p><p>Prima di iniziare dobbiamo installare Theano:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-8e2c01e elementor-widget elementor-widget-code-highlight" data-id="8e2c01e" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-bash ">
				<code readonly="true" class="language-bash">
					<xmp>$ pip install theano</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-50aa2d1 elementor-widget elementor-widget-text-editor" data-id="50aa2d1" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p><em>Come già detto, nel <a href="https://theano-pymc.readthedocs.io/en/latest/">sito ufficiale</a> sono disponibili le istruzioni di installazione di Theano per varie piattaforme.</em></p><p>Iniziamo con l&#8217;importazione delle librerie necessarie:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-45d0c9e elementor-widget elementor-widget-code-highlight" data-id="45d0c9e" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>import gzip
import six.moves.cPickle as pickle
import timeit

import numpy as np 
import theano
import theano.tensor as T</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-588fb95 elementor-widget elementor-widget-text-editor" data-id="588fb95" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Importiamo <code>gzip</code> e una versione più veloce di <code>pickle</code> per decomprimere e deserializzare il database MNIST. Inoltre importiamo <code>timeit</code> per calcolare il valore di <a href="https://en.wikipedia.org/wiki/Elapsed_real_time">elapsed real time</a> per il confronto CPU/GPU. Numpy è necessario per la creazione delle matrici e degli array, mentre importiamo la libreria tensor di Theano come <code>T</code> per comodità.</p><p>La prima cosa da fare è creare una classe che implementa il nostro modello di regressione logistica. Questa classe contiene le variabili per memorizzare la matrice <em>W</em> dei pesi e il vettore <em>b</em> dei bias polarizzazione. Conterrà anche un meccanismo per calcolare la probabilità di appartenenza alla classe \(P(Y=k \mid x; W,b)\) e conseguentemente, la previsione alla nuova classe \(y_{\text{pred}}\).</p><p>Diamo un&#8217;occhiata al codice che implementa la classe <code>LogisticRegression</code>.</p><p>Il nostro primo codice definisce la matrice dei pesi:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-872733e elementor-widget elementor-widget-code-highlight" data-id="872733e" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>self.W = theano.shared(
    value=np.zeros(
        (num_in, num_out), dtype=theano.config.floatX
    ),
    name='W', borrow=True
)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-1c2564d elementor-widget elementor-widget-text-editor" data-id="1c2564d" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Questo codice usa utilizza l&#8217;oggetto <code>theano.shared</code>, che consente di condividere una variabile simbolica tra le funzioni. Richiede una matrice di zeri di Numpy di un tipo di dati fisso <code>floatX</code> (che può essere a 32 o 64 bit). Dobbiamo dargli un nome, in questo caso &#8216;W&#8217; e infine usiamo il parametro <code>borrow=True</code> per evitare il <a href="https://en.wikipedia.org/wiki/Object_copying#Deep_copy" target="_blank" rel="noopener">deepcopying</a> dei dati in memoria. Questo è simile al passaggio di puntatori in C++. Tuttavia questo parametro non avrà alcun effetto su una GPU, come approfondito nel <a href="https://theano-pymc.readthedocs.io/en/latest/tutorial/aliasing.html#borrowing-when-creating-shared-variables" target="_blank" rel="noopener">tutorial di Theano</a>. In questa fase <em>W</em> NON è stata &#8220;addestrata&#8221; ma solo inizializzata con una matrice di zeri.</p><p>Ora creiamo uno codice simile per il vettore dei bias. È simile con l&#8217;eccezione che creiamo un vettore di zeri invece di una matrice di zeri:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fea1908 elementor-widget elementor-widget-code-highlight" data-id="fea1908" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>self.b = theano.shared(
    value=np.zeros(
        (num_out,), dtype=theano.config.floatX
    ),
    name='b', borrow=True
)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-cb2f0f1 elementor-widget elementor-widget-text-editor" data-id="cb2f0f1" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>abbiamo anche bisogno di un&#8217;espressione simbolica da memorizzare \(P(Y=k \mid x; W,B)\). Il codice è riportato di seguito:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-b4cb55e elementor-widget elementor-widget-code-highlight" data-id="b4cb55e" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>self.p_y_x = T.nnet.softmax(T.dot(x, self.W) + self.b)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-b2e6008 elementor-widget elementor-widget-text-editor" data-id="b2e6008" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Sembra piuttosto complicato! Cosa si sta facendo in questo frammento di codice? In primo luogo, notiamo l&#8217;uso della funzione <code>softmax</code>. Questa è una particolare funzione matematica (che si può approfondire <a href="https://en.wikipedia.org/wiki/Softmax_function" target="_blank" rel="noopener">qui</a>) data da:</p><p style="text-align: center;">\(\begin{eqnarray}\sigma({\bf z}) = \frac{\text{exp}(z_k)}{\sum^{K}_{l=1} \text{exp}(z_l)}\end{eqnarray}\)</p><p> Dove \(k \in \{ 1, \ldots, K \}\). Questa formula è nella stessa forma della probabilità della classe etichetta <em>Y</em>, dato un vettore di feature <em>x</em>. Nella nostra formula possiamo quindi utilizzare la funzione softmax implementata nella libreria Theano. Da notare che usiamo l&#8217;operatore <code>dot</code> tra il vettore <em>x</em> e la matrice dei pesi <em>W</em>, sommato al vettore dei bias <em>b</em>. Abbiamo quindi una rappresentazione simbolica per il calcolo della probabilità di <em>Y</em>.</p><p>L&#8217;ultima variabile da inizializzare è il meccanismo per calcolare l&#8217;<em>effettiva</em> classe della cifra, data la probabilità. Come descritto nei paragrafi precedenti, questo è caratterizzato dalla funzione \(\text{argmax}\). Quindi il seguente frammento di codice è relativamente facile da interpretare poiché utilizza semplicemente la funzione <code>argmax</code> di Theano:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-0e1bdb1 elementor-widget elementor-widget-code-highlight" data-id="0e1bdb1" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>self.y_pred = T.argmax(self.p_y_x, axis=1)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-37e325b elementor-widget elementor-widget-text-editor" data-id="37e325b" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Questo completa l&#8217;<em>inizializzazione</em> della classe. Da notare ancora una volta che in questa fase <em>W</em> e <em>b</em> non sono stati addestrati e sono semplicemente impostati come matrici di zeri, cioè matrici con tutti gli elementi uguali a zero.</p><p>A questo punto possiamo usare gli operatori di Theano per definire la funzione obiettivo della negative log-likelihood con una espressione simbolica. In questo modo possiamo definire un meccanismo per valutare la verosimiglianza per qualsiasi specifico insieme di parametri <em>W</em> e <em>b</em>, che sarebbe molto complicato da implementare in un codice senza l&#8217;aiuto degli operatori forniti da Theano:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-d9f53fb elementor-widget elementor-widget-code-highlight" data-id="d9f53fb" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def negative_log_likelihood(self, y):
    return -T.mean(T.log(self.p_y_x)[T.arange(y.shape[0]), y])</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-75570b8 elementor-widget elementor-widget-text-editor" data-id="75570b8" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Sebbene il codice sia conciso, effettua molte operazioni e quindi è opportuno descriverlo in modo approfondito. <code>y.shape[0]</code> è il numero di esempi nel minibatch di dimensione <em>N</em>, che usato come parametro di <code>T.arange(..)</code> otteniamo il vettore simbolico contenente l&#8217;elenco di numeri interi da <em>0</em> a <em>N-1</em>.</p><p>L&#8217;operatore <code>log</code> di Theano agisce sulla probabilità della classe \(y\), dato vettore delle feature \(x\), per produrre una matrice di probabilità logaritmiche. Questa matrice ha tante righe quanti sono gli esempi di addestramento nel minibatch (ad es <em>N</em>) e tante colonne quante sono le classi/cifre, <em>K</em>. Nel nostro caso abbiamo K=10 dato stiamo considerando le cifre \(0..9\). Quindi abbiamo una matrice di dimensioni \(N \times K\) = \(N \times 10\).</p><p>Combinando queste funzioni nel comando <code>T.log(self.p_y_x)[T.arange(y.shape[0]), y]</code> otteniamo un vettore che contiene le probabilità logaritmiche per ogni coppia di esempio di addestramento / risposta della classe della cifra. Questo vettore ha lunghezza <em>N</em>. Calcoliamo la media (<code>T.mean</code>) di questo vettore per ottenere la verosimiglianza logaritmica media di tutti gli esempi di addestramento nel minibatch. Infine, prendiamo il negativo per ottenere la negative log likelihood media degli esempi di addestramento.</p><p>Notiamo quindi che effettuiamo molti calcoli con una sola riga di comando. Questo è uno dei principali vantaggi quando usiamo Theano. Ci permette di definire le modalità di calcolo di un&#8217;espressione piuttosto che obbligarci a implementare il calcolo. Possiamo lasciare a Theano l&#8217;arduo compito di trovare un&#8217;implementazione ottimale.</p><p>Il passaggio finale è definire un meccanismo per calcolare il tasso di errore per un particolare batch di previsioni delle cifre. Per questo scopo definiamo il metodo <code>errors</code> per la classe <code>LogisticRegression</code>, che accetta un vettore di cifre <code>y</code> e lo confronta con il vettore delle previsioni <code>self.y_pred</code>:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ba4e677 elementor-widget elementor-widget-code-highlight" data-id="ba4e677" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def errors(self, y):
    # Per prima cosa controlliamo se il vettore y ha
    # la stessa dimensione del vettore di previsione y
    if y.ndim != self.y_pred.ndim:
        raise TypeError(
            "y should have the same shape as self.y_pred",
            ("y", y.type, "y_pred", self.y_pred.type)
        )
    # Controlla se y contiene i tipi (interi) corretti
    if y.dtype.startswith('int'):
        # Possiamo usare l'operatore Theano neq per restituire
        # il vettore di 1s o 0s, dove 1 rappresenta un
        # errore di classificazione
        return T.mean(T.neq(self.y_pred, y))
    else:
        raise NotImplementedError()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-5173edd elementor-widget elementor-widget-text-editor" data-id="5173edd" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Il metodo utilizza l&#8217;operatore <code>neg</code> di Theano, che restituisce un vettore di 1 o 0, dove 1 rappresenta un errore di classificazione. Questo ci permette di stimare l&#8217;accuratezza della previsione nell&#8217;addestramento del modello.</p><h4>Addestramento del modello</h4><p>Prima di poter addestrare il modello è necessario decomprimere il file gzip MNIST che abbiamo scaricato in precedenza, all&#8217;interno dello script Python.</p><p>Per restituire i corretti set  di training, validazione e test delle coppie feature-risposta (cioè coppie immagine-cifra) abbiamo bisogno di un meccanismo per creare variabili condivise di Theano, in modo da copiare i dati nella memoria della GPU. Se dovessimo copiare un minibatch in sequenza, le prestazioni si degraderebbero in modo significativo poiché il trasferimento della memoria della GPU è lento. Di seguito il metodo <code>shared_dataset</code> che implementa quanto sopra:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-bb2fb2a elementor-widget elementor-widget-code-highlight" data-id="bb2fb2a" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def shared_dataset(data_xy, borrow=True):
    """
    Crea variabili condivise Theano per consentire la
    copia dei dati sulla GPU per evitare il degrado
    delle performance per i dati in minibatch
    """
    data_x, data_y = data_xy
    shared_x = theano.shared(
        np.asarray(
            data_x, dtype=theano.config.floatX
        ), borrow=borrow
    )
    shared_y = theano.shared(
        np.asarray(
            data_y, dtype=theano.config.floatX
        ), borrow=borrow
    )
    return shared_x, T.cast(shared_y, 'int32')</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-2f7c4ac elementor-widget elementor-widget-text-editor" data-id="2f7c4ac" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				L&#8217;ultima riga richiede una piccola spiegazione. Dato che la GPU archivia i dati in un formato a virgola mobile ma per i scopi di addestramento abbiamo bisogno 
 che i valori delle cifre siano interi, allora dobbiamo eseguire il cast dei dati nel formato intero.

Il codice per aprire l&#8217;archivio compresso dei dati MNIST con gzip è il seguente:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-acffc1d elementor-widget elementor-widget-code-highlight" data-id="acffc1d" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def load_mnist_data(filename):
    """
    Carico il MNIST compresso con gzip nei
    dataset di test, convalida e training
    tramite la libreria pickle Python
    """
    # Uso la compressione gzip e le librerie di
    # deserializzazione pickle per aprire le immagini
    # MNIST nei dataset di addestramento, convalida e test
    with gzip.open(filename, 'rb') as gzf:
        try:
            train_set, valid_set, test_set = pickle.load(
                gzf, encoding='latin1'
            )
        except:
            train_set, valid_set, test_set = pickle.load(gzf)

    # Uso la funzione shared_dataset per creare le
    # variabili condivise di Theano da copiare nella GPU
    test_set_x, test_set_y = shared_dataset(test_set)
    valid_set_x, valid_set_y = shared_dataset(valid_set)
    train_set_x, train_set_y = shared_dataset(train_set)

    # Creo la lista di tuple che contiene le coppie
    # feature-risposta per i dataset di addestramento,
    # di validazione e di testing
    rval = [
        (train_set_x, train_set_y),
        (valid_set_x, valid_set_y),
        (test_set_x, test_set_y)
    ]
    return rval</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-48e6fcd elementor-widget elementor-widget-text-editor" data-id="48e6fcd" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Questo codice è relativamente semplice.  Usiamo un contesto <code>with</code> per aprire il file tramite la libreria <code>gzip</code>, quindi deserializziamo i dati tramite la libreria <code>pickle</code> di Python, preoccupandi di specificare la corretta codifica.</p><p>Quindi utilizziamo la  funzione<code>shared_dataset</code>, definita in precedenza, per creare le variabili condivise  di Theano per i dati (per essere copiati sulla GPU in modo da ottimizzare le prestazioni). Infine, restituiamo un insieme di coppie feature-risposta per i rispettive dataset di addestramento, convalida e testing.</p><p><span class="goog-text-highlight">Dopo aver descritto il codice per caricare il set di dati, dobbiamo implementare il metodo di addestramento della discesa stocastica del gradiente. </span>Questa è una funzione complessa e contiene molto codice. Proviamo quindi a descrivere i singoli blocchi che la compongono. In questa serie di articolo descriviamo molti esempi di addestramenti SGD, quindi ci sono altre occasioni dove approfondire questi concetti.</p><p>Il primo passo è definire la funzione e i suoi parametri:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-2a87854 elementor-widget elementor-widget-code-highlight" data-id="2a87854" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def stoch_grad_desc_train_model(
        filename, gamma=0.13, epochs=1000, B=600
):
    """
    Addestramento del modello di regrassione logistica
    usando la discesa stocastica del gradiente.

    filename - il percorso del file del dataset MNIST
    gamma - "learning rate" per la discesa del gradiente
    epochs - numero massimo di epoche per la SGD
    B - la dimensione per ogni minibatch
    """
    # Ottengo la corrette partizioni dei dataset
    datasets = load_mnist_data(filename)
    train_set_x, train_set_y = datasets[0]
    valid_set_x, valid_set_y = datasets[1]
    test_set_x, test_set_y = datasets[2]

    # Calcolo il numero di minibatc per ogni partizioni dei
    # dataset di addestramento, validazione e testting
    # Nota: Uso l'operatore // per restituisce la parte intera
    # del quoziente della divisione, ad es.
    # 1.0//2 is equal to 0.0
    # 1//2 is equal to 0
    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // B
    n_valid_batches = valid_set_x.get_value(borrow=True).shape[0] // B
    n_test_batches = test_set_x.get_value(borrow=True).shape[0] // B</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-59c87a7 elementor-widget elementor-widget-text-editor" data-id="59c87a7" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				I parametri di questa funzione sono il dataset <code>filename,</code> la dimensione dello step (o velocità di apprendimento) <code>gamma</code>, il numero massimo di <code>epochs</code> per eseguire l&#8217;algoritmo SGD e la dimensione del minibatch <code>B</code>. I valori predefiniti sono stati scelti in base a quelli suggeriti dal tutorial originale di regressione logistica di Theano.

Prima di tutto la funzione acquisisce i dataset MNIST e lo suddivide nei set di addestramento, convalida e test. Successivamente si calcola il numero di minibatch per ciascuna partizione dividendo le dimensioni di ciascun dataset per la dimensione del batch, <em>B</em>.

Il passaggio successivo è costruire il modello di regressione logistica:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-9625b97 elementor-widget elementor-widget-code-highlight" data-id="9625b97" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # COSTRUZIONE DEL MODELLO
    # ===============
    print("Building the logistic regression model...")

    # Creo le variabili simboliche per i dati del minibatch
    index = T.lscalar()  # valori scalari interi
    # Vettore delle feature, ad es. le immagini
    x = T.matrix('x')
    # Vettore degli interi che rappresentano le cifre
    y = T.ivector('y')

    # Inizializzazione del modello di regressione
    # logisita ed assegnazione del costo
    logreg = LogisticRegression(x=x, num_in=28 ** 2, num_out=10)
    cost = logreg.negative_log_likelihood(y)  # Questo deve essere minimizzato con la SGD

    # Creazione di un insieme di funzioni di Theano per i dataser di
    # testing e validazione che calcola gli errori del modello
    # per uno specifico minibatch
    test_model = theano.function(
        inputs=[index],
        outputs=logreg.errors(y),
        givens={
            x: test_set_x[index * B: (index + 1) * B],
            y: test_set_y[index * B: (index + 1) * B]
        }
    )

    validate_model = theano.function(
        inputs=[index],
        outputs=logreg.errors(y),
        givens={
            x: valid_set_x[index * B: (index + 1) * B],
            y: valid_set_y[index * B: (index + 1) * B]
        }
    )
</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-5f246f5 elementor-widget elementor-widget-text-editor" data-id="5f246f5" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Le variabili simboliche vengono create per memorizzare i dati del minibatch prima dell&#8217;istanziazione della clase <code>LogisticRegression</code>. Da notare la dimensione degli input <code>num_in</code>, che è pari a 28&#215;28 pixel per le immagini della calligrafia MNIST. La dimensione dell&#8217;output è 10, che rappresenta ciascuna delle cifre da 0 a 9.</p><p>La sezione successiva crea un set di funzioni Theano, che calcola gli errori associati a uno specifico minibatch di dati di test e addestramento. Fanno uso del metodo <code>errors</code> della classe <code>LogisticRegression </code>. Entrambe queste funzioni sono usate di seguito.</p><p>L&#8217;operatore simbolico <code>grad</code> di Theano è usato per calcolare il gradiente della log-verosimiglianza negativa rispetto alle variazioni dei sottostanti parametri <em>W</em> e <em>b</em>. A questo punto codifichiamo l&#8217;intervallo di discesa stocastica del stocastico nella lista <code>updates</code>. Infine usiamo un&#8217;ulteriore <code>function</code> di Theano, insieme al parametro <code>updates=updates</code> per valutare gli errori sul minibatch di addestramento e simultaneamente eseguire lo step di aggiornamento SGD sui parametri:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ecf5a3c elementor-widget elementor-widget-code-highlight" data-id="ecf5a3c" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
    # Uso di Theano per calcolare i gradienti simbolici della
    # funzione di costo (negative log likelihood) per i
    # sottostanti parametri W e b
    grad_W = T.grad(cost=cost, wrt=logreg.W)
    grad_b = T.grad(cost=cost, wrt=logreg.b)

    # Questo è la fase della discesa del gradiente.
    # Si specifica una lista di coppie, ognuna contiente una variabile
    # Theano e una espresione su come aggiornarla ad ogni step.
    updates = [
        (logreg.W, logreg.W - gamma * grad_W),
        (logreg.b, logreg.b - gamma * grad_b)
    ]

    # Simile al precedente insieme di funzioni di Theano, ma in questo
    # caso viene eseguita sui dati di allenamento e aggiorna i parametri
    # W, b in quanto valuta il costo per uno specifico minibatch
    train_model = theano.function(
        inputs=[index],
        outputs=cost,
        updates=updates,
        givens={
            x: train_set_x[index * B: (index + 1) * B],
            y: train_set_y[index * B: (index + 1) * B]
        }
    )
</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-d92288c elementor-widget elementor-widget-text-editor" data-id="d92288c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				La parte successiva della funzione riguarda l&#8217;effettivo ciclo di addestramento del modello:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e9d7f97 elementor-widget elementor-widget-code-highlight" data-id="e9d7f97" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
    # ADDESTRAMENTO DEL MODELLO
    # ===============
    print("Training the logistic regression model...")

    # Imposto i parametri per fermare anticipatamente il
    # minibatch se le performance sono abbastanza buone
    patience = 5000  # Numero minimo di esempi da valutare
    patience_increase = 2  # Aumento per il nuovo miglior punteggio
    improvement_threshold = 0.995  # Soglia di miglioramento relativo

    # Addrestramento su questo numero di minibatch prima di
    # controllare le prestazioni sul set di convalida
    validation_frequency = min(n_train_batches, patience // 2)

    # Tengo traccia della funzione obiettivo e dei punteggi del test
    best_validation_loss = np.inf
    test_score = 0.
    start_time = timeit.default_timer()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-289d440 elementor-widget elementor-widget-text-editor" data-id="289d440" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Definiamo una variabile chiamata <code>patience</code>, che usiamo per determinare il numero minimo iniziale di esempi da esaminare in ogni minibatch. Il valore di questo parametro aumenta all&#8217;aumentare delle prestazioni (cioè  al diminuire dell&#8217;errore di classificazione), dato che sono necessari più campioni per minibatch per aumentare continuamente le prestazioni relative per minibatch.</p><p>Inoltre calcoliamo la variabile <code>validation_frequency</code> per determinare la frequenza con cui valutare la performance della classificazione sul set di validazione. Infine iniziamo a cronometrare la durata della procedura di training tramite il modulo <code>timeit</code> di Python.</p><p>La seguente sezione del codice riguarda il ciclo di addestramento principale. È piuttosto lunga. Riportiamo il codice completo qui e lo descriviamo in dettaglio successivamente:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-f55a3ae elementor-widget elementor-widget-code-highlight" data-id="f55a3ae" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
    # Inizio del ciclo di addestramento
    # Il ciclo while esterno sul numero di epoche
    # Il ciclo for interno sui minibatch
    finished = False
    cur_epoch = 0
    while (cur_epoch < epochs) and (not finished):
        cur_epoch = cur_epoch + 1
        # Ciclo sui minibatch
        for minibatch_index in range(n_train_batches):
            # Calcolo della verosimiglianza media per i minibatch
            minibatch_avg_cost = train_model(minibatch_index)
            iter = (cur_epoch - 1) * n_train_batches + minibatch_index

            if (iter + 1) % validation_frequency == 0:
                # Se l'itezione corrente ha raggiunto la frequenza di validazione
                # allora si calcola la funzione obiettivo dei batch validati
                validation_losses = [
                    validate_model(i)
                    for i in range(n_valid_batches)
                ]
                this_validation_loss = np.mean(validation_losses)

                # Stampo i risultati della validazione corrente
                print(
                    "Epoch %i, Minibatch %i/%i, Validation Error %f %%" % (
                        cur_epoch,
                        minibatch_index + 1,
                        n_train_batches,
                        this_validation_loss * 100.
                    )
                )

                # Se il valore dell'ultima funzione obiettio è il migliore
                if this_validation_loss < best_validation_loss:
                    # Se la funzione obiettivo è all'interno della soglia
                    # di miglioramento, allora si incrementa il numero
                    # di iterazione ("patience") fino al prossimo controllo
                    if this_validation_loss < best_validation_loss * \
                            improvement_threshold:
                        patience = max(patience, iter * patience_increase)
                    # Importo la validazione corrente come la migliore
                    # validazione della perdita
                    best_validation_loss = this_validation_loss

                    # Calcolo le funzioni obiettivo sui minibatch nel
                    # dataset di testing. Il "test_score" è la media
                    # delle funzioni obiettivo
                    test_losses = [
                        test_model(i)
                        for i in range(n_test_batches)
                    ]
                    test_score = np.mean(test_losses)

                    # Stampa dei risultati del test corrente
                    print(
                        (
                            "     Epoch %i, Minibatch %i/%i, Test error of"
                            " best model %f %%"
                        ) % (
                            cur_epoch,
                            minibatch_index + 1,
                            n_train_batches,
                            test_score * 100.
                        )
                    )

                    # Salvataggio del modello su disco usando pickle
                    with open('best_model.pkl', 'wb') as f:
                        pickle.dump(logreg, f)
            # Se l'iterazione eccede l'attuale "patience"
            # allora fermo il loop oer questo minibatch
            if iter > patience:
                done_looping = True
                break

    end_time = timeit.default_timer()
    print(
        (
            "Optimization complete with "
            "best validation score of %f %%,"
            "with test performance %f %%"
        ) % (best_validation_loss * 100., test_score * 100.)
    )
    print(
        'The code run for %d epochs, with %f epochs/sec' % (
            cur_epoch,
            1. * cur_epoch / (end_time - start_time)
        )
    )
    print("The code ran for %.1fs" % (end_time - start_time))</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-3e2d65f elementor-widget elementor-widget-text-editor" data-id="3e2d65f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Il ciclo esterno è un ciclo <code>while</code> sul numero di epoche. Il ciclo interno è un ciclo <code>for</code> sul numero di minibatch di <em>addestramento</em>. Per ogni iterazione del ciclo interno, calcoliamo la negative log-likelihood media del minibatch tramite il metodo <code>train_model</code>, definito come una <code>function</code> di Theano.</p><p>Se il numero di iterazioni raggiunto è un multiplo della frequenza di <em>convalida</em>, calcoliamo la funzione obiettivo della validazione e stampiamo i risultati sulla console. A questo punto effettuiamo un controllo per verificare se abbiamo ottenuto la miglior funzione obiettivo della validazione, finora calcolata. In questo caso aumentiamo la variabile &#8220;patience&#8221; in modo da richiedere più iterazioni per il successivo miglioramento della validazione. A questo punto calcoliamo la negative log-likelihood sul dataset di testing e la stampiamo sulla console.</p><p>Quindi salviamo su disco (tramite <code>pickle</code>) l&#8217;attuale &#8220;migliore&#8221; modello di training. Se per questo minibatch superiamo il valore di &#8220;patience&#8221; allora passiamo al prossimo minibatch. Infine calcoliamo l&#8217;ora di fine e quindi stampiamo su console la migliore funzione obiettivo della validazione e tempo totale di esecuzione.</p><p>Questo completa la discesa stocastica del gradiente per il modello di regressione logistica con i parametri <em>W</em> e <em>b</em>.</p><h4>Testare il modello</h4><p>Rispetto all&#8217;addestramento del modello, la previsione delle cifre per la fase di test con nuovi dati mai visti è relativamente semplice. Il seguente frammento mostra come eseguire una previsione:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-643c0f4 elementor-widget elementor-widget-code-highlight" data-id="643c0f4" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def test_model(filename, num_preds):
    """
    Verifica del modello con un dataset MNIST di testing
    che il modello non ha mai visto
    """
    # Carichiamo il migliore modello salvato
    classifier = pickle.load(open('best_model.pkl'))

    # Uso di Theano per creare una funzione di previsione
    predict_model = theano.function(
        inputs=[classifier.x],
        outputs=classifier.y_pred
    )

    # Caricamento del dal dataset MNIST da "filename"
    # e isolamente dei dati di testing
    datasets = load_mnist_data(filename)
    test_set_x, test_set_y = datasets[2]
    test_set_x = test_set_x.get_value()

    # Predizione delle cifre per il numero 'num_preds' di immagini
    preds = predict_model(test_set_x[:num_preds])
    print(
        "Predicted digits for the first %s " \
        "images in test set:" % num_preds
    )
    print(preds)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-78888a6 elementor-widget elementor-widget-text-editor" data-id="78888a6" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Se hai utilizzato la libreria <a href="http://scikit-learn.org/stable/">Scikit-Learn</a> per eseguire qualsiasi lavoro di apprendimento automatico supervisionato, noterai che l&#8217;API non è troppo dissimile.</p><p>Il primo passaggio consiste nel caricare il modello <code>best_model.pkl</code> in pickled e inserirlo nella variabile <code>classifier</code>. Successivamente creiamo una funzione <code>theano.function</code>, che prende il vettore delle feature <code>x</code> in input e restituisce i valori previsti per le cifre <code>y_pred</code>. Quindi carichiamo il dataset effettivo e isoliamo il set di test. Infine creiamo un vettore di previsioni, <code>preds</code>, che contiene le previsioni di cifre per le prime <code>num_preds</code> immagini nel dataset di test.</p><h4>Script principale</h4><p>Di seguito il codice per unire tutti i pezzi e lanciare lo script:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-752f896 elementor-widget elementor-widget-code-highlight" data-id="752f896" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
if __name__ == "__main__":
    # Impostazione del dataset e del numero di
    # predizioni da fare sui dati di testing
    dataset_filename = "mnist.pkl.gz"
    num_preds = 20

    # Addestramento del modello tramite la
    # discesa stocastica del gradiente
    stoch_grad_desc_train_model(dataset_filename)

    # Verifica delle regressione logistica su un
    # dataset di test mai visto
    test_model(dataset_filename, num_preds)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-d820743 elementor-widget elementor-widget-text-editor" data-id="d820743" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Esecuzione del modello sulla CPU o sulla GPU</h2>
Per eseguire il codice sulla CPU possiamo usare il seguente comando da terminale. Usiamo il simbolo del dollaro per indicare che si tratta di un comando da terminale, quindi assicurati di non includerlo quando copi e incolli il codice nel terminale:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-8f4c78b elementor-widget elementor-widget-code-highlight" data-id="8f4c78b" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-markup ">
				<code readonly="true" class="language-markup">
					<xmp>$ THEANO_FLAGS=mode=FAST_RUN,device=cpu,floatX=float32 python deep_logistic_regression_theano.py</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-c8fa5e7 elementor-widget elementor-widget-text-editor" data-id="c8fa5e7" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Otteniamo un output simile al seguente:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-f614b36 elementor-widget elementor-widget-code-highlight" data-id="f614b36" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-markup ">
				<code readonly="true" class="language-markup">
					<xmp>Building the logistic regression model...
Training the logistic regression model...
Epoch 1, Minibatch 83/83, Validation Error 12.458333 %
     Epoch 1, Minibatch 83/83, Test error of best model 12.375000 %
Epoch 2, Minibatch 83/83, Validation Error 11.010417 %
     Epoch 2, Minibatch 83/83, Test error of best model 10.958333 %
Epoch 3, Minibatch 83/83, Validation Error 10.312500 %
     Epoch 3, Minibatch 83/83, Test error of best model 10.312500 %
Epoch 4, Minibatch 83/83, Validation Error 9.875000 %
     Epoch 4, Minibatch 83/83, Test error of best model 9.833333 %
Epoch 5, Minibatch 83/83, Validation Error 9.562500 %
     Epoch 5, Minibatch 83/83, Test error of best model 9.479167 %
Epoch 6, Minibatch 83/83, Validation Error 9.322917 %
     Epoch 6, Minibatch 83/83, Test error of best model 9.291667 %
..
.. --TRUNCATED--
..
Epoch 71, Minibatch 83/83, Validation Error 7.520833 %
Epoch 72, Minibatch 83/83, Validation Error 7.510417 %
Epoch 73, Minibatch 83/83, Validation Error 7.500000 %
     Epoch 73, Minibatch 83/83, Test error of best model 7.489583 %
Epoch 74, Minibatch 83/83, Validation Error 7.479167 %
     Epoch 74, Minibatch 83/83, Test error of best model 7.489583 %
Optimization complete with best validation score of 7.479167 %,with test performance 7.489583 %
The code run for 1000 epochs, with 37.882747 epochs/sec
The code ran for 26.4s
Predicted digits for the first 20 images in test set:
[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-54cec09 elementor-widget elementor-widget-text-editor" data-id="54cec09" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Sul mio desktop con un Intel Core i7-4770K, overcloccato a 3,50 Ghz, ci sono voluti 26,4 secondi.</p><p>In alternativa, per eseguire  lo script sulla GPU dobbiamo inserire nel terminale il seguente comando:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-028c10e elementor-widget elementor-widget-code-highlight" data-id="028c10e" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-markup ">
				<code readonly="true" class="language-markup">
					<xmp>$ THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python deep_logistic_regression_theano.py</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-9eb90ab elementor-widget elementor-widget-text-editor" data-id="9eb90ab" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				In questo caso otteniamo un output simile al seguente:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-003af9b elementor-widget elementor-widget-code-highlight" data-id="003af9b" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-markup ">
				<code readonly="true" class="language-markup">
					<xmp>Using gpu device 0: GeForce GTX 780 Ti (CNMeM is disabled, cuDNN not available)
Building the logistic regression model...
Training the logistic regression model...
Epoch 1, Minibatch 83/83, Validation Error 12.458333 %
     Epoch 1, Minibatch 83/83, Test error of best model 12.375000 %
Epoch 2, Minibatch 83/83, Validation Error 11.010417 %
     Epoch 2, Minibatch 83/83, Test error of best model 10.958333 %
Epoch 3, Minibatch 83/83, Validation Error 10.312500 %
     Epoch 3, Minibatch 83/83, Test error of best model 10.312500 %
Epoch 4, Minibatch 83/83, Validation Error 9.875000 %
     Epoch 4, Minibatch 83/83, Test error of best model 9.833333 %
Epoch 5, Minibatch 83/83, Validation Error 9.562500 %
     Epoch 5, Minibatch 83/83, Test error of best model 9.479167 %
Epoch 6, Minibatch 83/83, Validation Error 9.322917 %
     Epoch 6, Minibatch 83/83, Test error of best model 9.291667 %
..
.. --TRUNCATED--
..
Epoch 71, Minibatch 83/83, Validation Error 7.520833 %
Epoch 72, Minibatch 83/83, Validation Error 7.510417 %
Epoch 73, Minibatch 83/83, Validation Error 7.500000 %
     Epoch 73, Minibatch 83/83, Test error of best model 7.489583 %
Epoch 74, Minibatch 83/83, Validation Error 7.479167 %
     Epoch 74, Minibatch 83/83, Test error of best model 7.489583 %
Optimization complete with best validation score of 7.479167 %,with test performance 7.489583 %
The code run for 1000 epochs, with 251.317223 epochs/sec
The code ran for 4.0s
Predicted digits for the first 20 images in test set:
[7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4]</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-e39a004 elementor-widget elementor-widget-text-editor" data-id="e39a004" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Sulla stessa macchina desktop con una GeForce GTX 780 Ti abilitata per NVidia CUDA sono stati necessari 4,0 secondi, cioè un fattore di accelerazione di 6,6x per questo script. In prospettiva, un&#8217;attività di allenamento che richiede una settimana su una CPU richiederà solo poco più di un giorno sulla GPU. Quindi, se sei seriamente intenzionato a costruire una macchina o un cluster per la ricerca di deep learning, vale la pena considerare l&#8217;uso delle GPU. Sono il modo più semplice per aumentare le prestazioni per la maggior parte delle architetture di deep learning.</p><h2>Prossimi passi</h2><p>Sebbene la regressione logistica non sia certo una tecnica all&#8217;avanguardia ai fini della classificazione, ci consente di esplorare l&#8217;API di Theano, costruire un modello non banale su un set di dati di grandi dimensioni, addestrare il modello sia sulla CPU che sulla GPU e prevedere nuove classificazioni da questo modello.</p><p>Nel prossimo articolo descriviamo il nostro primo modello di rete neurale, ovvero il perceptron multistrato (MLP). Costruiamo un MLP con Theano e lo usiamo per lo stesso compito di classificazione supervisionato per predire le cifre MNIST. Quindi verifichiamo se le prestazioni sono migliori rispetto al modello di regressione logistica.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c22d6b3 elementor-widget elementor-widget-text-editor" data-id="c22d6b3" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Risorse aggiuntive per Machine Learning, Deep Learning e GPU</h2><ul><li><a href="https://www.coursera.org/learn/machine-learning">Coursera: Machine Learning by Andrew Ng</a></li><li><a href="https://developer.nvidia.com/deep-learning-courses">NVIDIA Self-Study Courses for Deep Learning</a></li><li><a href="https://www.udacity.com/course/intro-to-parallel-programming--cs344">Udacity: Intro to Parallel Programming &#8211; Using CUDA to Harness the Power of GPUs</a></li><li><a href="http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/" class="broken_link">Tim Dettmers Blog &#8211; A Full Hardware Guide to Deep Learning</a></li></ul><h2>Riferimenti</h2><ul><li><a href="http://www.iro.umontreal.ca/~pift6266/H10/notes/mlintro.html" name="ift6266-intro-ml-ai">[1] Very Brief Introduction to Machine Learning for AI, <em>IFT6266 Winter 2010</em></a></li><li><a href="http://www.iro.umontreal.ca/~pift6266/H10/notes/deepintro.html" name="ref-ift6266-intro-dl">[2] Introduction to Deep Learning Algorithms, <em>IFT6266 Winter 2010</em></a></li><li><a href="http://www.iro.umontreal.ca/~bengioy/papers/ftml.pdf" name="ref-bengio" class="broken_link">[3] Bengio, Y. (2009). Learning Deep Architectures for AI. <em>Foundations and Trends in Machine Learning</em> <strong>2</strong> (1), pg1-127</a></li><li><a href="http://deeplearning.net/tutorial/index.html" name="ref-deeplearningnet" class="broken_link">[4] Deep Learning Tutorials, <em>deeplearning.net</em></a></li><li><a href="http://deeplearning.net/software/theano/index.html" name="ref-theano" class="broken_link">[5] Bergstra, J. et al. (2010) &#8220;Theano: A CPU and GPU Math Expression Compiler&#8221;. <em>Proceedings of the Python for Scientific Computing Conference (SciPy) 2010. June 30 &#8211; July 3, Austin, TX</em></a></li><li><a href="http://neuralnetworksanddeeplearning.com/index.html" name="ref-nielson">[6] Nielson, M. (2015). &#8220;Neural Networks and Deep Learning&#8221;, <em>Determination Press</em></a></li><li><a href="http://arxiv.org/pdf/1312.5602v1.pdf" name="ref-deepmind-atari">[7] Playing Atari with Deep Reinforcement Learning, <em>DeepMind Technologies</em></a></li><li><a href="http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html" name="ref-deepmind-go">[8] Silver, D. et al. (2016). Mastering the Game of Go with Deep Neural Networks and Tree Search, <em>Nature</em> <strong>529</strong>, p484-489</a></li><li><a href="https://en.wikipedia.org/wiki/Deep_learning" name="ref-wiki-deep-learning">[9] Wikipedia: Deep Learning</a></li><li><a href="http://markus.com/deep-learning-101/" name="ref-beissinger">[10] Beissinger, M. (2013). &#8220;Deep Learning 101&#8221;</a></li><li><a href="https://www.researchgate.net/publication/260086856_A_Review_of_Unsupervised_Feature_Learning_and_Deep_Learning_for_Time-Series_Modeling" name="ref-langkvist" class="broken_link">[11] Längkvist, M.J. (2014). &#8220;A Review of Unsupervised Feature Learning and Deep Learning for Time-Series Modeling&#8221;. <em>Pattern Recognition Letters</em> <strong>42</strong> (1)</a></li><li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" name="ref-esl">[12] Hastie, T., Tibshirani, R., Friedman, J. (2009) <em>The Elements of Statistical Learning</em>, Springer</a></li><li><a href="http://www-bcf.usc.edu/~gareth/ISL/" name="ref-isl">[13] James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) <em>An Introduction to Statistical Learning</em>, Springer</a></li><li><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent" name="ref-sgd">[14] Wikipedia: Stochastic Gradient Descent</a></li><li><a href="http://deeplearning.net/tutorial/logreg.html" name="ref-theano-logreg" class="broken_link">[15] Classifying MNIST digits using Logistic Regression, <em>deeplearning.net</em></a></li><li><a href="http://yann.lecun.com/exdb/mnist/" name="ref-mnist">[16] LeCun, Y., Cortes, C., Burges, C.J.C., (2012). MNIST Database of Handwritten Digits</a></li></ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/deep-learning-con-theano-regressione-logistica/">Deep Learning con Theano &#8211; Regressione Logistica</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>K-Means Clustering dei dati giornalieri con barre OHLC</title>
		<link>https://datatrading.info/k-means-clustering-dei-dati-giornalieri-con-barre-ohlc/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Thu, 14 Dec 2017 18:38:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Statistical Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5097</guid>

					<description><![CDATA[<p>In questo articolo descriviamo il concetto di clustering non supervisionato . Nella finanza quantitativa, è estremamente utile trovare gruppi di asset simili o regimi nelle serie di prezzi  degli asset. Può aiutare nello sviluppo di filtri o regole di ingresso e uscita. Questo aiuta a migliorare la redditività per determinate strategie di trading. Il clustering &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/k-means-clustering-dei-dati-giornalieri-con-barre-ohlc/"> <span class="screen-reader-text">K-Means Clustering dei dati giornalieri con barre OHLC</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/k-means-clustering-dei-dati-giornalieri-con-barre-ohlc/">K-Means Clustering dei dati giornalieri con barre OHLC</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5097" class="elementor elementor-5097">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-ab2a4b1 elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="ab2a4b1" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-befd42b" data-id="befd42b" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-4b28a6b elementor-widget elementor-widget-text-editor" data-id="4b28a6b" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>In questo articolo descriviamo il concetto di clustering non supervisionato . Nella finanza quantitativa, è estremamente utile trovare gruppi di asset simili o regimi nelle serie di prezzi  degli asset. Può aiutare nello sviluppo di filtri o regole di ingresso e uscita. Questo aiuta a migliorare la redditività per determinate strategie di trading.</p><p>Il clustering è un metodo di apprendimento non supervisionato che tenta di suddividere i dati osservativi in ​​sottogruppi o cluster separati. Il risultato che si vuole ottenere con il raggruppamento consiste nel garantire che le osservazioni all&#8217;interno dei cluster siano simili tra loro ma diverse dalle osservazioni in altri cluster.</p><p>Il clustering è una vasta area di ricerca accademica ed è difficile fornire una completa tassonomia degli algoritmi di clustering in  un solo articolo. Quindi ci concentriamo su una tecnica ampiamente utilizzata nota come K-Means Clustering.</p><p>Applichiamo il K-Means Clustering ai dati giornalieri  rappresentati con le &#8220;barre OHLC&#8221; &#8211; open, high, low, close (cioè apertura, massimo, minino, chiusura) .- al fine di identificare cluster separati &#8220;di candele&#8221;. Questi cluster possono essere utilizzati per verificare se esistono determinati regimi di mercato, come abbiamo visto con i <a href="https://datatrading.info/modelli-di-markov-nascosti-per-determinare-il-regime-di-mercato/">Hidden Markov Models</a>.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-207f1c9 elementor-widget elementor-widget-text-editor" data-id="207f1c9" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>K-Means Clustering</h2><p>K-Means Clustering è una particolare tecnica per identificare sottogruppi o cluster all&#8217;interno di una serie di osservazioni. È una tecnica di <em>hard</em> clustering, cioè ogni osservazione è costretta ad avere un&#8217;associazione univoca ad un solo cluster. Questo è in contrasto con la tecnica di  <em>soft</em> clustering, o probabilistica, che assegna si limita ad assegnare probabilità di appartenenza al cluster.</p><p>Per utilizzare il K-Means Clustering è necessario specificare un parametro <em>K</em>, cioè il numero di cluster desiderati in cui partizionare i dati. Questi <em>K </em>cluster non si sovrappongono e hanno confini &#8220;ben definiti&#8221; tra di  essi (vedere la figura seguente). Il compito è assegnare ciascuna delle <em>N </em>osservazioni in uno dei <em>K</em> cluster, in cui ogni osservazione appartiene al cluster con la media del vettore feature/osservazione più vicina.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fefe983 elementor-widget elementor-widget-image" data-id="fefe983" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="564" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-boundaries-768x564.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-clustering-k-means-boundaries" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-boundaries-768x564.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-boundaries-300x220.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-boundaries-160x117.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-boundaries.png 1030w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-4600e6d elementor-widget elementor-widget-text-editor" data-id="4600e6d" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Matematicamente possiamo definire gli insiemi \(S_k\), con \(k \in \{ 1,\ldots,K \}\), ognuno dei quali contiene gli indici del sottoinsieme delle <em>N</em> osservazioni che si trovano in ogni cluster. Questi insiemi coprono in modo esaustivo tutti gli indici, ovvero ogni osservazione appartiene ad almeno uno degli insiemi \(S_k\) e i cluster si escludono a vicenda con confini &#8220;hard&#8221;:</p><ul><li>\({\bf S} = \bigcup_{k=1}^K S_k = \{ 1,\ldots,N \}\)</li><li>\(S_k \cap S_{k&#8217;} = \phi, \quad \forall k \neq k&#8217;\)</li></ul><p>L&#8217;obiettivo di K-Means Clustering è ridurre al minimo la <em>Within-Cluster Variation</em> (WCV), nota anche come <em>Within-Cluster Sum of Squares</em> (WCSS). Questo concetto rappresenta la somma tra i cluster della somma delle distanze da ciascun punto del cluster alla sua media. In altre parole, misura quanto le osservazioni all&#8217;interno di un cluster differiscono l&#8217;una dall&#8217;altra. E&#8217; quindi necessario minimizzare:</p><p style="text-align: center;">\(\begin{eqnarray}\text{argmin}_{\bf S} \sum_{k=1}^K \sum_{{\bf x}_i \in S_k} \| {\bf x}_i &#8211; {\bf \mu}_k \|\end{eqnarray}\)</p><p>Dove \({\bf \mu}_k\) rappresenta il vettore delle feature medie del cluster <em>k</em> e \({\bf x}_i\) è l&#8217;<em>i</em>-esimo vettore delle feature nel cluster <em>k</em>.</p><p>Sfortunatamente questa particolare minimizzazione è difficile da risolvere a <em>livello globale</em>, cioè trovare un minimo globale per questo problema è <a href="https://it.wikipedia.org/wiki/NP-difficile">NP-difficile</a> a livello di complessità.</p><p>Fortunatamente esistono utili algoritmi euristici per trovare minimi <em>locali</em> accettabili.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-aaa765d elementor-widget elementor-widget-text-editor" data-id="aaa765d" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>L&#8217;algoritmo</h4><p>L&#8217;algoritmo euristico per risolvere il K-Means clustering è noto come algoritmo K-Means. È relativamente semplice da descrivere e si compone di due passaggi, il secondo dei quali viene ripetuto fino al completamento:</p><ol><li>Assegnare ogni osservazione \({\bf x}_i\) a un cluster casuale <em>k</em>.</li><li>Iterare quanto segue finché l&#8217;assegnazione del cluster non rimane fissa:<br /><ul><li>Calcolare il vettore delle feature medie di ciascun cluster, il centroide \({\bf \mu}_k\).</li><li>Assegnare ogni osservazione \({\bf x}_i\) al \({\bf \mu}_k\) più vicino, dove la &#8220;vicinanza&#8221; è data dalla distanza euclidea standard.</li></ul></li></ol><p>Non descriviamo il motivo per cui questo algoritmo garantisce di trovare un  minimo locale. Per una discussione più dettagliata della teoria matematica alla base dell&#8217;algoritmo si può far riferimento ai lavori di James et al (2009) [1] e Hastie et al (2009) [2] .</p><p>Poiché le osservazioni sono  inizialmente assegnate ai cluster in modo casuale possiamo notare che la determinazione del miglior minimo locale è fortemente dipendente da queste assegnazioni iniziali. In pratica l&#8217;algoritmo è eseguito più volte (l&#8217;impostazione predefinita per <a href="http://scikit-learn.org/stable/">Scikit-Learn</a> è dieci volte) e viene scelto il miglior minimo locale, ovvero quello che minimizza maggiormente il WCSS.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ba9840a elementor-widget elementor-widget-text-editor" data-id="ba9840a" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Criticità</h4><p>L&#8217;algoritmo K-Means non è esente da difetti. Nella finanza quantitativa abbiamo un basso rapporto segnale/rumore nei dati dei prezzi finanziari, quindi l&#8217;algoritmo K-Means ha difficoltà ad estrarre il segnale predittivo da usare per le strategie di trading.</p><p>La natura dell&#8217;algoritmo K-Means prevede la generazione di <em>k</em> cluster, anche se i dati sono molto rumorosi. Questo implica che tali &#8220;cluster&#8221; non sono distribuzioni di dati veramente separate, ma sono in realtà artefatti di un set di dati rumoroso. E&#8217; uno dei problemi più difficili da affrontare nel trading quantitativo.</p><p>Un altro aspetto nello specificare un <em>k</em> consiste che determinati punti dati anomali verranno automaticamente assegnati a un cluster, indipendentemente dal fatto che facciano veramente parte della &#8220;distribuzione&#8221; che li ha generati o meno. Questo è causato dalla necessità di imporre un confine rigido del cluster. In finanza i punti dati &#8220;anomali&#8221; non sono rari, non da ultimo a causa di errori o tick negativi, ma anche a causa di flash crash e altri rapidi cambiamenti del prezzo di un asset.</p><p>Inoltre, lo stesso metodo di clustering è abbastanza sensibile alle variazioni nel set di dati sottostante. In altre parole, se una serie di prezzi di un asset finanziario è divisa in due gruppi e due diversi algoritmi K-Means sono stati adattati a ciascuno gruppo, condividendo lo stesso parametro <em>k</em>, è molto probabile ottenere due assegnazioni di cluster molto diverse. Questo solleva la domanda sulla robustezza di tale meccanismo su piccoli set di dati finanziari. Come sempre, anche in questo caso può essere utili usare più dati.</p><p>Queste criticità motivano  l&#8217;introduzione algoritmi di clustering più sofisticati, che esulano dallo scopo di questo articolo sia a causa delle grande gamma dei metodi disponibile che a causa della loro maggiore  complessità matematica. Tuttavia, per coloro che sono interessati ad approfondire il clustering non supervisionato, dovrebbero essere presi in considerazione i seguenti metodi:</p><ul><li><a href="https://en.wikipedia.org/wiki/Mixture_model">Modelli Gaussian Mixture</a> / <a href="https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm">Algoritmo EM</a> </li><li>Algoritmi <a href="https://en.wikipedia.org/wiki/DBSCAN">DBSCAN</a> e <a href="https://en.wikipedia.org/wiki/OPTICS_algorithm">OPTICS</a></li><li>Architetture di Deep Neural Network: <a href="https://en.wikipedia.org/wiki/Autoencoder">Autoencoder</a> e <a href="https://en.wikipedia.org/wiki/Restricted_Boltzmann_machine">macchine di Boltzmann con restrizioni</a></li></ul><p>Descriviamo ora la simulazione dei dati e all&#8217;adattamento dell&#8217;algoritmo K-Means ad essi.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-38b8637 elementor-widget elementor-widget-text-editor" data-id="38b8637" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Dati simulati</h4><p>In questo paragrafo descriviamo come applicare il K-Means Clustering ad un insieme di dati simulati, in modo da avere familiarità con la specifica <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">implementazione Scikit-Learn per questo algoritmo</a>. Inoltre descriviamo come la scelta di <em>k</em> nell&#8217;algoritmo è estremamente importante per assicurarsi di ottenere buoni risultati.</p><p>In particolare descriviamo come campionare tre  separate distribuzioni gaussiane bidimensionali per creare una selezione dei dati osservati. Usiamo quindi l&#8217;algoritmo K-Means, con diversi valori del parametro <em>k</em> per dedurre l&#8217;appartenenza al cluster. Infine tracciamo il grafico di un confronto tra due diversi valori di <em>k</em> due scelte separate, insieme all&#8217;appartenenza al cluster dedotta in base al colore.</p><p>Analoghi esercizi con i dati simulati sono stati effettuati  in precedenti articoli. Aiutano a identificare i potenziali difetti nei modelli su dati sintetici, le cui proprietà statistiche sono facilmente controllabili. In questo modo abbiamo una visione approfondita dei limiti di tali modelli prima della loro applicazione su dati finanziari reali, dove sicuramente non conosciamo a priori le proprietà statistiche!</p><p>Il primo passo è importare le librerie necessarie. La libreria <code>itertools</code> di Python è utilizzata per concatenare insieme liste di liste durante la generazione di dati campione casuali. Itertools è una libreria estremamente utile, che può far risparmiare una notevole quantità di tempo di sviluppo. Leggere la <a href="https://docs.python.org/3/library/itertools.html">documentazione</a> è un buon esercizio per qualsiasi sviluppatore o trader in erba.</p><p>Le restanti librerie da importare sono NumPy, Matplotlib e la classe <code>KMeans</code> di Scikit-Learn, che risiede nel modulo <code>cluster</code>:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fb9e824 elementor-widget elementor-widget-code-highlight" data-id="fb9e824" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp># simulated_data.py

import itertools

import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-af5e1d4 elementor-widget elementor-widget-text-editor" data-id="af5e1d4" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>All&#8217;interno della funzione <code>__main__</code> impostiamo prima di tutto il seme casuale in modo che il seguente codice sia completamente riproducibile. Successivamente impostiamo il numero di campioni per ciascun cluster (<code>samples=100</code>), nonché le matrici bidimensionali della media e covarianza di ciascun cluster gaussiano (uno per ogni elemento in ciascuna lista).</p><p>La lista <code>norm_dist</code> contiene tre separate liste bidimensionali di osservazioni, una per ciascun cluster. Infine i dati osservati <em>X</em> sono generati concatenando ciascuna di queste sottoliste, utilizzando la libreria itertools:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-9d26591 elementor-widget elementor-widget-code-highlight" data-id="9d26591" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>np.random.seed(1)

# Imposto il numero di campioni, la media e la 
# varianza per ognuno dei tre cluster simulati
samples = 100
mu = [(7, 5), (8, 12), (1, 10)]
cov = [
    [[0.5, 0], [0, 1.0]],
    [[2.0, 0], [0, 3.5]],
    [[3, 0], [0, 5]],
]

# Generazione di una lista di cluster 2D
norm_dists = [
    np.random.multivariate_normal(m, c, samples) 
    for m, c in zip(mu, cov)
]
X = np.array(list(itertools.chain(*norm_dists)))</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-a0bb0a4 elementor-widget elementor-widget-text-editor" data-id="a0bb0a4" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Come con molte implementazioni di modelli di machine learning con Scikit-Learn, l&#8217;API è estremamente semplice. In questo caso consiste nell&#8217;inizializzare la classe <code>KMeans</code> con il parametro <code>n_clusters</code>, che rappresenta il numero di cluster da trovare, e poi chiamare il metodo <code>fit</code> sui dati osservati. Le assegnazioni del cluster possono essere estratte dalla proprieta <code>labels_</code>.</p><p>Nel seguente codice questa procedura viene eseguita sia per k=3 che per k=4 sullo stesso set di dati:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-b70291f elementor-widget elementor-widget-code-highlight" data-id="b70291f" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp># Applico l'algoritmo K-Means per k=3, che è uguale
# al numero dei veri cluster gaussiani
km3 = KMeans(n_clusters=3)
km3.fit(X)
km3_labels = km3.labels_

# Applico l'algoritmo K-Means per k=4, che è uguale
# al numero dei veri cluster gaussiani
km4 = KMeans(n_clusters=4)
km4.fit(X)
km4_labels = km4.labels_</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-721830a elementor-widget elementor-widget-text-editor" data-id="721830a" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Infine creiamo due grafici a dispersione dei dati tramite la libreria Matplotlib, uno per k=3 e uno per k=4, utilizzando i colori per rappresentare le assegnazioni dei cluster mediante l&#8217;algoritmo K-Means:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-4d415c9 elementor-widget elementor-widget-code-highlight" data-id="4d415c9" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp># Creo il grafico per confrontare l'algoritmo 
# K-Means per k=3 e k=4 
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14,6))
ax1.scatter(X[:, 0], X[:, 1], c=km3_labels.astype(np.float))
ax1.set_xlabel("$x_1$")
ax1.set_ylabel("$x_2$")
ax1.set_title("K-Means con $k=3$")
ax2.scatter(X[:, 0], X[:, 1], c=km4_labels.astype(np.float))
ax2.set_xlabel("$x_1$")
ax2.set_ylabel("$x_2$")
ax2.set_title("K-Means con $k=4$")
plt.show()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-a18b791 elementor-widget elementor-widget-text-editor" data-id="a18b791" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Di seguito l&#8217;output del codice:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-1ada27e elementor-widget elementor-widget-image" data-id="1ada27e" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="381" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-simulated-768x381.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-clustering-k-means-simulated" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-simulated-768x381.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-simulated-300x149.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-simulated-160x79.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-k-means-simulated.png 800w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c49daa9 elementor-widget elementor-widget-text-editor" data-id="c49daa9" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p><em>Da notare che le differenze di colore tra i due grafici  rappresentano solamente la presenza di un diverso numero di cluster, piuttosto che qualsiasi altra relazione implicita.</em></p><p>L&#8217;intero set di dati bidimensionale è stato generato dal campionamento di tre  separate distribuzioni gaussiane con medie e varianze diverse. Risulta subito evidente che la scelta di <em>k</em> quando si esegue l&#8217;algoritmo K-Means è importante per l&#8217;interpretazione dei risultati.</p><p>Nel grafico di sinistra l&#8217;algoritmo è costretto a scegliere tra tre cluster. Ha catturato in gran parte i tre  separati gruppi gaussiani, assegnando rispettivamente i colori blu, rosso e verde. Chiaramente ci sono difficoltà a selezionare i cluster più vicini per i punti &#8220;periferici&#8221; di ciascun cluster che si trovano nelle vicinanze di \(x_1=5,x_2=8\). Questa è una situazione critica per qualsiasi algoritmo di clustering che implica la &#8220;sovrapposizione&#8221; dei dati.</p><p>Ricordiamo che l&#8217;algoritmo K-Means è uno strumento di <em>hard</em> clustering, cioè crea un  distinto confine &#8220;<em>hard</em>&#8221; tra l&#8217;appartenenza ad un cluster o ad un&#8217;altro, piuttosto che assegnare probabilisticamente l&#8217;appartenenza come in un algoritmo di &#8220;soft&#8221; cluster.</p><p>Nel grafico di destra l&#8217;algoritmo è costretto a scegliere tra quattro cluster e ha diviso il raggruppamento sul lato sinistro del grafico in due regioni separate (gialla e verde). Tuttavia è noto che questo cluster è stato generato da una singola distribuzione gaussiana e quindi l&#8217;algoritmo ha assegnato i dati &#8220;in modo errato&#8221;. I restanti cluster sul lato destro sono invece &#8220;correttamente&#8221; identificati .</p><p>La scelta di <em>k</em> ha significative implicazioni sull&#8217;utilità dell&#8217;algoritmo, in particolare per quanto riguarda le applicazioni di trading quantitativo. Di seguito vediamo come la scelta di <em>k</em> può avere un impatto  significativo sull&#8217;efficacia della capacità predittiva per i dati finanziari reali.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-99baf16 elementor-widget elementor-widget-text-editor" data-id="99baf16" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Clustering OHLC</h4><p>In questo paragrafo applichiamo il K-Means clustering ai dati giornalieri Open-High-Low-Close (OHLC), noti anche come <em>barre</em> o <em>candele</em>. Questa analisi è interessante perché considera dimensioni extra dei dati giornalieri che sono spesso ignorate, a favore del solo utilizzo di prezzi di chiusura rettificati.</p><p>Dato che è importante confrontare ciascuna candela su una base &#8220;simile&#8221;, dobbiamo normalizzare ciascuna delle dimensioni High, Low e Close con il corrispondente prezzo di apertura. Si ha l&#8217;ulteriore vantaggio di rettificare/aggiustare automaticamente i prezzi  in base agli split azionari, ai dividendi e altri eventi aziendali &#8220;discreti&#8221; che incidono sui prezzi. Normalizzando ciascuna candela con questa logica, si riduce la dimensione da quattro (Aperto, Alto, Basso, Chiuso) a tre (Alto/Aperto, Basso/Aperto, Chiuso/Aperto).</p><p>Nel seguente codice scarichiamo due anni di dati  dell&#8217;indice S&amp;P500. Rappresentiamo graficamente le candele utilizzando Matplotlib. Quindi normalizziamo  i dati come appena descritto, e li raggruppiamo utilizzando K-Means e quindi  creiamo un diagramma a dispersione tridimensionale per visualizzare l&#8217;appartenenza al cluster.<br />A questo punto applichiamo nuovamente le etichette del cluster ai dati della candela originali e le usiamo per visualizzare l&#8217;appartenenza al cluster (così come i confini) su un grafico a candela ordinato in base all&#8217;etichetta del cluster. Infine, creiamo una &#8220;matrice di follow-on&#8221;, che descrive la frequenza che il cluster di domani sia <em>j</em>, se il cluster di oggi è <em>i</em>. Tale matrice è utile per verificare se c&#8217;è la possibilità di costruire una strategia di trading predittiva basata sull&#8217;appartenenza al cluster di oggi.</p><p>Questo codice richiede molte importazioni. La maggior parte di questi sono relative alle opzioni di formattazione richieste da Matplotlib. La libreria standard <code>copy</code> è usata per creare copie complete dei DataFrames in modo che i dati non siano sovrascritte da ogni successiva funzione  grafica. Inoltre, importiamo NumPy e Pandas per la manipolazione dei dati. Infine importiamo il modulo <code>KMeans</code>da Scikit-Learn:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-a0ae4b3 elementor-widget elementor-widget-code-highlight" data-id="a0ae4b3" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp># ohlc_clustering.py

import copy
import datetime

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from mplfinance.original_flavor import candlestick_ohlc
import matplotlib.dates as mdates
from matplotlib.dates import (
    DateFormatter, WeekdayLocator, DayLocator, MONDAY
)
import numpy as np
import pandas as pd
import yfinance as yf
from sklearn.cluster import KMeans</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-b8f4614 elementor-widget elementor-widget-text-editor" data-id="b8f4614" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>La prima funzione da implementare crea una serie temporale tridimensionale a partire dai dati OHLC dei prezzi finanziari. Ciascuna dimensione rappresenta rispettivamente i prezzi normalizzati per high/open, low/open e close/open. Si eliminano le altre colonne e si restituisce il DataFrame:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-8417b3e elementor-widget elementor-widget-code-highlight" data-id="8417b3e" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def get_open_normalised_prices(data):
    """
    Restituisce un DataFrame pandas contenenti i prezzi high, low
    e close normalizzati con il prezzo open per i dati OHLC. 
    Cioè si crea le colonne High/Open, Low/Open e Close/Open
    """
    df = data.copy()
    df["H/O"] = df["High"]/df["Open"]
    df["L/O"] = df["Low"]/df["Open"]
    df["C/O"] = df["Close"]/df["Open"]
    df.drop(
        [
            "Open", "High", "Low",
            "Close", "Volume", "Adj Close"
        ],
        axis=1, inplace=True
    )
    return df</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-e1d8783 elementor-widget elementor-widget-text-editor" data-id="e1d8783" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>La seguente funzione <code>plot_candlesticks</code> utilizza il metodo <code>candlestick_ohlc</code> di Matplotlib per creare un grafico a candele della serie dei prezzi finanziari fornita come parametro. La maggior parte della funzione consiste nelle specifiche di Matplotlib necessarie per ottenere una corretta formattazione dei dati. I commenti spiegano ogni istruzione in modo dettagliato:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-19c7970 elementor-widget elementor-widget-code-highlight" data-id="19c7970" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def plot_candlesticks(data, since):
    """
    Visualizzo il grafico a candele dei prezzi,
    con specifica formatazzione delle date
    """
    # Copio e resetto l'indice del dataframe
    # per usare solo un sottoinsieme dei dati
    df = copy.deepcopy(data)
    df = df[df.index >= since]
    df.reset_index(inplace=True)
    df['date_fmt'] = df['Date'].apply(
        lambda date: mdates.date2num(date.to_pydatetime())
    )

    # Imposto la corretta formattazione dell'asse delle date
    # con Lunedi evidenziato come un punto principale
    mondays = WeekdayLocator(MONDAY)
    alldays = DayLocator()
    weekFormatter = DateFormatter('%b %d')
    fig, ax = plt.subplots(figsize=(16,4))
    fig.subplots_adjust(bottom=0.2)
    ax.xaxis.set_major_locator(mondays)
    ax.xaxis.set_minor_locator(alldays)
    ax.xaxis.set_major_formatter(weekFormatter)

    # Visualizzo il grafico a candele OHLC, dove i giorni positivi
    # sono candele nere e quelli negativi sono rosse
    csticks = candlestick_ohlc(
        ax, df[
            ['date_fmt', 'Open', 'High', 'Low', 'Close']
        ].values, width=0.6,
        colorup='#000000', colordown='#ff0000'
    )
    ax.set_facecolor((1,1,0.9))
    ax.xaxis_date()
    plt.setp(
        plt.gca().get_xticklabels(),
        rotation=45, horizontalalignment='right'
    )
    plt.show()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-8e8538f elementor-widget elementor-widget-text-editor" data-id="8e8538f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				La seguente funzione <code>plot_3d_normalised_candles</code> crea un grafico a dispersione di tutte le candele nello spazio tridimensionale, normalizzate al prezzo di apertura. Ogni candela giornaliera è colorata in base all&#8217;appartenenza ad un cluster (che viene determinata nei successivi frammenti di codice):					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-46db482 elementor-widget elementor-widget-code-highlight" data-id="46db482" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def plot_3d_normalised_candles(data, labels):
    """
    Visualizza un grafico a dispersione 3D di tutte le candelle
    normalizzate con l'apertura evidenziando i cluster con colori diversi
    """
    fig = plt.figure(figsize=(12, 9))
    ax = Axes3D(fig, elev=21, azim=-136)
    ax.scatter(
        data["H/O"], data["L/O"], data["C/O"],
        c=labels.astype(np.float)
    )
    ax.set_xlabel('High/Open')
    ax.set_ylabel('Low/Open')
    ax.set_zlabel('Close/Open')
    plt.show()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-b7c646c elementor-widget elementor-widget-text-editor" data-id="b7c646c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>La funzione successiva <code>plot_cluster_ordered_candles</code> è simile al grafico a candele precedente, dove viene ordinato in base appartenenza al cluster invece che per data. Inoltre, ogni confine di cluster viene visualizzato con una linea tratteggiata blu. La funzione è alquanto complessa a causa, anche in questo caso, alle istruzioni necessarie per la formattazione con Matplotlib.</p><p>L&#8217;ultima sezione della funzione prevede la creazione di un DataFrame chiamato <code>change_indices</code>. Il suo compito è determinare l&#8217;indice in cui si trova un nuovo limite del cluster. Si ottiene ordinando tutti gli elementi in base al loro indice del cluster e quindi utilizzando il metodo <code>diff</code> per ottenere i punti di modifica. Quindi viene filtrato da tutti i valori che non sono uguali a zero, che restituisce un DataFrame costituito da cinque righe, una per ogni limite. Infine si utilizza il metodo <code>axvline</code> di Matplotlib per tracciare la linea blu tratteggiata:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-be1f8d0 elementor-widget elementor-widget-code-highlight" data-id="be1f8d0" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def plot_cluster_ordered_candles(data):
    """
    Visualizza il grafico a candele ordinato secondo l'appartenza
    ad un cluster con la linea tratteggiata blu che rappresenta
    il bordo di ogni cluster.
    """
    # Imposto il formato per gli assi per formmattare
    # correttamente le date, con Lunedi come tick principale
    mondays = WeekdayLocator(MONDAY)
    alldays = DayLocator()
    weekFormatter = DateFormatter("")
    fig, ax = plt.subplots(figsize=(16,4))
    ax.xaxis.set_major_locator(mondays)
    ax.xaxis.set_minor_locator(alldays)
    ax.xaxis.set_major_formatter(weekFormatter)

    # Ordino i dati in base ai valori dei cluster e ottengo
    # un dataframe che contiene i valori degli indici per
    # ogni variazione dei bordi dei cluster
    df = copy.deepcopy(data)
    df.sort_values(by="Cluster", inplace=True)
    df.reset_index(inplace=True)
    df["clust_index"] = df.index
    df["clust_change"] = df["Cluster"].diff()
    change_indices = df[df["clust_change"] != 0]

    # Visualizzo il grafico OHLC con le candele ordinati in base ai cluster
    csticks = candlestick_ohlc(
        ax, df[
            ["clust_index", 'Open', 'High', 'Low', 'Close']
        ].values, width=0.6,
        colorup='#000000', colordown='#ff0000'
    )
    ax.set_facecolor((1,1,0.9))

    # Aggiungo ogni bordi di cluster come una linea blu trattegiata
    for row in change_indices.iterrows():
        plt.axvline(
            row[1]["clust_index"],
            linestyle="dashed", c="blue"
        )
    plt.xlim(0, len(df))
    plt.setp(
        plt.gca().get_xticklabels(),
        rotation=45, horizontalalignment='right'
    )
    plt.show()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-e2f4317 elementor-widget elementor-widget-text-editor" data-id="e2f4317" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>L&#8217;ultima funzione è <code>create_follow_cluster_matrix</code>. Il suo compito è produrre una matrice \(k \times k\), dove <em>k</em> è il numero di cluster selezionati per il processo di K-Means Clustering. Ciascun elemento della matrice rappresenta la frequenza percentuale che il cluster <em>j</em> sia il cluster giornaliero successivo al cluster <em>i</em>. Questo è utile nell&#8217;impostazione del trading quantitativo perchè permette di determinare la distribuzione campionaria delle variazioni di cluster.</p><p>La matrice viene costruita utilizzando il metodo <code>shift</code> di Pandas, per creare una una nuova colonna <code>ClusterTomorrow</code> contenente il valore del cluster di domani. Si crea quindi la colonna <code>ClusterMatrix</code> formando una tupla dell&#8217;indice del cluster di oggi e dell&#8217;indice del cluster di domani. Si utilizza quindi il metodo <code>value_counts</code> di Pandas per creare una distribuzione di frequenza di queste coppie. Infine, si calcola una matrice NumPy \(k \times k\) con la frequenza percentuale delle occorrenze di ogni cluster follow-on:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-dd22934 elementor-widget elementor-widget-code-highlight" data-id="dd22934" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def create_follow_cluster_matrix(data):
    """
    Crea una matrice k x k, dove k è il numero di clusters
    che mostra quanto il cluster i è seguito dal cluster j.
    """
    data["ClusterTomorrow"] = data["Cluster"].shift(-1)
    data.dropna(inplace=True)
    data["ClusterTomorrow"] = data["ClusterTomorrow"].apply(int)
    data["ClusterMatrix"] = list(zip(data["Cluster"], data["ClusterTomorrow"]))
    cmvc = data["ClusterMatrix"].value_counts()
    clust_mat = np.zeros( (k, k) )
    for row in cmvc.iteritems():
        clust_mat[row[0]] = row[1]*100.0/len(data)
    print("Cluster Follow-on Matrix:")
    print(clust_mat)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-af894f0 elementor-widget elementor-widget-text-editor" data-id="af894f0" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				La funzione <code>__main__</code> unisce tutte le funzioni di cui sopra. Si esegue l&#8217;algoritmo K-Means e si usano i valori di appartenenza ai cluster in tutte le successive funzioni:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-606c830 elementor-widget elementor-widget-code-highlight" data-id="606c830" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
if __name__ == "__main__":
    # Scarico i dati dei prezzi di S&P500 da Yahoo Finance
    start = datetime.datetime(2013, 1, 1)
    end = datetime.datetime(2015, 12, 31)
    sp500 = yf.download("^GSPC", start, end)

    # Visualizzo il grafico a candele dei prezzi dell'ultimo anno
    plot_candlesticks(sp500, datetime.datetime(2015, 1, 1))

    # Eseguo il K-Means clustering con 5 clusters sui dati
    # 3-dimensionali di H/O, L/O e C/O
    sp500_norm = get_open_normalised_prices(sp500)
    k = 5
    km = KMeans(n_clusters=k, random_state=42)
    km.fit(sp500_norm)
    labels = km.labels_
    sp500["Cluster"] = labels

    # Visualizzo il grafico 3D delle candele normalizzate usando H/O, L/O, C/O
    plot_3d_normalised_candles(sp500_norm, labels)

    # Visualizzo le candele OHLC riordinate
    # nei loro rispettivi cluster
    plot_cluster_ordered_candles(sp500)

    # Creo e restituisco la matrice dei cluster follow-on
    create_follow_cluster_matrix(sp500)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-918595f elementor-widget elementor-widget-text-editor" data-id="918595f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Di seguito l&#8217;output della matrice di follow-on del cluster:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-821f708 elementor-widget elementor-widget-code-highlight" data-id="821f708" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-default copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-markup ">
				<code readonly="true" class="language-markup">
					<xmp>Cluster Follow-on Matrix:
[[ 2.38410596  2.78145695  4.2384106   3.57615894  1.05960265]
 [ 1.45695364  1.85430464  3.17880795  4.76821192  0.66225166]
 [ 4.2384106   1.98675497  9.93377483 14.43708609  1.05960265]
 [ 5.43046358  4.2384106  12.58278146 14.70198675  1.05960265]
 [ 0.66225166  0.92715232  1.7218543   0.52980132  0.52980132]]</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-91352b0 elementor-widget elementor-widget-text-editor" data-id="91352b0" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Da notare che la matrice non è certamente distribuita uniformemente. In altre parole, è probabile che alcune &#8220;candele&#8221; seguano altre con maggiore frequenza. Questo permette la possibilità di creare strategie di trading attorno all&#8217;identificazione dei cluster e alla previsione dei cluster successivi.</p><p>La seguente figura mostra il grafico delle candele dei prezzi OHLC dell&#8217;S&amp;P500 per tutto il 2015. Da notare il forte ribasso intorno alla fine di agosto e la successiva lenta ripresa in ottobre e novembre:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-90b587b elementor-widget elementor-widget-image" data-id="90b587b" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="240" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-sp500-candles-768x240.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-clustering-ohlc-sp500-candles" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-sp500-candles-768x240.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-sp500-candles-300x94.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-sp500-candles-160x50.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-sp500-candles.png 900w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-31fc93c elementor-widget elementor-widget-text-editor" data-id="31fc93c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>La seguente figura è un grafico tridimensionale di prezzi normalizzati high/open, low/open e close/open tracciati l&#8217;uno contro l&#8217;altro. Ognuno dei k=5 cluster sono stati colorati. Si noti che la maggior parte delle barre si trovano intorno \((1.0, 1.0, 1.0)\). Questo significa che la maggior parte dei giorni non è estremamente volatile e quindi le azioni non vengono scambiate con prezzi in un intervallo troppo ampio.</p><p>Tuttavia, ci sono molti giorni in cui il prezzo di chiusura è sostanzialmente al di sopra del prezzo di apertura, come evidenziato dal cluster azzurro nella parte superiore della figura. Inoltre ci sono molti giorni in cui il prezzo minimo è molto al di sotto del prezzo di apertura, indicato dal cluster giallo:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-f4c3775 elementor-widget elementor-widget-image" data-id="f4c3775" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="672" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-kmeans-scatterplot-768x672.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-clustering-ohlc-kmeans-scatterplot" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-kmeans-scatterplot-768x672.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-kmeans-scatterplot-300x263.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-kmeans-scatterplot-160x140.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-kmeans-scatterplot.png 800w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fdbaaa5 elementor-widget elementor-widget-text-editor" data-id="fdbaaa5" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>La seguente figura mostra le candele per il 2013-2015 ordinate in base all&#8217;appartenenza al cluster. Da questo grafico si evidenzia il funzionamento dell&#8217;algoritmo K-Means sui dati delle candele. Ci sono due grandi cluster al centro del grafico che rappresentano rispettivamente giorni di leggero ribasso e giorni di leggero rialzo., mentre alle estremità del grafico si possono vedere i rialzi e i ribassi più elevati.</p><p>E&#8217; interessante notare come l&#8217;appartenenza al cluster è altamente discontinua. Ci sono molti più giorni a bassa volatilità che giorni ad alta volatilità. In particolare i cluster estremi contengo le giornate con forti ribassi:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-8e92961 elementor-widget elementor-widget-image" data-id="8e92961" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="283" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-candle-clusters-768x283.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-clustering-ohlc-candle-clusters" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-candle-clusters-768x283.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-candle-clusters-300x111.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-candle-clusters-160x59.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-clustering-ohlc-candle-clusters.png 800w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-a9c1aa8 elementor-widget elementor-widget-text-editor" data-id="a9c1aa8" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Questa analisi è certamente interessante e motiva ulteriori approfondimenti. Tuttavia, è necessaria una notevole quantità di lavoro extra per eseguire qualsiasi forma di strategia di trading quantitativo. In particolare, ci siamo limitato a solo due anni interi dei dati giornalieri dell&#8217;S&amp;P500. Potrebbe essere facilmente esteso nel tempo o su molti più asset (azioni o altro).</p><p>Inoltre non possiamo verificare se la scelta di <em>k</em> è corretta. Forse \(k=4\) o \(k=6\) potrebbe ro essere migliori. Si dovrebbe scegliere <em>k</em> asset per asset e, in caso affermativo, in base a quale metrica di &#8220;bontà&#8221;?</p><p>Un altro problema è che questi calcoli sono effettuati in-sample . Qualsiasi utilizzo futuro di questo algoritmo come strumento predittivo presuppone implicitamente che la distribuzione dei cluster rimanga simile al passato. Un&#8217;implementazione più realistica prenderebbe in considerazione una qualche forma di strumento di clustering &#8220;rolling&#8221; o &#8220;online&#8221; che produrrebbe una matrice di follow-on per ciascuna finestra mobile.</p><p>Sarebbe necessario che questa matrice non si discostasse troppo frequentemente, altrimenti è probabile che il suo potere predittivo sia scarso, ma abbastanza frequentemente da poter rilevare implicitamente i cambiamenti del regime di mercato. Chiaramente questo motiva molte differenti vie di ricerca!</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e61eed9 elementor-widget elementor-widget-text-editor" data-id="e61eed9" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Nota bibliografica</h2><p>K-Means Clustering è una tecnica ben nota e descritta in molti libri di testo di machine learning. Un&#8217;introduzione relativamente semplice, senza ricorrere a troppa matematica, è descritta da James et al (2013) [1]. Vengono delineate le basi dell&#8217;algoritmo e le sue insidie.</p><p>I libri di livello universitario di Hastie et al (2009) [2] e Murphy (2012) [3] approfondiscono il &#8220;quadro più ampio&#8221; degli algoritmi di clustering, inserendoli nel quadro della modellazione probabilistica. Inoltre, mettono K-Means nel contesto con altri algoritmi di clustering come la quantizzazione vettoriale e i modelli di miscele gaussiane. Altri libri che discutono del K-Means clustering includono Bishop (2007) [4] e Barber (2012) [5].</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-d1cfaef elementor-widget elementor-widget-text-editor" data-id="d1cfaef" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Riferimenti</h2>
<ul>
 	<li><a href="http://www-bcf.usc.edu/~gareth/ISL/" name="ref-isl2013">[1] James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) <em>An Introduction to Statistical Learning</em>, Springer</a></li>
 	<li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" name="ref-esl2009">[2] Hastie, T., Tibshirani, R., Friedman, J. (2009) <em>The Elements of Statistical Learning</em>, Springer</a></li>
 	<li><a href="https://www.cs.ubc.ca/~murphyk/MLbook/" name="ref-murphy2012">[3] Murphy, K.P. (2012) <em>Machine Learning &#8211; A Probabilistic Perspective</em>, MIT Press</a></li>
 	<li><a href="http://amzn.to/2crPMo9" name="ref-bishop2007">[4] Bishop, C. (2007) <em>Pattern Recognition and Machine Learning</em>, Springer</a></li>
 	<li><a href="http://www.cs.ucl.ac.uk/staff/d.barber/brml/" name="ref-barber2012">[5] Barber, D. (2012) <em>Bayesian Reasoning and Machine Learning</em>, Cambridge University Press</a></li>
 	<li><a href="https://www.r-bloggers.com/artificial-intelligence-in-trading-k-means-clustering/" name="ref-martinaitis2011">[6] Martinaitis, D. (2011) <em>Artificial intelligence in trading: k-means clustering</em>, R-Bloggers</a></li>
 	<li><a href="http://intelligenttradingtech.blogspot.co.uk/2010/06/quantitative-candlestick-pattern.html" name="">[7] Intelligent Trading (2010) <em>Quantitative Candlestick Pattern Recognition (HMM, Baum Welch, and all that)</em>, Intelligent Trading Tech</a></li>
</ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/k-means-clustering-dei-dati-giornalieri-con-barre-ohlc/">K-Means Clustering dei dati giornalieri con barre OHLC</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Combinazioni di Decision Tree con bagging, random forest e alberi potenziati</title>
		<link>https://datatrading.info/combinazioni-di-decision-tree-con-bagging-random-forest-e-alberi-potenziati/</link>
					<comments>https://datatrading.info/combinazioni-di-decision-tree-con-bagging-random-forest-e-alberi-potenziati/#respond</comments>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Sat, 09 Dec 2017 15:29:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Statistical Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=5055</guid>

					<description><![CDATA[<p>In un precedente articolo è stato introdotto l&#8217;albero decisionale (DT) come metodo di apprendimento supervisionato. Nell&#8217;articolo abbiamo definito che la vera potenzialità dei Decision Tree è la loro capacità di funzionare estremamente bene come predittori quando usati in un insieme statistico (statistical ensemble). In questo articolo descriviamo come la combinazione di più DT in un &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/combinazioni-di-decision-tree-con-bagging-random-forest-e-alberi-potenziati/"> <span class="screen-reader-text">Combinazioni di Decision Tree con bagging, random forest e alberi potenziati</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/combinazioni-di-decision-tree-con-bagging-random-forest-e-alberi-potenziati/">Combinazioni di Decision Tree con bagging, random forest e alberi potenziati</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="5055" class="elementor elementor-5055">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-a0f32aa elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="a0f32aa" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-b65f67e" data-id="b65f67e" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-efb5f7f elementor-widget elementor-widget-text-editor" data-id="efb5f7f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>In un <a href="https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/">precedente articolo</a> è stato introdotto l&#8217;albero decisionale (DT) come metodo di apprendimento supervisionato. Nell&#8217;articolo abbiamo definito che la vera potenzialità dei Decision Tree è la loro capacità di funzionare estremamente bene come predittori quando usati in un insieme statistico (<em>statistical ensemble</em>).</p><p>In questo articolo descriviamo come la combinazione di più DT in un insieme statistico migliora notevolmente le prestazioni predittive sul modello combinato. Queste tecniche non si limitano ai DT, ma possono efficacemente applicate a molti modelli di machine learning, sia di regressione che di classificazione. Tuttavia, i DT forniscono una configurazione &#8220;naturale&#8221; per descrivere i metodi d&#8217;insieme e sono spesso comunemente associati tra loro.</p><p>Dopo aver descritto la teoria di questi metodi d&#8217;insieme, vediamo come implementarli in Python usando la libreria Scikit-Learn applicata ai dati finanziari. Negli articoli successivi descriviamo come applicare tali metodi d&#8217;insieme all&#8217;interno di reali strategie di trading, utilizzando il framework <a href="https://github.com/datatrading-info/DataTrader">DataTrader</a>.</p><p>Se non si ha familiarità con gli alberi decisionali, è opportuno leggere l&#8217;<a href="https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/">articolo introduttivo</a> prima di approfondire i metodi dell&#8217;insieme.</p><p>Prima di approfondire le tecniche dell&#8217;insieme di <strong>bootstrap aggegration (bagging), random forest e boosting</strong> è necessario introdurre una tecnica della statistica frequentista nota come <strong>bootstrap</strong>, che consente a queste tecniche di funzionare.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-7530d38 elementor-widget elementor-widget-text-editor" data-id="7530d38" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Il Bootstrap</h2><p>Il Bootstrapping [1] è una tecnica di ricampionamento statistico che prevede il campionamento casuale di un set di dati tramite <em>sostituzione</em>. Viene spesso utilizzato come strumento per quantificare l&#8217;incertezza associata a un modello di machine learning.</p><p>Nella finanza quantitativa il bootstrapping è estremamente utile perchè consente di generare nuovi campioni da una popolazione senza dover andare a raccogliere ulteriori &#8220;dati di addestramento&#8221;. Nelle applicazioni di finanza quantitativa è spesso impossibile generare più dati a partire dai prezzi di asset finanziari dato che esiste solo una &#8220;storia&#8221; da cui campionare.</p><p>L&#8217;obiettivo è produrre molti set di training separati tramite il campionamento ripetuto dei dati con la sostituzione del training set originale. Questi sono quindi utilizzati per consentire ai metodi &#8220;meta-learner&#8221; o &#8220;ensemble&#8221; di <em>ridurre la varianza delle loro previsioni</em>, migliorando notevolmente le loro prestazioni predittive.</p><p>Due delle seguenti tecniche d&#8217;insieme, il bagging e le foreste casuali, fanno un uso massiccio di tecniche di bootstrapping.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-dfcd786 elementor-widget elementor-widget-text-editor" data-id="dfcd786" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Aggregazione bootstrap (Bagging)</h2><p>Come descritto nell&#8217;articolo sulla <a href="https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/">teoria degli Decition Tree</a>, uno dei principali svantaggi dei DT è l&#8217;elevata varianza delle stime effettuate (<em>high-variance estimator</em>). Ne consegue che l&#8217;aggiunta di un piccolo numero di osservazioni di addestramento extra può alterare drasticamente le prestazioni di previsione di un decision tree, nonostante i dati di addestramento non  subiscono variazioni significative.</p><p>Al contrario un <em>low-variance estimator</em>, come la regressione lineare, non è estremamente sensibile all&#8217;aggiunta di punti extra, almeno quelli che sono relativamente vicini ai punti rimanenti.</p><p>Un modo per mitigare questo problema consiste nell&#8217;utilizzare un concetto noto come aggregazione bootstrap o <strong>bagging</strong>. L&#8217;idea è di combinare più modelli di learning (come i DT), ognuno addestrato su diversi campioni di bootstrap e calcolare la media delle loro previsioni al fine di ridurre la varianza complessiva di queste previsioni.</p><p>Come sottolineato da James et al (2013) [2], date <em>N </em>osservazioni indipendenti e identicamente distribuite (iid) \(Z_1, \ldots, Z_N\), ciascuno con una varianza di \(\sigma^2\) allora la varianza della media delle osservazioni, \(\bar{Z}\) è data da \(\sigma^2 / N\), cioè, se si prende la media di queste osservazioni, la varianza viene ridotta di un fattore uguale al numero di osservazioni. Questo dimostra che l&#8217;approccio di bagging è corretto.</p><p>Tuttavia, nella finanza quantitativa si ha quasi sempre ha disposizione un solo set di dati di &#8220;training&#8221;, quindi è difficile, se non impossibile, creare più set di training indipendenti e separati. In questi casi è necessario applicare il bootstrap in modo da generare molti diversi set di training, a partire da un set più grande.</p><p>Dal lavoro di James et al (2013) [2] e dall&#8217;articolo Random Forest su Wikipedia [3], se creiamo \(B\) campioni bootstrap separati del set di addestramento, con diversi stimatori di modelli \(\hat{f}^b ({\bf x})\), allora la media dei campioni forma una modello di stima a bassa varianza, \(\hat{f}_{\text{avg}}\):</p><p style="text-align: center;">\(\begin{eqnarray}\hat{f}_{\text{avg}} ({\bf x}) = \frac{1}{B} \sum^{B}_{b=1} \hat{f}^b ({\bf x})\end{eqnarray}\)</p><p>Questa procedura è nota come <em>bagging</em> [4]. È applicabile ai DT perché quest&#8217;ultimi sono &#8216;high-variance estimators&#8217; e quindi il bagging è uno strumento per ridurre sensibilmente la varianza.</p><p>L&#8217;esecuzione del bagging per i DT è semplice. Centinaia o migliaia di alberi molto profondi (non potati) vengono creati attraverso \(B\) campioni bootstrap dei dati di addestramento. Sono combinati con le modalità descritte in precedenza e riducono significativamente la varianza complessiva.</p><p>Il bagging ha il principale vantaggio di non poter sovradimensionare il modello solamente aumentando il numero di campioni bootstrap \(B\). Questo è valido anche per le Random Forest, ma non per gli alberi potenziati.</p><p>Sfortunatamente questo guadagno nell&#8217;accuratezza della previsione produce una significativa riduzione dell&#8217;interpretabilità del modello. Tuttavia, nella ricerca quantitativa, l&#8217;interpretabilità è spesso meno importante rispetto all&#8217;accuratezza della previsione grezza. Quindi questo non è uno svantaggio troppo significativo per le applicazioni di trading algoritmico.</p><p><em>Da notare che esistono metodi statistici specifici per dedurre variabili importanti nel bagging, ma esulano dallo scopo di questo articolo.</em></p>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
				<section class="elementor-section elementor-top-section elementor-element elementor-element-769fbb4 elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="769fbb4" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-12b327f" data-id="12b327f" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-49e3be5 elementor-widget elementor-widget-text-editor" data-id="49e3be5" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Random Forest</h2><p>Le foreste casuali [5] sono molto simili alla procedura di bagging ad eccezione dell&#8217;uso di una tecnica chiamata<em> feature bagging</em>, che ha il vantaggio di diminuire significativamente la correlazione tra ogni DT e quindi aumentare, in media, la sua accuratezza predittiva.</p><p>Il bagging delle feature consiste nel selezionare casualmente un sottoinsieme delle feature a <em>p</em>-dimensioni delle caratteristiche, per ogni divisione nella crescita dei singoli DT. Questo può sembrare controintuitivo, dopotutto si desidera inizialmente includere il maggior numero possibile di feature per ottenere quante più informazioni possibili per il modello. Tuttavia ha lo scopo di evitare deliberatamente (in media) feature predittive molto forti che causano divisioni molto simili negli alberi (e quindi aumentano la correlazione).</p><p>Cioè, se una particolare feature è efficace nel prevedere il valore della risposta, verrà selezionata per molti alberi. In questo caso una procedura  di bagging standard può essere abbastanza correlata. Le foreste casuali evitano questo scenario, scartando deliberatamente queste  forti feature nell&#8217;addestramento di molti alberi.</p><p>Se tutti i valori <em>p</em> sono scelti nella divisione degli alberi in un insieme di foreste casuali, questo corrisponde semplicemente all&#8217;insieme (ensemble) standard. Una regola pratica per le foreste casuali è usare \(\sqrt{p}\) feature, opportunamente arrotondate, ad ogni divisione.</p><p>Di seguito descriviamo il codice Python per verificare come confrontare le prestazioni delle foreste casuali e del bagging, all&#8217;aumentare del numero di DT utilizzati come stimatori di base.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-6a7a7bc elementor-widget elementor-widget-text-editor" data-id="6a7a7bc" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Boosting</h2><p>Un altro metodo d&#8217;insieme molto usato nel machine learning è noto come <strong>potenziamento degli alberi</strong>. Il boosting differisce dal bagging perchè non implica il campionamento bootstrap. Nel boosting i modelli vengono generati in modo sequenziale e iterativo, cioè è necessario disporre di informazioni sul modello \(i\) prima dell&#8217;esecuzione dell&#8217;iterazione \(i+1\).</p><p>Il potenziamento è stato introdotto da Kearns e Valiant (1989) [6], come risposta alla possibilità di combinare, in qualche modo, una selezione di modelli di machine learning deboli per produrre un unico più forte modello di  machine learning. Debole, in questo caso, significa un modello che è solo leggermente migliore della probabilità casuale di prevedere una risposta. Di conseguenza, un modello forte è invece ben correlato alla vera risposta.</p><p>Questo ha motivato il concetto di potenziamento. L&#8217;idea è di <em>addestrare in modo iterativo</em> modelli deboli di machine learning su un set di dati continuamente aggiornato e quindi unire insieme i modelli deboli per produrre un modello finale e forte. Questo è diverso dal bagging, che semplicemente calcola la media dei modelli su campioni bootstrap separati.</p><p>L&#8217;algoritmo di base per il potenziamento, descritto a lungo in James et al (2013) [2] e Hastie et al (2009) [7] , è riportato di seguito:</p><ol><li>Impostare l&#8217;estimatore iniziale  a zero, cioè \(\hat{f}({\bf x}) = 0\). Impostare inoltre i residui sulle risposte correnti, \(r_i = y_i\), per tutti gli elementi del training set.</li><li>Impostare il numero di alberi potenziati, \(B\) ed effettuare il seguente ciclo per \(b=1,\ldots,B\):<br /><ul><li>Addestrare un albero \(\hat{f}^b\) con <em>k</em> divisioni dei dati di allenamento \((x_i, r_i)[/late], per ogni <em>i</em>.</li><li>Aggiungere una versione in scala di questo albero all&#8217;estimatore finale: \(\)\hat{f} ({\bf x}) \leftarrow \hat{f} ({\bf x}) + \lambda \hat{f}^b ({\bf x})\)</li><li>Aggiornare i residui per tenere conto del nuovo modello: \(r_i \leftarrow r_i &#8211; \lambda \hat{f}^b (x_i)\)</li></ul></li><li>Impostare il modello  finale potenziato in modo che sia la somma dei singoli  modelli studenti deboli: \(\hat{f}({\bf x}) = \sum_{b=1}^B \lambda \hat{f}^b ({\bf x})\)</li></ol><p>Si noti che ogni albero successivo viene adattato ai residui dei dati. Quindi ogni iterazione successiva sta lentamente migliorando il modello forte complessivo migliorando le sue prestazioni nelle regioni con scarse prestazioni dello spazio delle feature.</p><p>Da sottolineare che questa procedura dipende fortemente dall&#8217;ordine in cui vengono addestrati ​​gli alberi. Si dice che questo processo &#8220;impara lentamente&#8221;. Tali procedure di apprendimento lento tendono a produrre modelli di machine learning con buone prestazioni. Questo è il motivo per cui gli algoritmi di ensemble che coinvolgono modelli di machine learning potenziati tendono a vincere molte delle <a href="https://www.kaggle.com/competitions">competizioni di Kaggle</a>.</p><p>Ci sono tre iperparametri per l&#8217;algoritmo di potenziamento che abbiamo appena descritto. Vale a dire, la profondità dell&#8217;albero \(k\), il numero di alberi potenziati \(B\) e il tasso di contrazione \(\lambda\). Alcuni di questi parametri possono essere impostati mediante <a href="https://datatrading.info/la-cross-validation-per-ottimizzare-il-machine-learning/">convalida incrociata</a>.</p><p>Uno degli svantaggi computazionali del boosting è che si tratta di un metodo iterativo sequenziale. Ciò significa che non può essere facilmente parallelizzato, a differenza del bagging, che è parallelizzabile direttamente.</p><p>Esistono molti algoritmi di potenziamento, inclusi <a href="https://en.wikipedia.org/wiki/AdaBoost">AdaBoost</a>, <a href="https://en.wikipedia.org/wiki/Xgboost">xgboost</a> e <a href="https://en.wikipedia.org/wiki/LogitBoost">LogitBoost</a>. Prima che l&#8217;uso delle reti neurali profonde convoluzionali diventasse prevalente, gli alberi potenziati erano spesso (e sono tuttora!) alcuni dei migliori strumenti di classificazione &#8220;out of the box&#8221; esistenti.</p><p>Nel prossimo paragrafo descriviamo come il boosting si confronta con il bagging, almeno per il caso del Decision Tree.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-8bc839c elementor-widget elementor-widget-text-editor" data-id="8bc839c" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Implementazione con Python Scikit-Learn</h2><p>In questo paragrafo applichiamo i tre metodi d&#8217;insieme, descritti in precedenza, per prevedere i rendimenti giornalieri per le azioni Amazon, utilizzando i tre giorni precedenti dei dati sui rendimenti.</p><p>Questo è un compito impegnativo, dato che i titoli liquidi come Amazon hanno un basso rapporto segnale-rumore. Inoltre tali dati sono anche <a href="https://datatrading.info/correlazione-seriale-nellanalisi-delle-serie-storiche/">correlati serialmente</a>, cioè i campioni scelti non sono veramente indipendenti l&#8217;uno dall&#8217;altro, quindi si possono avere conseguenze spiacevoli per la validità statistica della procedura.</p><p>Negli articoli successivi eseguiamo una procedura più robusta tramite il meccanismo di convalida incrociata delle serie temporali implementato in Scikit-Learn. Per ora, usiamo una suddivisione standard di training-testing, dato che in questo articolo ci concentriamo sul confronto dell&#8217;errore <em>tra i modelli</em> e non sull&#8217;errore assoluto ottenuto su ciascuno.</p><p>Il risultato finale è un <a href="https://en.wikipedia.org/wiki/Mean_squared_error">grafico dell&#8217;errore quadratico medio</a> (MSE) di ciascun metodo (bagging, random forest e boosting) rispetto al numero di stimatori utilizzati nel campione. Vediamo chiaramente che il bagging e le foreste casuali non si adattano all&#8217;aumentare del numero di stimatori, mentre AdaBoost si adatta significativamente.</p><p>Come sempre, il primo passaggio è importare le necessarie librerie e le funzioni Python. Per questo script sono necessari molti moduli, la maggior parte dei quali si trova nella <a href="http://scikit-learn.org/stable/">libreria Scikit-Learn</a>. Inoltre dobbiamo importare i &#8220;soliti sospetti&#8221;, ovvero Matplotlib, NumPy, Pandas e Seaborn per l&#8217;analisi e il plotting dei dati. Inoltre abbiamo bisogno dei metodi d&#8217;insieme come <code>BaggingRegressor</code>, <code>RandomForestRegressor</code> e <code>AdaBoostRegressor. </code>Infine, importiamo la metrica <code>mean_squared_error</code>, lo strumento di convalida incrociata <code>train_test_split</code>, lo strumento di <code>preprocessing</code> e di <code>DecisionTreeRegressor</code></p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-870cc4b elementor-widget elementor-widget-code-highlight" data-id="870cc4b" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp># ensemble_prediction.py

import datetime

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import yfinance as yf
import seaborn as sns
import sklearn
from sklearn.ensemble import (
    BaggingRegressor, RandomForestRegressor, AdaBoostRegressor
)
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import scale
from sklearn.tree import DecisionTreeRegressor</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-45d7b77 elementor-widget elementor-widget-text-editor" data-id="45d7b77" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Prima di tutto dobbiamo usare Pandas per creare il DataFrame dei valori ritardati. Questo particolare pezzo di codice è stato ampiamente utilizzato in altri articoli sul sito, quindi non c&#8217;è bisogno di descriverlo nei dettagli. La funzione crea un DataFrame contenente i dati dei rendimenti ritardati di tre giorni per una specifica serie temporale di un asset disponibile su Yahoo Finance (oltre al volume degli scambi giornalieri):</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c1d1544 elementor-widget elementor-widget-code-highlight" data-id="c1d1544" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
def create_lagged_series(symbol, start_date, end_date, lags=3):
    """
    Crea un DataFrame panda che memorizza
    i rendimenti percentuali dell valore della chiusura
    rettificata di un assest scaricato da Yahoo Finance,
    insieme a una serie di rendimenti ritardati dei
    giorni di trading precedenti (il ritardo predefinito è 3 giorni).
    È incluso anche il volume degli scambi.
    """

    # Scaricare i dati storici da Yahoo Finance
    ts = yf.download(symbol, start=start_date, end=end_date)

    # Creazione di un DataFrame dei ritardi
    tslag = pd.DataFrame(index=ts.index)
    tslag["Today"] = ts["Adj Close"]
    tslag["Volume"] = ts["Volume"]

    # Creazione della serie dei ritardi dei
    # prezzi di chiusura dei giorni precedenti
    for i in range(0,lags):
        tslag["Lag%s" % str(i+1)] = ts["Adj Close"].shift(i+1)

    # Creazione del DataFrame dei rendimenti
    tsret = pd.DataFrame(index=tslag.index)
    tsret["Volume"] = tslag["Volume"]
    tsret["Today"] = tslag["Today"].pct_change()*100.0

    # Creazione delle colonne delle percentuali dei rendimenti ritardi
    for i in range(0,lags):
        tsret["Lag%s" % str(i+1)] = tslag[
            "Lag%s" % str(i+1)
        ].pct_change()*100.0
    tsret = tsret[tsret.index >= start_date]
    return tsret</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-f559724 elementor-widget elementor-widget-text-editor" data-id="f559724" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Nella funzione <code>__main__</code> impostiamo i parametri. Innanzitutto definiamo un seme casuale per rendere il codice replicabile su altri ambienti di lavoro. Il parametro <code>n_jobs</code> controlla il numero dei core del processore da utilizzare per il bagging e per le foreste casuali. Il boosting non è parallelizzabile, quindi non fa uso di questo parametro.

Il parametro <code>n_estimators</code> definisce il numero totale di stimatori da utilizzare nel grafico del MSE, mentre <code>step_factor</code> controlla la granularità del calcolo impostando i passi attraverso il numero di stimatori. In questo caso <code>axis_step</code> è uguale a 1000/10 = 100, cioè sono eseguiti 100 calcoli separati per ciascuno dei tre metodi di ensemble:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-5d35184 elementor-widget elementor-widget-code-highlight" data-id="5d35184" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Impostazione del seed random, numero di stimatori
    # and lo "step factor" usato per il grafico di MSE
    # per ogni metodo
    random_state = 42
    n_jobs = 1  # Fattore di parallelizazione per il bagging e random forests
    n_estimators = 1000
    step_factor = 10
    axis_step = int(n_estimators/step_factor)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-a77c5d6 elementor-widget elementor-widget-text-editor" data-id="a77c5d6" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Il codice seguente scarica dieci anni di prezzi AMZN e li converte in una serie dei rendimenti lagged utilizzando la funzione <code>create_lagged_series</code>. I valori mancanti vengono eliminati (una conseguenza della procedura di calcolo dei ritardi) e i dati vengono ridimensionati in modo che siano compresi tra -1 e +1 per facilitare il confronto. Quest&#8217;ultima procedura è comune nel machine learning e permette alle feature con grandi differenze nelle dimensioni assolute di essere paragonabili ai modelli:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-64d9817 elementor-widget elementor-widget-code-highlight" data-id="64d9817" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Scaricare 10 anni di storico di Amazon
start = datetime.datetime(2006, 1, 1)
end = datetime.datetime(2015, 12, 31)
amzn = create_lagged_series("AMZN", start, end, lags=3)
amzn.dropna(inplace=True)

# Uso dei ritardi dei primi 3 giorni dei prezzi close di AMZN
# e ridimensione dei dati ttra -1 e +1 per i confronti
X = amzn[["Lag1", "Lag2", "Lag3"]]
y = amzn["Today"]
X = scale(X)
y = scale(y)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-a0acd69 elementor-widget elementor-widget-text-editor" data-id="a0acd69" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>I dati sono suddivisi in un set di addestramento e un set di test, con il 70% dei dati che formano i dati di addestramento e il restante 30% che formano il set di test. Da sottolineare che le serie temporali di dati finanziari hanno correlazione seriale, quindi questa procedura introduce alcuni errori dato che non teniamo di questa correlazione. Tuttavia, è trascurabile nel confronto tra i tre metodi d&#8217;insieme, scopo principale di questo articolo:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-bc6879a elementor-widget elementor-widget-code-highlight" data-id="bc6879a" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Divisione in training-testing con il 70% dei dati per il 
    # training e il rimanente 30% dei dati per il testing
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=random_state
    )</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-d3b0c32 elementor-widget elementor-widget-text-editor" data-id="d3b0c32" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Le seguenti matrici NumPy memorizzano il numero di stimatori a ogni step dell&#8217;asse, nonché l&#8217;effettivo MSE associato per ciascuno dei tre metodi dell&#8217;insieme. Sono tutti inizialmente azzerati e successivamente compilati:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-43143c2 elementor-widget elementor-widget-code-highlight" data-id="43143c2" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Inizializzazione degli array che conterrano il 
    # MSE per ogni metodo d'insieme
    estimators = np.zeros(axis_step)
    bagging_mse = np.zeros(axis_step)
    rf_mse = np.zeros(axis_step)
    boosting_mse = np.zeros(axis_step)</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-0a13391 elementor-widget elementor-widget-text-editor" data-id="0a13391" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Il primo metodo di ensemble da utilizzare è la procedura di bagging. Il codice esegue un&#8217;iterazione sul numero totale di stimatori (in questo caso da 1 a 1000, con un passo di dimensione pari a 10), definisce il modello dell&#8217;insieme con il corretto modello di base (in questo caso un Decision Tree di regressione), lo adatta ai dati di addestramento e quindi calcola l&#8217;errore quadratico medio sui dati del test. Questo MSE viene quindi aggiunto all&#8217;array del bagging MSE:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-96b2336 elementor-widget elementor-widget-code-highlight" data-id="96b2336" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Stimare il Bagging MSE per l'intero numero di
    # stimatore, con un passo specifico ("step_factor")
    for i in range(0, axis_step):
        print("Bagging Estimator: %d of %d..." % (
            step_factor * (i + 1), n_estimators)
              )
        bagging = BaggingRegressor(
            DecisionTreeRegressor(),
            n_estimators=step_factor * (i + 1),
            n_jobs=n_jobs,
            random_state=random_state
        )
        bagging.fit(X_train, y_train)
        mse = mean_squared_error(y_test, bagging.predict(X_test))
        estimators[i] = step_factor * (i + 1)
        bagging_mse[i] = mse</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-5576c40 elementor-widget elementor-widget-text-editor" data-id="5576c40" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Lo stesso approccio viene eseguito per le random forest. Poiché le foreste casuali utilizzano implicitamente un albero di regressione come stimatore di base, non è necessario specificarlo nel costruttore dell&#8217;insieme:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-998a0e6 elementor-widget elementor-widget-code-highlight" data-id="998a0e6" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>     # Stima del Random Forest MSE per l'intero numero di
    # stimatori, con un passo specifico ("step_factor")
    for i in range(0, axis_step):
        print("Random Forest Estimator: %d of %d..." % (
            step_factor * (i + 1), n_estimators)
              )
        rf = RandomForestRegressor(
            n_estimators=step_factor * (i + 1),
            n_jobs=n_jobs,
            random_state=random_state
        )
        rf.fit(X_train, y_train)
        mse = mean_squared_error(y_test, rf.predict(X_test))
        estimators[i] = step_factor * (i + 1)
        rf_mse[i] = mse
</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-fd5b123 elementor-widget elementor-widget-text-editor" data-id="fd5b123" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Allo stesso modo per l&#8217;algoritmo di boosting AdaBoost sebbene non è presente il parametro <code>n_jobs</code> perchè le tecniche di boosting non sono parallelizzabili. Il tasso di apprendimento, o fattore di contrazione, <code>\lambda</code> è stato impostato a 0,01. La regolazione di questo valore ha un grande impatto sull&#8217;assoluto MSE calcolato per ciascun stimatore totale:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-098291c elementor-widget elementor-widget-code-highlight" data-id="098291c" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Stima del AdaBoost MSE per l'intero numero di
    # stimatori, con un passo specifico ("step_factor")
    for i in range(0, axis_step):
        print("Boosting Estimator: %d of %d..." % (
            step_factor * (i + 1), n_estimators)
              )
        boosting = AdaBoostRegressor(
            DecisionTreeRegressor(),
            n_estimators=step_factor * (i + 1),
            random_state=random_state,
            learning_rate=0.01
        )
        boosting.fit(X_train, y_train)
        mse = mean_squared_error(y_test, boosting.predict(X_test))
        estimators[i] = step_factor * (i + 1)
        boosting_mse[i] = mse</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-ab7d692 elementor-widget elementor-widget-text-editor" data-id="ab7d692" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				L&#8217;ultimo pezzo di codice grafica semplicemente questi array l&#8217;uno contro l&#8217;altro usando Matplotlib, ma con la combinazione di colori predefinita di Seaborn, che è visivamente più gradevole rispetto ai valori predefiniti di Matplotlib:					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-dbd74bf elementor-widget elementor-widget-code-highlight" data-id="dbd74bf" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>    # Visualizzazione del grafico del MSE per il numero di stimatori
    plt.figure(figsize=(8, 8))
    plt.title('Bagging, Random Forest and Boosting comparison')
    plt.plot(estimators, bagging_mse, 'b-', color="black", label='Bagging')
    plt.plot(estimators, rf_mse, 'b-', color="blue", label='Random Forest')
    plt.plot(estimators, boosting_mse, 'b-', color="red", label='AdaBoost')
    plt.legend(loc='upper right')
    plt.xlabel('Estimators')
    plt.ylabel('Mean Squared Error')
    plt.show()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-7c16794 elementor-widget elementor-widget-text-editor" data-id="7c16794" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				Il grafico risultante è riportato nella figura seguente. Da notare come l&#8217;aumento del numero di stimatori per i metodi basati sul bootstrap (bagging e foreste casuali) porta l&#8217;MSE a &#8220;sistemarsi&#8221; e diventare quasi identico tra di loro. Tuttavia, per l&#8217;algoritmo di potenziamento AdaBoost si può vedere che l&#8217;aumento del numero di stimatori  oltre a circa 100, il metodo inizia ad aver un significativo overfit.					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-3abde93 elementor-widget elementor-widget-image" data-id="3abde93" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="700" height="558" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-ensemble-mse-comparison.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-cart-ensemble-mse-comparison" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-ensemble-mse-comparison.png 700w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-ensemble-mse-comparison-300x239.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-ensemble-mse-comparison-160x128.png 160w" sizes="(max-width: 700px) 100vw, 700px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e05e306 elementor-widget elementor-widget-text-editor" data-id="e05e306" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Quando si costruisce una strategia di trading basata su una procedura di boosting ensemble, questo fatto deve essere tenuto presente, altrimenti è probabile ottenere una significativa sottoperformance della strategia quando viene applicata a dati finanziari fuori campione.</p><p>In un articolo successivo utilizziamo i modelli di insieme per prevedere i rendimenti degli asset utilizzando <a href="https://github.com/datatrading-info/DataTrader">DataTrader</a>. Vediamo inoltre se è fattibile produrre una strategia solida che possa essere redditizia al di sopra dei costi di transazione a frequenza più elevata, necessari per eseguire questa strategia a mercato.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c69707d elementor-widget elementor-widget-text-editor" data-id="c69707d" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Riferimenti</h2>
<ul>
 	<li><a href="http://projecteuclid.org/euclid.aos/1176344552" name="ref-efron1979">[1] Efron, B. (1979) &#8220;Bootstrap methods: Another look at the jackknife&#8221;, <em>The Annals of Statistics</em> <strong>7</strong> (1): 1-26</a></li>
 	<li><a href="http://www-bcf.usc.edu/~gareth/ISL/" name="ref-isl">[2] James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) <em>An Introduction to Statistical Learning</em>, Springer</a></li>
 	<li><a href="https://en.wikipedia.org/wiki/Random_forest" name="ref-wiki-random-forest">[3] Wikipedia (2016) <em>Wikipedia: Random Forest</em>, https://en.wikipedia.org/wiki/Random_forest</a></li>
 	<li><a href="http://link.springer.com/article/10.1007%2FBF00058655" name="ref-breiman1996">[4] Breiman, L. (1996) &#8220;Bagging predictors&#8221;, <em>Machine Learning</em> <strong>24</strong> (2): 123-140</a></li>
 	<li><a href="http://link.springer.com/article/10.1023%2FA%3A1010933404324" name="ref-breiman2001">[5] Breiman, L. (2001) &#8220;Random Forests&#8221;, <em>Machine Learning</em> <strong>45</strong> (1): 5-32</a></li>
 	<li><a href="http://dl.acm.org/citation.cfm?doid=73007.73049" name="ref-kearns1989">[6] Kearns, M., Valiant, L. (1989) &#8220;Crytographic limitations on learning Boolean formulae and finite automata&#8221;, <em>Symposium on Theory of computing. ACM.</em> <strong>21</strong> (None): 433-444</a></li>
 	<li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" name="ref-esl">[7] Hastie, T., Tibshirani, R., Friedman, J. (2009) <em>The Elements of Statistical Learning</em>, Springer</a></li>
</ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/combinazioni-di-decision-tree-con-bagging-random-forest-e-alberi-potenziati/">Combinazioni di Decision Tree con bagging, random forest e alberi potenziati</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
					<wfw:commentRss>https://datatrading.info/combinazioni-di-decision-tree-con-bagging-random-forest-e-alberi-potenziati/feed/</wfw:commentRss>
			<slash:comments>0</slash:comments>
		
		
			</item>
		<item>
		<title>Metodo della Massima Verosimiglianza per la Regressione Lineare</title>
		<link>https://datatrading.info/metodo-della-massima-verosimiglianza-per-la-regressione-lineare/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Mon, 04 Dec 2017 15:59:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Statistical Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=4583</guid>

					<description><![CDATA[<p>Lo scopo di questa serie di articoli è quello di descrivere una tecnica molto familiare, la regressione lineare, in un contesto matematico più rigoroso sotto un&#8217;interpretazione probabilistica del machine learning. Questo permette di comprendere il quadro delle probabilità che verrà successivamente utilizzato per modelli di .apprendimento supervisionato più complessi, in un contesto più semplice. Iniziamo &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/metodo-della-massima-verosimiglianza-per-la-regressione-lineare/"> <span class="screen-reader-text">Metodo della Massima Verosimiglianza per la Regressione Lineare</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/metodo-della-massima-verosimiglianza-per-la-regressione-lineare/">Metodo della Massima Verosimiglianza per la Regressione Lineare</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="4583" class="elementor elementor-4583">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-89d9710 elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="89d9710" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-464f969" data-id="464f969" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-592e672 elementor-widget elementor-widget-text-editor" data-id="592e672" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Lo scopo di questa serie di articoli è quello di descrivere una tecnica molto familiare, la regressione lineare, in un contesto matematico più rigoroso sotto un&#8217;interpretazione probabilistica del machine learning. Questo permette di comprendere il quadro delle probabilità che verrà successivamente utilizzato per modelli di .apprendimento supervisionato più complessi, in un contesto più semplice.</p><p>Iniziamo definendo la regressione lineare multipla, inserendola in un framework di apprendimento supervisionato probabilistico e ricavando una stima ottimale per i suoi parametri attraverso una tecnica nota come metodo di massima verosimiglianza.</p><p>Negli articoli successivi descriviamo i metodi per ridurre o mitigare la dimensione di determinati set di dati attraverso i concetti di selezione e restringimento di sottoinsiemi. Inoltre usiamo la libreria <a href="http://scikit-learn.org/stable/">Scitkit-Learn</a> di Python per dimostrare la regressione lineare, la selezione di sottoinsiemi e il restringimento.</p><p>Molte di queste tecniche si possono facilmente applicare a modelli più sofisticati e ci aiutano notevolmente nella creazione di metodi statistici efficaci e robusti per lo sviluppo di strategie di trading.</p><p><em>Questo articolo è molto più rigoroso dal punto di vista matematico rispetto ad altri articoli. E&#8217; necessario per introdurre un più avanzato  meccanismo probabilistico che pervade la ricerca sull&#8217;apprendimento automatico. Dopo aver visto alcuni esempi di modelli più semplici in questo framework, è più facile iniziare a consultare i documenti accademici di Machine Learning più avanzati, utili per nuove idee di trading.</em></p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-9545970 elementor-widget elementor-widget-text-editor" data-id="9545970" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Regressione lineare</h2><p>La regressione lineare è una delle tecniche statistiche più familiari e dirette. Viene spesso insegnato al liceo, anche se in modo semplificato. Di solito è anche la prima tecnica presa in considerazione quando si studia l&#8217;apprendimento supervisionato poiché solleva questioni importanti che riguardano molti altri modelli supervisionati.</p><p>La regressione lineare afferma che il valore della risposta \(y\) è una funzione lineare delle feature d&#8217;ingresso \({\bf x}\), cioè:</p><p style="text-align: center;">\(\begin{eqnarray}y ({\bf x}) = \beta^T {\bf x} + \epsilon = \sum_{j=0}^p \beta_j x_j + \epsilon\end{eqnarray}\)</p><p>Dove \(\beta^T, {\bf x} \in \mathbb{R}^{p+1}\) e \(\epsilon \sim \mathcal{N}(\mu, \sigma^2)\), cioè \(\beta^T\) e \(x\) sono entrambi vettori di dimensione <em>p+1</em> e \(\epsilon\),  l&#8217;<em>errore</em> o il <em>residuo</em>, ha distribuzione normale con media \(\mu\) e varianza \(\sigma^2\). \(\epsilon\) rappresenta la differenza tra le previsioni fatte dalla regressione lineare e il vero valore della variabile di risposta.</p><p>Da notare che \(\beta^T\), cioè la trasposizione del vettore \(\beta\),  e \(x\) hanno entrambi dimensione <em>p+1</em>, piuttosto che dimensione <em>p</em>, perché dobbiamo includere un termine di intercetta. \(\beta^T = (\beta_0, \beta_1, \ldots, \beta_p)\), mentre \({\bf x} = (1, x_1, \ldots, x_p)\). Dobbiamo includere &#8216;1&#8217; in \(x\) come &#8220;trucco&#8221; notazionale.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-d830e93 elementor-widget elementor-widget-text-editor" data-id="d830e93" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Interpretazione probabilistica</h2><p>Un modo alternativo per descrivere la regressione lineare è considerarla come un modello di probabilità congiunta [2] , [3]. In altre parole siamo interessati alla probabilità congiunta di avere il comportamento della risposta <em>y</em> condizionato ai valori del vettore delle feature <em>x</em>, nonché a altri parametri del modello (descritti dal vettore \({\bf \theta}\)). Quindi siamo interessati a un modello nella forma \(p(y \mid {\bf x}, {\bf \theta})\), cioè un modello di <strong>densità di probabilità condizionata</strong> (CPD).</p><p>La regressione lineare può essere scritta come CPD nel modo seguente:</p><p style="text-align: center;">\(\begin{eqnarray}p(y \mid {\bf x}, {\bf \theta}) = \mathcal (y \mid \mu({\bf x}), \sigma^2 ({\bf x}))\end{eqnarray}\)</p><p>Per la regressione lineare  assumiamo che \(\mu({\bf x})\) sia lineare e quindi \(\mu ({\bf x}) = \beta^T {\bf x}\). Dobbiamo anche assumere che la varianza nel modello sia fissa (cioè che non dipenda da <em>x</em>) e quindi \(\sigma^2 ({\bf x}) = \sigma^2\) è una costante. Ciò implica che il nostro vettore di parametri corrisponda a \(\theta = (\beta, \sigma^2)\).</p><p>Ricordiamo che abbiamo usato una tale interpretazione probabilistica quando abbiamo descritto la <a href="https://datatrading.info/modelli-di-regressione-lineare-bayesiana-con-pymc3/">regressione lineare bayesiana</a> in un precdente articolo.</p><p>Generalizzando l&#8217;interpretazione del modello in questo modo abbiamo il vantaggio di poter facilmente vedere come altri modelli, specialmente quelli che gestiscono le non linearità, si inseriscono nello stesso quadro probabilistico. Questo permette di ottenere risultati attraverso i modelli utilizzando tecniche simili.</p><p>Se consideriamo \({\bf x} = (1, x)\), possiamo creare un grafico bidimensionale \({\bf x} = (1, x)\) per <em>x</em> e <em>y</em> in modo da rappresentare graficamente questa distribuzione congiunta. A tale scopo dobbiamo correggere i parametri \(\beta = (\beta_0, \beta_1)\) e \(\sigma^2\) (che costituiscono i parametri di \(\theta\)). Di seguito uno script Python che usa matplotlib per visualizzare la distribuzione:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-54f8c12 elementor-widget elementor-widget-code-highlight" data-id="54f8c12" data-element_type="widget" data-widget_type="code-highlight.default">
				<div class="elementor-widget-container">
					<div class="prismjs-okaidia copy-to-clipboard word-wrap">
			<pre data-line="" class="highlight-height language-python ">
				<code readonly="true" class="language-python">
					<xmp>
from matplotlib import cm
from matplotlib.ticker import LinearLocator, FormatStrFormatter
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import norm


if __name__ == "__main__":
    # Set up the X and Y dimensions
    fig = plt.figure()
    ax = fig.gca(projection='3d')
    X = np.arange(0, 20, 0.25)
    Y = np.arange(-10, 10, 0.25)
    X, Y = np.meshgrid(X, Y)

    # Create the univarate normal coefficients
    # of intercep and slope, as well as the
    # conditional probability density
    beta0 = -5.0
    beta1 = 0.5
    Z = norm.pdf(Y, beta0 + beta1*X, 1.0)

    # Plot the surface with the "coolwarm" colormap
    surf = ax.plot_surface(
        X, Y, Z, rstride=1, cstride=1, cmap=cm.coolwarm,
        linewidth=0, antialiased=False
    )

    # Set the limits of the z axis and major line locators
    ax.set_zlim(0, 0.4)
    ax.zaxis.set_major_locator(LinearLocator(5))
    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))

    # Label all of the axes
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('P(Y|X)')

    # Adjust the viewing angle and axes direction
    ax.view_init(elev=30., azim=50.0)

    # Plot the probability density
    plt.show()</xmp>
				</code>
			</pre>
		</div>
				</div>
				</div>
				<div class="elementor-element elementor-element-22076e6 elementor-widget elementor-widget-image" data-id="22076e6" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="700" height="558" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-linreg-cond-prob-dens-2dplot.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-linreg-cond-prob-dens-2dplot" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-linreg-cond-prob-dens-2dplot.png 700w, https://datatrading.info/wp-content/uploads/trading-machine-learning-linreg-cond-prob-dens-2dplot-300x239.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-linreg-cond-prob-dens-2dplot-160x128.png 160w" sizes="(max-width: 700px) 100vw, 700px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-ed8841e elementor-widget elementor-widget-text-editor" data-id="ed8841e" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>È chiaro che la risposta \(y\) è linearmente dipendente da \(x\). Tuttavia siamo anche in grado di verificare l&#8217;elemento probabilistico del modello dato che la probabilità si distribuisce normalmente attorno alla risposta lineare.</p><h4>Estensione della funzione di base</h4><p>L&#8217;uso dell&#8217;interpretazione probabilistica ha il vantaggio di verificare facilmente come modellare relazioni non lineari, semplicemente sostituendo il vettore delle feature \(x\) con una specifica funzione di trasformazione \(\phi({\bf x})\):</p><p style="text-align: center;">\(\begin{eqnarray}p(y \mid {\bf x}, {\bf \theta}) = \mathcal(y \mid \beta^T \phi({\bf x}), \sigma^2)\end{eqnarray}\)</p><p>Per \({\bf x} = (1, x_1, x_2, x_3)\) possiamo creare una \(\phi\) che include termini di ordine superiore, inclusi termini incrociati, ad es:</p><p style="text-align: center;">\(\begin{eqnarray}\phi({\bf x}) = (1, x_1, x_1^2, x_2, x^2_2, x_1 x_2, x_3, x_3^2, x_1 x_3, \ldots)\end{eqnarray}\)</p><p>Da sottolineare che questa funzione non è lineare nelle <em>feature</em>, \(x\), ma è ancora lineare nei <em>parametri</em>, \({\bf \beta}\), quindi può essere considerata una regressione lineare.</p><p>Tale modifica, utilizzando una funzione di trasformazione \(\phi\), è nota come <strong>estensione della funzione di base</strong> e può essere utilizzata per generalizzare la regressione lineare a molte configurazioni di dati non lineari.</p><p>Esistono molte altre tecniche di apprendimento supervisionato più sofisticate per catturare le non linearità. Abbiamo descritto una di queste tecniche, Support Vector Machines con il &#8220;trucco del kernel&#8221;, in <a href="https://datatrading.info/guida-introduttiva-alla-support-vector-machine-svm/">questo articolo</a>.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-9e586cc elementor-widget elementor-widget-text-editor" data-id="9e586cc" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Metodo della massima verosimiglianza</h2><p>In questa paragrafo descriviamo come i coefficienti di regressione lineare ottimali, ovvero il parametro delle componenti \(\beta\), sono scelti per adattarsi al meglio ai dati. Nel caso univariato questo è spesso noto come &#8220;trovare la retta di migliore adattamento&#8221;. Tuttavia, siamo in un caso multivariato, come il nostro vettore di feature \({\bf x} \in \mathbb{R}^{p+1}\), quindi si tratta di &#8220;trovare l&#8217;iperpiano <em>p</em>-dimensionale di migliore adattamento&#8221;!</p><p>Lo strumento principale per trovare i parametri dei modelli statistici è noto come <strong>metodo della massima verosimiglianza</strong> (MLE). E&#8217; stato introdotto brevemente nell&#8217;articolo sul <a href="https://datatrading.info/deep-learning-con-theano-regressione-logistica/" data-wplink-edit="true">Deep Learning e la regressione logistica</a>.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-1d41a1f elementor-widget elementor-widget-text-editor" data-id="1d41a1f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Verosimiglianza e verosimiglianza logaritmica negativa</h4><p>L&#8217;idea fondamentale è, se i dati sono stati <em>generati</em> dal modello, quali parametri sono stati usati con maggiore probabilità? Cioè, qual è la probabilità di avere i dati \(\mathcal{D}\), dato uno specifico insieme di parametri \({\bf \theta}\)? Anche questo caso è un problema di densità di probabilità condizionata. Vogliamo trovare i valori di \({\bf \theta}\) che massimizzano \(p(\mathcal{D} \mid {\bf \theta})\). Questo CPD è noto come <strong>verosimiglianza</strong> e abbiamo descritto alcuni esempi nell&#8217;articolo <a href="https://datatrading.info/introduzione-alla-statistica-bayesiana/">introduttivo sulle statistiche bayesiane</a>.</p><p>Questo problema può essere formulato come la ricerca della moda di \(p(\mathcal{D} \mid {\bf \theta})\), che corrisponde a \(\hat{{\bf \theta}}\). Per facilitare il calcolo, cerchiamo di massimizzare il logaritmo naturale del CPD, invece dello stesso CPD:</p><p style="text-align: center;">\(\begin{eqnarray}\hat{{\bf \theta}} = \text{argmax}_{\theta} \log p(\mathcal{D} \mid {\bf \theta})\end{eqnarray}\)</p><p>Nei problemi di regressione lineare dobbiamo assumere che i vettori delle feature siano tutti <strong>indipendenti e identicamente distribuiti</strong> (iid). Questo rende molto più semplice risolvere il problema della <strong>log-verosimiglianza</strong>, usando le proprietà dei logaritmi naturali. Poiché dobbiamo differenziare questi valori, è molto più facile differenziare una somma rispetto a un prodotto, da cui il logaritmo:</p><p style="text-align: center;">\(\begin{eqnarray}\mathcal{l}({\bf \theta}) &amp;:=&amp; \log p(\mathcal{D} \mid {\bf \theta}) \\<br />&amp;=&amp; \log \left( \prod_{i=1}^{N} p(y_i \mid {\bf x}_i, {\bf \theta}) \right) \\<br />&amp;=&amp; \sum_{i=1}^{N} \log p(y_i \mid {\bf x}_i, {\bf \theta})\end{eqnarray}\)</p><p>Come descritto nell&#8217;articolo sul <a href="https://datatrading.info/deep-learning-con-theano-regressione-logistica/">Deep Learning e la Regressione Logistica</a>, per motivi di maggiore facilità di calcolo, è spesso consigliabile ridurre al minimo il negativo della log-verosimiglianza piuttosto che massimizzare il log-verosimiglianza. Quindi, possiamo &#8220;mettere un segno meno davanti alla log-verosimiglianza&#8221; per ottenere la log-verosimiglianza negativa (NLL):</p><p style="text-align: center;">\(\begin{eqnarray}\text{NLL} ({\bf \theta}) = &#8211; \sum_{i=1}^{N} \log p(y_i \mid {\bf x}_i, {\bf \theta})\end{eqnarray}\)</p><p>Questa è la funzione che dobbiamo minimizzare. In questo modo deriviamo la <strong>stima dei minimi quadrati ordinari</strong> per i coefficienti \(\beta\).</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-f9192db elementor-widget elementor-widget-text-editor" data-id="f9192db" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Minimi quadrati ordinari</h4><p>Il nostro obiettivo è ricavare l&#8217;insieme ottimale di coefficienti \(\beta\) che &#8220;molto probabilmente&#8221; hanno generato i dati per il nostro problema di addestramento. Questi coefficienti devono formare un iperpiano di &#8220;best fit&#8221; attraverso i dati di allenamento. Il processo da seguire è dato da:</p><ol><li>Utilizzare la definizione della distribuzione normale per estendere la funzione di verosimiglianza logaritmica negativa.</li><li>Utilizzare le proprietà dei logaritmi per riformularlo in termini di somma residua dei quadrati (RSS), che è equivalente alla somma di ogni residuo attraverso tutte le osservazioni.</li><li>Riscrivere i residui in forma matriciale, creando la matrice <em>X</em> dei dati, che ha \(N \times (p+1)\) dimensioni, e formulare l&#8217;RSS come un&#8217;equazione di matrici.</li><li>Differenziare questa equazione matriciale rispetto a al vettore \(\beta\) dei parametri e impostare l&#8217;equazione a zero (con alcune ipotesi su <em>X</em>)</li><li>Risolvere l&#8217;equazione  per \(\beta\) per ricavare \(\hat{\beta}_\text{OLS}\), la stima dei<strong> minimi quadrati ordinari</strong> (OLS).</li></ol><p>Di seguito seguiamo da vicino gli approcci descritti in [2] e [3] . Il primo passo è espandere l&#8217;NLL utilizzando la formula per una distribuzione normale:</p><p style="text-align: center;">\(\begin{eqnarray}\text{NLL} ({\bf \theta}) &amp;=&amp; &#8211; \sum_{i=1}^{N} \log p(y_i \mid {\bf x}_i, {\bf \theta}) \\<br />&amp;=&amp; &#8211; \sum_{i=1}^{N} \log \left[ \left(\frac{1}{2 \pi \sigma^2}\right)^{\frac{1}{2}} \exp \left( &#8211; \frac{1}{2 \sigma^2} (y_i &#8211; {\bf \beta}^{T} {\bf x}_i)^2 \right)\right] \\<br />&amp;=&amp; &#8211; \sum_{i=1}^{N} \frac{1}{2} \log \left( \frac{1}{2 \pi \sigma^2} \right) &#8211; \frac{1}{2 \sigma^2} (y_i &#8211; {\bf \beta}^T {\bf x}_i)^2 \\<br />&amp;=&amp; &#8211; \frac{N}{2} \log \left( \frac{1}{2 \pi \sigma^2} \right) &#8211; \frac{1}{2 \sigma^2} \sum_{i=1}^N (y_i &#8211; {\bf \beta}^T {\bf x}_i)^2 \\<br />&amp;=&amp; &#8211; \frac{N}{2} \log \left( \frac{1}{2 \pi \sigma^2} \right) &#8211; \frac{1}{2 \sigma^2} \text{RSS}({\bf \beta})\end{eqnarray}\)</p><p>Dove \(\text{RSS}({\bf \beta}) := \sum_{i=1}^N (y_i &#8211; {\bf \beta}^T {\bf x}_i)^2\)<br />è la <strong>somma residua dei quadrati</strong>, nota anche come <strong>somma degli errori quadrati</strong> (SSE).</p><p>Poiché il primo termine nell&#8217;equazione è una costante, dobbiamo semplicemente preoccuparci di minimizzare l&#8217;RSS, che sarà sufficiente per produrre la stima del parametro ottimale.</p><p>Per semplificare la  formula, possiamo scrivere quest&#8217;ultimo termine in forma matriciale. Considerando \(N \times (p+1)\) della matrice <em>X </em>possiamo scrivere il termine RSS come:</p><p style="text-align: center;">\(\begin{eqnarray}\text{RSS}({\bf \beta}) = ({\bf y} &#8211; {\bf X}{\bf \beta})^T ({\bf y} &#8211; {\bf X}{\bf \beta})\end{eqnarray}\)</p><p>A questo punto vogliamo ora differenziare questo termine rispetto alla variabile dei parametr \({\bf \beta}\):</p><p style="text-align: center;">\(\begin{eqnarray}\frac{\partial RSS}{\partial \beta} = -2 {\bf X}^T ({\bf y} &#8211; {\bf X} \beta)\end{eqnarray}\)</p><p>C&#8217;è un presupposto  fondamentale da fare. Abbiamo bisogno che \({\bf X}^T {\bf X}\) sia definito positivamente, che si verifica solo nel caso in cui ci sono più osservazioni che dimensioni. Se questo non è il caso (cosa estremamente comune nelle configurazioni ad alta dimensione), non è possibile trovare un insieme univoco di coefficienti \(\beta\) e quindi la  conseguente equazione matriciale non sarà valida.</p><p>Nell&#8217;ipotesi di una \({\bf X}^T {\bf X}\) definita positivamente possiamo impostare l&#8217;equazione differenziata a zero e ricavare \(\beta\):</p><p style="text-align: center;">\(\begin{eqnarray}{\bf X}^T ({\bf y} &#8211; {\bf X} \beta) = 0\end{eqnarray}\)</p><p>La soluzione a questa equazione matriciale fornisce \(\hat{\beta}_\text{OLS}\):</p><p style="text-align: center;">\(\begin{eqnarray}\hat{\beta}_\text{OLS} = ({\bf X}^{T} {\bf X})^{-1} {\bf X}^{T} {\bf y}\end{eqnarray}\)</p><p> </p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c06f0b8 elementor-widget elementor-widget-text-editor" data-id="c06f0b8" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Prossimi passi</h2><p>Ora che abbiamo descritto la procedura MLE per produrre le stime OLS, possiamo discutere cosa succede quando ci troviamo in un ambiente ad alta dimensione (come spesso accade con i dati del mondo reale) e quindi la nostra matrice \({\bf X}^T {\bf X}\) non ha l&#8217;inverso. In questo caso è necessario utilizzare tecniche di selezione di sottoinsiemi e restringimento per ridurre la dimensionalità del problema. Questo è l&#8217;argomento del prossimo articolo.</p><h2>Nota bibliografica</h2><p>Un&#8217;introduzione elementare alla regressione lineare, così come al restringimento, alla regolarizzazione e alla riduzione della dimensione, nel quadro dell&#8217;apprendimento supervisionato, può essere trovata in [1] . Una spiegazione molto più rigorosa delle tecniche, compresi i recenti sviluppi, si può trovare in [2] . Un approccio probabilistico (principalmente bayesiano) alla regressione lineare, insieme a una derivazione completa della stima di massima verosimiglianza tramite i minimi quadrati ordinari e un&#8217;ampia discussione sulla contrazione e sulla regolarizzazione, può essere trovata in [3] . Una panoramica basata su esempi del &#8220;mondo reale&#8221; della regressione lineare in un regime di alta linearità, con un&#8217;ampia discussione sulla riduzione della dimensione e sui minimi quadrati parziali può essere trovata in [4].</p><h2>Riferimenti</h2><ul><li><a href="http://www-bcf.usc.edu/~gareth/ISL/" name="ref-isl"><span><span class="goog-text-highlight">[1] James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) </span></span><em><span><span class="goog-text-highlight">An Introduction to Statistical Learning</span></span></em><span><span class="goog-text-highlight"> , Springer</span></span></a></li><li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" name="ref-esl"><span>[2] Hastie, T., Tibshirani, R., Friedman, J. (2009) </span><em><span>Gli elementi dell&#8217;apprendimento statistico</span></em><span> , Springer</span></a></li><li><a href="https://www.cs.ubc.ca/~murphyk/MLbook/" name="ref-murphy"><span>[3] Murphy, KP (2012) </span><em><span>Apprendimento automatico Una prospettiva probabilistica</span></em><span> , MIT Press</span></a></li><li><a href="http://appliedpredictivemodeling.com/" name="ref-kuhn"><span>[4] Kuhn, M., Johnson, K. (2013) </span><em><span>Modellazione predittiva applicata</span></em><span> , Springer</span></a></li></ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/metodo-della-massima-verosimiglianza-per-la-regressione-lineare/">Metodo della Massima Verosimiglianza per la Regressione Lineare</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Decision Tree per il Machine Learning Supervisionato</title>
		<link>https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Thu, 30 Nov 2017 11:06:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Statistical Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=4933</guid>

					<description><![CDATA[<p>Questo articolo descriveun metodo di machine learning statistico noto come Decision Tree. Gli alberi decisionali (DT) sono una tecnica di apprendimento supervisionato che stima/predice i valori delle risposte tramite l&#8217;apprendimento di regole decisionali derivate dalle feature. Possono essere utilizzati sia in un contesto di regressione che di classificazione. Per questo motivo sono talvolta indicati anche &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/"> <span class="screen-reader-text">Decision Tree per il Machine Learning Supervisionato</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/">Decision Tree per il Machine Learning Supervisionato</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="4933" class="elementor elementor-4933">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-29e9dc0 elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="29e9dc0" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-8a34b47" data-id="8a34b47" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-a434d40 elementor-widget elementor-widget-text-editor" data-id="a434d40" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Questo articolo descriveun metodo di machine learning statistico noto come <strong>Decision Tree</strong>. Gli alberi decisionali (DT) sono una tecnica di apprendimento supervisionato che stima/predice i valori delle <em>risposte</em> tramite l&#8217;apprendimento di regole decisionali derivate dalle <em>feature</em>. Possono essere utilizzati sia in un contesto di <a href="http://en.wikipedia.org/wiki/Regression_analysis">regressione</a> che di <a href="http://en.wikipedia.org/wiki/Statistical_classification">classificazione</a>. Per questo motivo sono talvolta indicati anche come Classification And Regression Trees (CART).</p><p>I modelli DT/CART sono un esempio di una più generale area del machine learning nota come <strong>adaptive basis function models</strong>. Questi modelli apprendono le feature direttamente dai dati, anziché essere prespecificate, come in altrei approcci. Tuttavia, a differenza della regressione lineare, questi modelli <em>non sono lineari nei parametri</em> e quindi possiamo solamente calcolare una stima di massima verosimiglianza  (MLE) <em>localmente ottimale</em> per i parametri [1] .</p><p>I modelli DT/CART funzionano suddividendo lo spazio delle caratteristiche in una serie di semplici regioni rettangolari, suddivise per assi paralleli . Per ottenere una previsione per una particolare osservazione, viene utilizzata la media o la modalità delle risposte delle osservazioni di addestramento , all&#8217;interno della partizione a cui appartiene la nuova osservazione.</p><p>L&#8217;utilizzo di un DT/CART ha il vantaggio principale di produrre, per costruzione, un set di regole decisionali interpretabili <em>if-then-else</em>, che sono simili ai diagrammi di flusso grafici. Mentre ha il principale svantaggio di non avere la stessa precisione di essere competitivo rispetto alle altre tecniche supervisionate come le support vector machines o deep neural networks in termini di precisione di previsione.</p><p>Tuttavia i DT/CART possono diventare estremamente competitivi se utilizzati in un metodo <em>ensemble</em> come con l&#8217;aggregazione bootstrap (&#8220;<strong>bagging</strong>&#8221; ), le <strong>random forest</strong> o il <strong>boosting</strong>.</p><p>Nella finanza quantitativa gli insiemi di modelli DT/CART vengono utilizzati nella previsione, sia per  prezzi/direzioni futuri degli asset sia per la liquidità di determinati strumenti. Negli articoli futuri descriviamo strategie di trading basate su questi metodi.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-48f8402 elementor-widget elementor-widget-text-editor" data-id="48f8402" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Panoramica matematica</h2><p>Considerando una specifica funzione di base adattiva probabilistica, il modello \(f({\bf x})\) è data da [1] :</p><p style="text-align: center;">\(\begin{eqnarray}f({\bf x}) = \mathbb{E}(y \mid {\bf x}) = \sum^{M}_{m=1} w_m \phi({\bf x}; {\bf v}_m)\end{eqnarray}\)</p><p>Dove \(w_m\) è la risposta media in una particolare regione, \(R_m\), e \({\bf v}_m\) descrive come ciascuna variabile viene divisa in corrispondenza di un determinato valore di soglia. Queste divisioni definiscono comei lo spazio delle feature \(R^p\) viene mappato in \(M\) diverse regioni di &#8220;iperblocco&#8221;.</p><h2>Decision tree per la regressione</h2><p>Consideriamo un esempio astratto del problema di regressione con due variabili caratteristiche (\(X_1\), \(X_2\)) e una risposta numerica \(y\). In questo modo possiamo facilmente visualizzare la natura del partizionamento effettuato dall&#8217;albero.</p><p>Nella seguente figura possiamo vedere un albero pre-addestrato per questo specifico esempio:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-9ccaa29 elementor-widget elementor-widget-image" data-id="9ccaa29" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="768" height="581" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-example-tree-768x581.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-cart-example-tree" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-example-tree-768x581.png 768w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-example-tree-300x227.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-example-tree-160x121.png 160w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-example-tree.png 902w" sizes="(max-width: 768px) 100vw, 768px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-6f6291f elementor-widget elementor-widget-text-editor" data-id="6f6291f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>In che modo questo corrisponde a una partizione dello spazio delle feature? La figura seguente mostra un sottoinsieme di \(\mathbb{R}^2\) che contiene i dati del nostro esempio. Notiamo come il dominio viene partizionato utilizzando le divisioni parallele all&#8217;asse. Ovvero, ogni divisione del dominio è allineata con uno degli assi delle feature:</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-3b3422d elementor-widget elementor-widget-image" data-id="3b3422d" data-element_type="widget" data-widget_type="image.default">
				<div class="elementor-widget-container">
								<div class="elementor-image">
												<img width="766" height="739" src="https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-axis-parallel-split.png" class="attachment-medium_large size-medium_large" alt="trading-machine-learning-cart-axis-parallel-split" loading="lazy" srcset="https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-axis-parallel-split.png 766w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-axis-parallel-split-300x289.png 300w, https://datatrading.info/wp-content/uploads/trading-machine-learning-cart-axis-parallel-split-160x154.png 160w" sizes="(max-width: 766px) 100vw, 766px" />														</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-df140c7 elementor-widget elementor-widget-text-editor" data-id="df140c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>Il concetto di divisione in assi paralleli si generalizza direttamente per dimensioni maggiori di due. Per uno spazio di feature di dimensioni <em>p</em>, un sottoinsieme di \(\mathbb{R}^p\), lo spazio è suddiviso in <em>M</em> regioni, \(R_m\), ognuno dei quali è un iperblocco a <em>p</em>-dimensioni.</p><p>Dobbiamo ancora descrivere come tale albero venga &#8220;cresciuto&#8221; o &#8220;addestrato&#8221;. Il seguente paragrafo descrive l&#8217;algoritmo per eseguire questa operazione.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-0151dc6 elementor-widget elementor-widget-text-editor" data-id="0151dc6" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Creare un albero di regressione e fare previsioni</h4><p>L&#8217;euristica di base per la creazione di un DT è la seguente:</p><ul><li>Date <em>p</em> feature, partizionare lo spazio delle feature a p-dimensioni (un sottoinsieme di \(\mathbb{R}^p\)) in <em>M</em> regioni reciprocamente distinte che coprono completamente il sottoinsieme dello spazio delle caratteristiche e non si sovrappongono. Queste regioni sono date da \(R_1,&#8230;,R_M\).</li><li>Qualsiasi nuova osservazione che cade in una specifica partizione \(R_m\) ha una risposta stimata data dalla media di tutte le <em>osservazioni di addestramento</em> con la partizione, indicata con \(w_m\).</li></ul><p>Tuttavia, questo processo in realtà non descrive come formare la partizione in modo algoritmico! Per questo abbiamo bisogno di usare una tecnica nota come <strong>Recursive Binary Splitting (RBS)</strong>[2].</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-2a9dd14 elementor-widget elementor-widget-text-editor" data-id="2a9dd14" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h6>Divisione binaria ricorsiva (Recursive Binary Splitting)</h6><p>L&#8217;obiettivo di questo algoritmo è ridurre al minimo una qualche forma di criterio di errore. In questo caso particolare, desideriamo ridurre al minimo la <strong>somma residua dei quadrati (RSS)</strong>, una misura di errore utilizzata anche nelle configurazioni di regressione lineare. L&#8217;RSS, nel caso di uno spazio di feature diviso in <em>M</em> partizioni è data da:</p><p style="text-align: center;">\(\begin{eqnarray}\text{RSS} = \sum^{M}_{m=1} \sum_{i \in R_m} ( y_i &#8211; \hat{y}_{R_m} )^2\end{eqnarray}\)</p><p>Per prima cosa sommiamo su tutte le partizioni dello spazio delle caratteristiche (la prima sommatoria) e quindi sommiamo su tutte le osservazioni di test (indicizzate da <em>i</em>) in una partizione particolare (la seconda sommatoria). Prendiamo quindi il quadrato della differenza tra la risposta \(y_i\) di una particolare osservazione e la risposta media \(\hat{y}_{R_m}\) delle osservazioni di addestramento all&#8217;interno della partizione.</p><p>Sfortunatamente considerare tutte le possibili partizioni dello spazio delle feature in <em>M </em>rettangoli è troppo costoso dal punto di vista computazionale (dato che è un problema<a href="https://en.wikipedia.org/wiki/NP-completeness"> NP-completo</a>). E&#8217; necessario quindi prevedere un approccio di ricerca meno  oneroso dal punto di vista computazionale, ma più sofisticato. Il Recursive Binary Splitting (RBS) è utile a questo scopo.</p><p>Il RBS affronta il problema partendo dalla cima dell&#8217;albero e dividendolo in due rami, creando così una partizione in due spazi. Esegue più volte questa specifica suddivisione nella parte superiore dell&#8217;albero e sceglie la suddivisione delle  feature che riduce al minimo l&#8217;RSS (attuale).</p><p>A questo punto l&#8217;albero crea un nuovo ramo in una determinata partizione ed esegue la stessa procedura, ovvero valuta l&#8217;RSS ad ogni split della partizione e sceglie la migliore.</p><p>Questo lo rende un algoritmo <strong>avido</strong>, nel senso che esegue la valutazione per ogni iterazione del ciclo, piuttosto che &#8220;guardare avanti&#8221; e continuare a ramificarsi prima di effettuare le valutazioni. È questa natura &#8220;avida&#8221; dell&#8217;algoritmo che lo rende computazionalmente fattibile e quindi nell&#8217;uso pratico [1], [2] .</p><p>In questa fase non abbiamo descritto quando effettivamente termina questa procedura. Ci sono alcuni criteri che possiamo prendere in considerazione, tra cui porre un limite alla profondità massima dell&#8217;albero, garantire esempi di addestramento sufficienti in ciascuna regione e/o garantire che le regioni siano sufficientemente omogenee in modo tale che l&#8217;albero sia relativamente &#8220;equilibrato&#8221;.</p><p>Tuttavia, come con tutti i metodi di machine learning supervisionato, dobbiamo essere costantemente consapevoli dell&#8217;overfitting. Questo motiva il concetto di &#8220;potatura&#8221; (pruning) dell&#8217;albero.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-4f71e63 elementor-widget elementor-widget-text-editor" data-id="4f71e63" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Potare l&#8217;albero</h4><p>A causa del sempre presente  rischio di overfitting e del <a href="https://datatrading.info/il-compromesso-bias-varianza-nel-machine-learning/">compromesso bias-varianza</a>, abbiamo bisogno di uno strumento per regolare il processo di divisione dell&#8217;albero in modo che possa generalizzare gli insiemi di test nel migliore dei modi.</p><p>Dato che è troppo costoso utilizzare la <a href="https://datatrading.info/la-cross-validation-per-ottimizzare-il-machine-learning/">convalida incrociata</a> direttamente su ogni possibile combinazione di sottoalbero durante la crescita (addestramento) dell&#8217;albero, dobbiamo prevedere un approccio alternativo che fornisca comunque un buon tasso di errore di test.</p><p>L&#8217;approccio classico consiste nel far crescere l&#8217;albero intero a una profondità prestabilita e quindi eseguire una procedura nota come &#8220;potatura&#8221;. Un approccio è chiamato <em>cost-complexity pruning</em> ed è descritto dettagliatamente in [2] e [3] . Si basa sull&#8217;introduzione di un ulteriore parametro di ottimizzazione, indicato con \(\alpha\), che bilancia la profondità dell&#8217;albero e la bontà di adattamento ai dati di allenamento. L&#8217;approccio utilizzato è simile alla <a href="https://www.jstor.org/stable/2346178" target="_blank" rel="noopener">tecnica LASSO</a> sviluppata da Tibshirani.</p><p>Non descriviamo i dettagli della potatura degli alberi dato che usiamo la libreria Scikit-Learn per implementare questo approccio.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-cea9bcf elementor-widget elementor-widget-text-editor" data-id="cea9bcf" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Alberi decisionali per la classificazione</h2><p>Finora abbiamo descritto i Decision Tree applicati alla regressione, ma gli alberi decisionali funzionano ugualmente bene per la classificazione, da qui la &#8220;C&#8221; nei modelli CART!</p><p>L&#8217;unica differenza, come per tutti i regimi di classificazione, è la previsione di un valore categorico per la variabile di risposta, invece che un valore continuo. Per effettuare una <em>previsione</em> di una classe di categoria dobbiamo utilizzare la <em>moda</em> della regione di addestramento a cui appartiene un&#8217;osservazione, invece che la <em>media</em>. In altre parole, prendiamo il valore di classe più comune e lo assegniamo come risposta dell&#8217;osservazione.</p><p>Inoltre, dobbiamo considerare criteri alternativi per dividere gli alberi poiché il solito punteggio RSS non è applicabile nell&#8217;approccio categoriale. Prendiamo in considerazione re criteri alternativi, la &#8220;hit rate&#8221;, il Gini Index e il Cross-Entropy [1] , [2] , [3] .</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-aec3661 elementor-widget elementor-widget-text-editor" data-id="aec3661" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Classificazione Error Rate/Hit Rate</h4><p>Invece che verificare quanto una risposta numerica è lontana dal valore medio, come nella regressione, possiamo definire la &#8220;frequenza di successo&#8221; (hit rate) come la frazione di osservazioni di addestramento in una particolare regione che non appartengono alle classi più diffuse. Cioè, l&#8217;errore è dato da [1], [2]:</p><p style="text-align: center;">\(\begin{eqnarray}E = 1 &#8211; \text{argmax}_{c} (\hat{\pi}_{mc})\end{eqnarray}\)</p><p>Dove \(\hat{\pi}_{mc}\) rappresenta la frazione di dati di addestramento nella regione \(R_m\) che appartengono alla classe <em>c</em>.</p><h4>Indice di Gini</h4><p>Il <em>Gini Index </em>è una metrica di errore alternativa, progettata per mostrare quanto sia &#8220;pura&#8221; una regione. La &#8220;Purezza&#8221; in questo caso indica la quantità di dati di addestramento in una determinata regione che appartiene a una singola classe. Se una regione \(R_m\) contiene dati che provengono principalmente da una singola classe <em>c</em> allora il valore dell&#8217;indice Gini sarà piccolo:</p><p style="text-align: center;">\(\begin{eqnarray}G = \sum_{c=1}^C \hat{\pi}_{mc} (1 &#8211; \hat{\pi}_{mc})\end{eqnarray}\)</p><h4>Entropia incrociata (o devianza)</h4><p>Una terza alternativa, simile all&#8217;indice di Gini, è nota come Cross-Entropy o Deviance :</p><p style="text-align: center;">\(\begin{eqnarray}D = &#8211; \sum_{c=1}^C \hat{\pi}_{mc} \text{log} \hat{\pi}_{mc}\end{eqnarray}\)</p><p>Ciò motiva la domanda su quale metrica di errore utilizzare durante l&#8217;addestramento di un albero di classificazione. Al fine di massimizzare l&#8217;accuratezza della previsione, possiamo dire che l&#8217;Indice  di Gini e la Devianza sono usati più spesso dell&#8217;Hit Rate. Non approfondiamo le motivazioni di questa scelta, ma una buona discussione può essere trovata nei libri forniti nel seguente paragrafo &#8220;Riferimenti&#8221;.</p><p>Nei prossimi articoli usiamo la libreria Scikit-Learn per eseguire attività di classificazione e valutare le misure di errore al fine di determinare l&#8217;efficacia delle nostre previsioni su dati invisibili.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fbd7e0e elementor-widget elementor-widget-text-editor" data-id="fbd7e0e" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Vantaggi e svantaggi degli alberi decisionali</h2>
Come tutti i metodi di machine learning, i modelli DT/CART presenta vantaggi e svantaggi rispetto ad altri modelli:
<h3>Vantaggi</h3>
<ul>
 	<li>I modelli DT/CART sono facili da interpretare, come regole &#8220;if-else&#8221;.</li>
 	<li>I modelli possono gestire feature categoriali e continue nello stesso set di dati</li>
 	<li>Il metodo di costruzione per i modelli DT/CART prevede che le variabili delle feature vengono selezionate automaticamente, invece di dover utilizzare la selezione di sottoinsiemi o simili</li>
 	<li>I modelli sono in grado di scalare efficacemente su grandi set di dati</li>
</ul>
<h3>Svantaggi</h3>
<ul>
 	<li>Prestazioni di previsione relative scarse rispetto ad altri modelli ML</li>
 	<li>I modelli DT/CART soffrono di <em>instabilità</em>, cioè sono molto sensibili ai piccoli cambiamenti nello spazio delle feature. Nel linguaggio del compromesso bias-varianza, sono stimatori di varianza elevata.</li>
</ul>
Sebbene i modelli DT/CART stessi soffrano di scarse prestazioni di previsione, sono estremamente competitivi se utilizzati in un ambiente <em>ensemble</em>, tramite aggregazione bootstrap (&#8220;bagging&#8221;), foreste casuali o boosting.

Nei successivi articoli usiamo il <a href="http://scikit-learn.org/stable/modules/tree.html">modulo Decision Tree</a> della libreria <a href="http://scikit-learn.org/stable">scikit-learn</a> di Python per effettuare la classificazione e regressione su alcuni dataset di finanza quantitativa.

Inoltre vediamo come insiemi di modelli DT/CART possono funzionare molto bene per determinati set di dati finanziari quantitativa.					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-e55be10 elementor-widget elementor-widget-text-editor" data-id="e55be10" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Nota bibliografica</h2><p>Una facile introduzione ai metodi basati sui Decision Tree può essere trovata in James et al (2013) [2], che copre le basi di entrambi i DT e degli associati metodi di ensemble. Un resoconto più rigoroso, presentato a livello di matematica/statistica in ritardo di laurea/laurea in matematica, può essere trovato in Hastie et al (2009) [3] . Murphy (2012) [1] descrive i modelli di funzione di base adattiva, di cui i modelli DT/CART sono un sottoinsieme. Il libro copre sia l&#8217;approccio frequentista che bayesiano a questi modelli. Per il professionista che lavora su dati del &#8220;mondo reale&#8221; (come i quants), Kuhn et al (2013) [4] è un testo molto interessante e ad un livello più semplice.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-a2dba5a elementor-widget elementor-widget-text-editor" data-id="a2dba5a" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Riferimenti</h2>
<ul>
 	<li><a href="https://www.cs.ubc.ca/~murphyk/MLbook/" name="ref-murphy">[1] Murphy, K.P. (2012) <em>Machine Learning A Probabilistic Perspective</em>, MIT Press</a></li>
 	<li><a href="http://www-bcf.usc.edu/~gareth/ISL/" name="ref-isl">[2] James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) <em>An Introduction to Statistical Learning</em>, Springer</a></li>
 	<li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" name="ref-esl">[3] Hastie, T., Tibshirani, R., Friedman, J. (2009) <em>The Elements of Statistical Learning</em>, Springer</a></li>
 	<li><a href="http://appliedpredictivemodeling.com/" name="ref-kuhn">[4] Kuhn, M., Johnson, K. (2013) <em>Applied Predictive Modeling</em>, Springer</a></li>
</ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/decision-tree-per-il-machine-learning-supervisionato/">Decision Tree per il Machine Learning Supervisionato</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>Guida Introduttiva all&#8217;Apprendimento Non Supervisionato</title>
		<link>https://datatrading.info/guida-introduttiva-allapprendimento-non-supervisionato/</link>
		
		<dc:creator><![CDATA[Gianluca]]></dc:creator>
		<pubDate>Sat, 25 Nov 2017 14:48:00 +0000</pubDate>
				<category><![CDATA[Tutorial Machine Learning]]></category>
		<category><![CDATA[Tutorial Statistical Learning]]></category>
		<guid isPermaLink="false">https://datatrading.info/?p=4887</guid>

					<description><![CDATA[<p>In questo articolo introduciamo i concetti dell&#8217;apprendimento non supervisionato, una  delle più complesse metodologie del machine learning. L&#8217;apprendimento supervisionato prevede l&#8217;assunzione di una serie di osservazioni di dati, ognuna delle quali contiene una caratteristica (feature), o predittore, vettore, nonché  un output o una risposta associati. L&#8217;obiettivo dell&#8217;apprendimento supervisionato è cercare di prevedere l&#8217;output/risposta a partire &#8230;</p>
<p class="read-more"> <a class="" href="https://datatrading.info/guida-introduttiva-allapprendimento-non-supervisionato/"> <span class="screen-reader-text">Guida Introduttiva all&#8217;Apprendimento Non Supervisionato</span> Leggi tutto »</a></p>
<p>L'articolo <a rel="nofollow" href="https://datatrading.info/guida-introduttiva-allapprendimento-non-supervisionato/">Guida Introduttiva all&#8217;Apprendimento Non Supervisionato</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></description>
										<content:encoded><![CDATA[		<div data-elementor-type="wp-post" data-elementor-id="4887" class="elementor elementor-4887">
						<div class="elementor-inner">
				<div class="elementor-section-wrap">
									<section class="elementor-section elementor-top-section elementor-element elementor-element-c38808b elementor-section-boxed elementor-section-height-default elementor-section-height-default" data-id="c38808b" data-element_type="section">
						<div class="elementor-container elementor-column-gap-default">
							<div class="elementor-row">
					<div class="elementor-column elementor-col-100 elementor-top-column elementor-element elementor-element-7e77137" data-id="7e77137" data-element_type="column">
			<div class="elementor-column-wrap elementor-element-populated">
							<div class="elementor-widget-wrap">
						<div class="elementor-element elementor-element-4dcee1e elementor-widget elementor-widget-text-editor" data-id="4dcee1e" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<p>In questo articolo introduciamo i concetti dell&#8217;<strong>apprendimento non supervisionato</strong>, una  delle più complesse metodologie del machine learning.</p><p>L&#8217;apprendimento supervisionato prevede l&#8217;assunzione di una serie di osservazioni di dati, ognuna delle quali contiene una caratteristica (feature), o predittore, vettore, nonché  un output o una risposta associati. L&#8217;obiettivo dell&#8217;apprendimento supervisionato è cercare di prevedere l&#8217;output/risposta a partire caratteristiche/predittori associati. È &#8220;supervisionato&#8221; perché nella fase di addestramento, o supervisione, del processo di apprendimento l&#8217;algoritmo ha accesso alla &#8220;verità di base&#8221; tramite risposte note a determinati input. Li usa per regolare i parametri del suo modello. In questo modo può tentare di fare una stima della risposta quando è esposto a nuove feature.</p><p>Nell&#8217;apprendimento non supervisionato abbiamo ancora accesso alle  feature ma non abbiamo una risposta associata. In questo caso siamo interessati esclusivamente agli attributi delle caratteristiche stesse. Gli attributi possono  descrivere se le feature formano cluster o sottogruppi specifici nello spazio delle caratteristiche. Potrebbero anche descrivere se possiamo lavorare con dati di dimensioni molto elevate in un ambiente di dimensioni molto inferiori.</p><p>Le tecniche di apprendimento non supervisionato sono usate nei casi dove può essere proibitivo, in termini di tempo e/o denaro , &#8220;etichettare&#8221; i dati delle caratteristiche, il che consentirebbe di analizzarli utilizzando tecniche supervisionate. Un&#8217;ulteriore motivazione è dovuta al fatto che immagini, video, documenti in linguaggio naturale e dati di ricerca scientifica (come le espressioni geniche), una volta quantificati, hanno una dimensione molto elevata. Tale dimensione elevata richiede tecniche di apprendimento supervisionate con molti gradi di libertà, che potenzialmente portano a un overfitting e quindi a scarse prestazioni del test. Le tecniche di apprendimento non supervisionato sono una  parziale soluzione a questi problemi.</p><p>Sfortunatamente, la mancanza di &#8220;verità di base&#8221; o &#8220;supervisione&#8221; per le tecniche non supervisionate causa spesso a una valutazione soggettiva delle loro prestazioni. Non ci sono approcci ampiamente accettati per quantificare il rendimento degli algoritmi non supervisionati. Le prestazioni sono in gran parte determinate caso per caso utilizzando approcci euristici. Tali valutazioni &#8220;basate sul giudizio&#8221; potrebbero sembrare non scientifiche ai trader  quantitativi, ma le tecniche non supervisionate si sono rivelate estremamente utili in molte aree di ricerca.</p><p>Le tecniche di apprendimento non supervisionato sono spesso impiegate nei domini del rilevamento delle anomalie, dell&#8217;analisi delle abitudini di acquisto, dei sistemi di raccomandazione e dell&#8217;elaborazione del linguaggio naturale. Nella finanza quantitativa trovano impiego nei set di dati di de-noising, nel raggruppamento di portafogli/asset, nel rilevamento del regime di mercato e nella generazione di segnali di trading con l&#8217;elaborazione del linguaggio naturale.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-3a8fb35 elementor-widget elementor-widget-text-editor" data-id="3a8fb35" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Dati di grandi dimensioni</h2><p>La finanza quantitativa e il trading algoritmico vanno ben oltre l&#8217;analisi delle serie temporali dei prezzi degli asset. L&#8217;elevata concorrenza causata dalla proliferazione di fondi quantitativi ha costretto le nuove e le vecchie imprese a prendere in considerazione fonti di dati alternative. Molte di queste fonti sono disomogenee, non numeriche e formano database estremamente grandi. Quando quantificati, spesso mediante un processo noto come vettorizzazione, molti di questi dati sono di grandissime dimensioni. Gli esempi includono immagini satellitari, video ad alta risoluzione, corpora di documenti di testo e i dati dei sensori.</p><p>Per fornire un esempio relativo alle dimensioni elevate di alcuni set di dati, si consideri un monitor standard 1080p, che ha una risoluzione di 1920 X 1080 = 2073600 pixel. Se limitiamo ciascuno di questi pixel solo a essere nero o bianco (cioè &#8220;off&#8221; o &#8220;on&#8221;), allora ci sono \(2^{2073600}\) potenziali immagini che possono essere visualizzate. Questo è un numero enorme (prova a inserirlo nel tuo terminale Python!). Diventa significativamente peggiore se consideriamo che ogni pixel ha spesso \(2^{24}\) potenziali colori (tre canali a 8 bit, rispettivamente per Rosso, Verde e Blu).</p><p>Quindi è particolarmente importante cercare di ridurre la dimensione dei set di dati a un livello più gestibile cercando di trovare <strong>sottospazi dimensionali inferiori</strong> che catturino ancora l&#8217;essenza dei dati. Un&#8217;ulteriore criticità è anche l&#8217;enorme numero di campioni, &#8220;non ci si può aspettare che i dati di addestramento popolino lo spazio&#8221; [3] . Se <em>n</em> è il numero di campioni disponibili e <em>p</em> è la dimensione dello spazio, allora siamo in una situazione in cui \(p \gg n\). In sostanza, ci sono grandi sottoinsiemi dello spazio di cui si sa molto poco. Questo problema è spesso indicato come <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">Curse of Dimensionality</a>.</p><p>Gran parte dell&#8217;apprendimento non supervisionato si concentra quindi nei metodi per ridurre le dimensioni dei dataset a un livello gestibile pur mantenendo la  &#8220;significatività&#8221; dei dati. Matematicamente, vogliamo descrivere le variazioni chiave nei dati utilizzando una inferiore <a href="https://it.wikipedia.org/wiki/Variet%C3%A0_(geometria)">varietà</a> dimensionale di dimensione \(q &lt; p\), che è incluso nel più grande spazio p-dimensionale. Per questo compito sono stati sviluppati algoritmi di riduzione della dimensionalità come l&#8217;Analisi dei Componenti Principali (PCA) lineare e il PCA del kernel non lineare.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-dbe1b7f elementor-widget elementor-widget-text-editor" data-id="dbe1b7f" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Basi matematiche dell&#8217;apprendimento non supervisionato</h2><p>Nell&#8217;apprendimento supervisionato abbiamo accesso a un set di training composto da <em>n</em> coppie di <em>vettori di feature</em>, o <em>predittori</em>, \({\bf x}_i \in \mathbb{R}^p\), e <em>uscite</em> o <em>risposte</em> associate, \(y_i \in \mathbb{R}\). Quindi il nostro set di dati \(({\bf x}_1, y_1), \ldots, ({\bf x}_n, y_n)\) è composto da  <em>n</em> tuple. Le risposte \(y_i\),possono essere considerate come &#8220;etichette&#8221; per l&#8217;insieme delle feature e servono a guidare l&#8217;algoritmo di apprendimento supervisionato nella sua fase di addestramento. Per addestrare il modello dobbiamo usare una funzione di collegamento tra il valore reale della risposta \(y\) e la sua stima dal modello \(\hat{y}\), dato da \(L(y, \hat{y})\).</p><p>L&#8217;apprendimento non supervisionato è diverso dato che abbiamo accesso solo ai predittori \({\bf x}_i\). Cioè, non abbiamo le rispettive risposte etichettate \(y_i\), per ogni punto dati. Quindi per questo tipo di tecniche non esiste il concetto di addestramento o supervisione poiché non c&#8217;è nulla che l&#8217;algoritmo possa utilizzare come verità base. Siamo invece interessati esclusivamente alla struttura delle stesse feature \({\bf x}_i\).</p><p>Un approccio prevede la formulazione probabilistica delle attività tramite un concetto noto come <strong>stima della densità </strong>[2], [4].</p><p>Nel caso di apprendimento supervisionato vogliamo costruire modelli nella forma \(p(y_i \mid {\bf x}_i, \theta)\), cioè siamo particolarmente interessati alla distribuzione delle risposte \(y_i\), che dipendono dai vettori delle feature \({\bf x}_i\) e dai parametri del modello, \(\theta\). Questo è noto come <strong>stima condizionata della densità</strong>.</p><p>Al contrario, nell&#8217;apprendimento non supervisionato, poiché non abbiamo accesso alle risposte\(y_i\), siamo interessati ai modelli probabilistici nella forma \(p({\bf x}_i \mid \theta)\), cioè  la distribuzione dei vettori delle feature \({\bf x}_i\) è condizionata ai parametri del modello, \(\theta\). Questo è noto come <strong>stima incondizionata della densità</strong>. .</p><p>Come accennato in precedenza, una delle sfide principali nei problemi di apprendimento non supervisionato è che spesso \(p \gg n\), cioè la dimensione dello spazio delle feature, <em>p</em>, supera di gran lunga il numero di osservazioni, <em>n</em>. Ciò significa che lo spazio non è molto ben popolato dai dati delle feature e bisogna prestare molta attenzione alle tecniche di <strong>riduzione della dimensione</strong>.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c345298 elementor-widget elementor-widget-text-editor" data-id="c345298" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Algoritmi di apprendimento senza supervisione</h2><p>Ci sono due aree principali dell&#8217;apprendimento non supervisionato che ci interessano nella finanza quantitativa: la riduzione della dimensione e il clustering.</p><h4>Riduzione della dimensione</h4><p>Il meccanismo più comune nell&#8217;apprendimento non supervisionato per ridurre la dimensione dei dataset consiste nell&#8217;analisi delle principali componenti (PCA) (lineare).</p><p>Nel machine learning e nei problemi di finanza quantitativa spesso abbiamo un ampio insieme di variabili correlate in uno spazio di elevate dimensioni. Il PCA ci consente di sintetizzare i dataset utilizzando un numero ridotto di dimensioni. Per raggiungere tale scopo si effettua una trasformazione ortogonale delle coordinate dello spazio originale, formando un nuovo insieme di variabili linearmente non correlate, chiamate <em>componenti principali</em>.</p><p>Le componenti principali corrispondono agli autovettori della matrice di covarianza dei dati. Ciascuna componente principale è ortogonale l&#8217;una all&#8217;altra (per costruzione) e &#8220;spiegano&#8221; (o &#8220;esprimono&#8221;) l’ammontare della variabilità totale osservata sulle variabili originarie. Di solito le prime componenti principali sono in grado di spiegare una grande frazione della variabilità dell&#8217;insieme originale, portando a un&#8217;inferiore dimensione della rappresentazione in questo nuovo spazio.</p><p>In altri termini, si può pensare la PCA come un cambio di base. La trasformazione produce un insieme di vettori di base, un sottoinsieme dei quali è in grado di coprire un sottospazio lineare all&#8217;interno dello spazio originale che rappresenta quasi totalmente il raggruppamento dei dati.</p><p>Tuttavia, non tutti i dati sono facilmente riassunti in un sottospazio lineare. Nei problemi di classificazione, ad esempio, ci sono molte fonti di dati che non sono separabili linearmente. In questo caso è possibile invocare il &#8220;trucco del kernel&#8221;, come descritto nell&#8217;articolo sulla <a href="https://datatrading.info/guida-introduttiva-alla-support-vector-machine-svm/">Support Vector Machines</a>, per separare linearmente uno spazio in uno spazio dimensionale molto più elevato e quindi effettuare PCA nello spazio trasformato. Questo permette di applicare la PCA a set di dati non lineari.</p><p>Nella finanza quantitativa la PCA è spesso usata per <em>l&#8217;analisi di fattori</em>. Un esempio potrebbe essere l&#8217;osservazione di un gran numero di titoli correlati e il tentativo di ridurne la dimensione osservando un insieme più piccolo di <em>variabili latenti</em> non osservate e non correlate . Si prende in considerazione l&#8217;analisi delle componenti principali e l&#8217;analisi dei fattori nei successivi articoli.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-c1fe82e elementor-widget elementor-widget-text-editor" data-id="c1fe82e" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h4>Clustering</h4><p>Un&#8217;altra importante tecnica di apprendimento non supervisionato è nota come <strong>analisi dei cluster</strong>. Questa tecnica ha l&#8217;obiettivo di assegnare un&#8217;<em>etichetta </em>agli elementi di uno spazio delle feature in modo da divederli in raggruppamenti o <em>cluster</em>. In alcuni casi, se i sottogruppi all&#8217;interno dello spazio delle feature sono chiaramente distinti e facilmente separabili, i cluster sono individuati senza ambiguità. In altri casi i cluster si possono &#8220;sovrapporre&#8221;, rendendo difficile l&#8217;individuazione di un confine di divisione.</p><p>Il classico algoritmo per l&#8217;analisi dei cluster è il K-Means Clustering. L&#8217;idea di base consiste nell&#8217;assegnare tutti gli <em>n</em> elementi di uno spazio funzionale in <em>K</em> cluster separati e non sovrapposti.</p><p>Questo obbiettivo viene raggiunto tramite un semplice algoritmo iterativo. A tutti gli elementi dello spazio delle funzionalità viene inizialmente assegnato un cluster \(k \in \{1, \ldots, K \}\) in modo casuale. A questo punto l&#8217;algoritmo itera e per ogni passo dell&#8217;iterazione calcola il vettore medio &#8211; il centroide &#8211; di ogni cluster, <em>k</em>, quindi assegna ogni elemento al cluster che possiede il centriode più vicino, utilizzando una metrica di distanza euclidea. L&#8217;algoritmo viene ripetuto fino a quando le posizioni dei centroidi rimangono fisse entro una certa distanza di tolleranza pre-specificata.</p><p>Nella finanza quantitativa il clustering è comunemente usato per identificare asset con caratteristiche simili, utile nella costruzione di portafogli diversificati. Può anche essere utilizzato per rilevare i regimi di mercato e quindi potenzialmente fungere da strumento di gestione del rischio. Descriviamo questo tecniche di clustering in articoli futuri.</p>					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-66adb76 elementor-widget elementor-widget-text-editor" data-id="66adb76" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Nota bibliografica</h2>
Un&#8217;introduzione all&#8217;apprendimento non supervisionato e alle sue difficoltà può essere trovata in[1] . È accessibile a coloro che non hanno un forte background matematico o a coloro che provengono da altre aree della scienza. Una discussione matematica significativamente più avanzata, a livello accademico, può essere trovata in [2]. Il libro discute molte tecniche non supervisionate sebbene si tratti principalmente di metodi supervisionati. [3] discute le grandi dimensioni e i problemi che provocano ad un ragionevole livello matematico, concentrandosi principalmente su PCA e clustering, mentre [4] considera l&#8217;apprendimento non supervisionato attraverso l&#8217;approccio di stima probabilistica della densità ad un inferiore livello di rigore matematico.					</div>
						</div>
				</div>
				<div class="elementor-element elementor-element-fb0c135 elementor-widget elementor-widget-text-editor" data-id="fb0c135" data-element_type="widget" data-widget_type="text-editor.default">
				<div class="elementor-widget-container">
								<div class="elementor-text-editor elementor-clearfix">
				<h2>Riferimenti</h2>
<ul>
 	<li><a href="http://www-bcf.usc.edu/~gareth/ISL/" name="ref-isl">[1] James, G., Witten, D., Hastie, T., Tibshirani, R. (2013) <em>An Introduction to Statistical Learning</em>, Springer</a></li>
 	<li><a href="http://statweb.stanford.edu/~tibs/ElemStatLearn/" name="ref-esl">[2] Hastie, T., Tibshirani, R., Friedman, J. (2009) <em>The Elements of Statistical Learning</em>, Springer</a></li>
 	<li><a href="http://www.cs.ucl.ac.uk/staff/d.barber/brml/" name="ref-barber">[3] Barber, D. (2012) <em>Bayesian Reasoning and Machine Learning</em>, Cambridge University Press</a></li>
 	<li><a href="https://www.cs.ubc.ca/~murphyk/MLbook/" name="ref-murphy">[4] Murphy, K.P. (2012) <em>Machine Learning A Probabilistic Perspective</em>, MIT Press</a></li>
</ul>					</div>
						</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
									</div>
			</div>
					</div>
		<p>L'articolo <a rel="nofollow" href="https://datatrading.info/guida-introduttiva-allapprendimento-non-supervisionato/">Guida Introduttiva all&#8217;Apprendimento Non Supervisionato</a> proviene da <a rel="nofollow" href="https://datatrading.info">Data Trading</a>.</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
